## DEEPFAKE CHALLENGE

## Tech majors, governments must find ways to check use of AI tools that create fake images, like that of Rashmika Mandanna

VIDEO OF actor Rashmika Mandanna has recently gone viral on social media. The problem: It's not she who is in the video. The woman on whose body her face has been morphed has also been violated. This video is not a one-off. Of late, there have been quite a few such fake videos. Deepfakes, as they are known, employ artificial intelligence tools to create fake images, audio and videos. The dramatic spread of Artificial Intelligence platforms has made it easier to create such persuasive deepfakes. There is a deepfake video of Ukrainian President Volodymyr Zelenskyy asking his soldiers to put down their weapons. The relative ease with which such deepfakes can be created and quickly disseminated and consumed, made possible by the wide reach of social media platforms, has become a matter of global concern. More so in times of polarised politics.

Such concerns were acknowledged at Bletchley Park in the UK last week during the first AI safety summit. The Bletchley Declaration, signed by 28 countries including the US, UK, France, China, Japan and India, noted the risks "stemming from the capability to manipulate content or generate deceptive content", and called for global action to address the potential risks stemming from AI. Across the world, countries have opted for different approaches when it comes to regulating AI. While some are in favour of strict oversight and regulation, others are veering towards a lighter touch. For instance, last week, US President Joe Biden issued an executive order to establish "new standards for AI safety and security". The order requires that companies share the results of their safety tests with the US government. It also involves the setting up of standards for "extensive" testing in order to ensure that they are safe before they are publicly released. In India, TRAI had in July outlined the broad contours a regulatory framework could take. It proposed a risk matrix (high or low risk) to classify AI use cases and also called for setting up a statutory authority and a multi-stakeholder body to advise it.

The critical role, however, is that of technology companies. For instance, tech majors such as Alphabet, Meta and OpenAI are taking steps such as watermarking AI-generated content to allow users to identify deepfakes. India is poised to play an important role in the development of the AI ecosystem. That's why it must also help shape the global AI regulatory framework. However, even as policymakers raise the regulatory guardrails and address concerns ranging from privacy to discrimination, and intellectual property rights, among others, they must seek to foster innovation, not stifle it.