<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
 </head>
 <body>
  <h1>
   Martingales
  </h1>
  <p block-type="Text">
   The word
   <i>
    martingale
   </i>
   originated from Middle French. It means a device for steadying a horse's head or checking its upward movement. In eighteenthcentury France,
   <i>
    martingale
   </i>
   also referred to a class of betting strategies in which a player increases the stake usually by doubling each time a bet is lost. The word "martingale", which appeared in the official dictionary of the Academy in 1762 (in the sense of a strategy) means "a strategy that consists in betting all that you have lost". See [7] for more about the origin of martingales. The simplest version of the martingale betting strategies was designed to beat a fair game in which the gambler wins his stake if a coin comes up heads and loses it if the coin comes up tails. The strategy had the gambler keep doubling his bet until the first head eventually occurs. At this point, the gambler stops the game and recovers all previous losses, besides winning a profit equal to the original stake. Logically, if a gambler is able to follow this "doubling strategy" (in French, it is still referred to as la martingale), he would win sooner or later. But in reality, the exponential growth of the bets would bankrupt the gambler quickly. It is Doob's optional stopping theorem (the cornerstone of martingale theory) that shows the impossibility of successful betting strategies.
  </p>
  <p block-type="Text">
   In probability theory, a
   <i>
    martingale
   </i>
   is a stochastic process (a collection of random variables) such that the conditional expectation of an observation at some future time
   <math display="inline">
    t
   </math>
   , given all the observations up to some earlier time
   <math display="inline">
    s &lt; t
   </math>
   , is equal to the observation at that earlier time
   <math display="inline">
    s
   </math>
   . The name "martingale" was introduced by Jean Ville
   <math display="inline">
    (1910-1989)
   </math>
   as a synonym of "gambling system" in his book on "collectif" in the Borel collection, 1938. However, the concept of martingale was created and investigated as early as in 1934 by Paul Pierre Lévy (1886–1971), and a lot of the original development of the theory was done by Joseph Leo Doob (1910-2004). At present, the martingale theory is one of the central themes of modern probability. It plays a very important role in the study of stochastic processes. In practice, a martingale is a model of a fair game. In financial markets, a fair game means that there is no arbitrage. Mathematical finance builds the bridge that connects no-arbitrage arguments and martingale theory. The fundamental theorem (principle) of asset pricing states, roughly
  </p>
  <p block-type="Text">
   speaking, that a mathematical model for stochastic asset prices
   <math display="inline">
    X
   </math>
   is free of arbitrage if and only if
   <math display="inline">
    X
   </math>
   is a martingale under an equivalent probability measure. The fair price of a
   <i>
    contingent claim
   </i>
   associated with those assets
   <math display="inline">
    X
   </math>
   is the expectation of its payoff under the martingale equivalent measure (risk neutral measure).
  </p>
  <p block-type="Text">
   Martingale theory is a vast field of study, and this article only gives an introduction to the theory and describes its use in finance. For a complete description, readers should consult texts such as [4, 13] and [6].
  </p>
  <h4>
   <b>
    Discrete-time Martingales
   </b>
  </h4>
  <p block-type="TextInlineMath">
   A (finite or infinite) sequence of random variables
   <math display="inline">
    X = \{X_n | n = 0, 1, 2, \ldots\}
   </math>
   on a probability space
   <math display="inline">
    (\Omega, \mathcal{F}, \mathbb{P})
   </math>
   is called a discrete-time
   <i>
    martingale
   </i>
   (respectively,
   <i>
    submartingale
   </i>
   ,
   <i>
    supermartingale
   </i>
   ) if for all
   <math display="inline">
    n = 0.1.
   </math>
  </p>
  <p block-type="TextInlineMath">
   2, ...,
   <math display="inline">
    \mathbb{E}[|X_n|] &lt; \infty
   </math>
   and
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\Big[X_{n+1}\Big|X_0, X_1, \dots, X_n\Big] = X_n
   </math>
   <br/>
   (respectively
   <math>
    \ge X_n, \le X_n
   </math>
   ) (1)
  </p>
  <p block-type="Text">
   By the tower property of conditional expectations, equation
   <math display="inline">
    (1)
   </math>
   is equivalent to
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\Big[X_n \Big| X_0, X_1, \dots, X_k\Big] = X_k
   </math>
   <br/>
   (respectively
   <math>
    \ge X_k, \le X_k
   </math>
   ), for any
   <math>
    k \le n
   </math>
   (2)
  </p>
  <p block-type="Text" class="has-continuation">
   Obviously, X is a submartingale if and only if
   <math display="inline">
    -X
   </math>
   is a supermartingale. Every martingale is also a submartingale and a supermartingale; conversely, any stochastic process that is both a submartingale and a supermartingale is a martingale. The expectation
   <math display="inline">
    \mathbb{E}[X_n]
   </math>
   of a martingale X at time n, is a constant for all
   <math display="inline">
    n
   </math>
   . This is one of the reasons that in a fair game, the asset of a player is supposed to be a martingale. For a supermartingale X,
   <math display="inline">
    \mathbb{E}[X_n]
   </math>
   is a nonincreasing function of
   <math display="inline">
    n
   </math>
   , whereas for a submartingale
   <math display="inline">
    X
   </math>
   ,
   <math display="inline">
    \mathbb{E}[X_n]
   </math>
   is a nondecreasing function of
   <math display="inline">
    n
   </math>
   . Here is a mnemonic for remembering which is which: "Life is a supermartingale; as time advances, expectation decreases." The conditional expectation of
   <math display="inline">
    X_n
   </math>
   in equation (2) should be evaluated on the basis
  </p>
  <p block-type="Text">
   of
   <i>
    all
   </i>
   information available up to time
   <math display="inline">
    k
   </math>
   , which can be summarized by a
   <math display="inline">
    \sigma
   </math>
   -algebra
   <math display="inline">
    \mathcal{F}_k
   </math>
   ,
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathcal{F}_k = \{\text{all events occurring at times} \}
   </math>
   <br/>
   <math display="block">
    i = 0, 1, 2, \dots, k\}
   </math>
   (3)
  </p>
  <p block-type="TextInlineMath">
   A sequence of increasing
   <math display="inline">
    \sigma
   </math>
   -algebras
   <math display="inline">
    \{\mathcal{F}_n | n = 0, 1,
   </math>
   2,...}, that is,
   <math display="inline">
    \mathcal{F}_k \subseteq \mathcal{F}_n \subseteq \mathcal{F}
   </math>
   for
   <math display="inline">
    k \leq n
   </math>
   , is called a
   <i>
    filtration
   </i>
   , denoted by
   <math display="inline">
    \mathbb{F}
   </math>
   . When
   <math display="inline">
    \mathcal{F}_n
   </math>
   is the smallest
   <math display="inline">
    \sigma
   </math>
   -algebra containing all the information of X up to time
   <i>
    n
   </i>
   ,
   <math display="inline">
    \mathcal{F}_n
   </math>
   is called the
   <math display="inline">
    \sigma
   </math>
   -algebra generated by
   <math display="inline">
    X_0, X_1, \ldots, X_n
   </math>
   , denoted by
   <math display="inline">
    \sigma\{X_0, X_1, \ldots, X_n\}
   </math>
   , and
   <math display="inline">
    \mathbb{F}
   </math>
   is called the
   <i>
    natural filtration
   </i>
   of X. For another sequence of random variables
   <math display="inline">
    \{Y_k | k = 0, 1, \ldots\}
   </math>
   , let
   <math display="inline">
    \mathcal{F}_k = \sigma\{Y_0, Y_1, \dots, Y_k\}, \text{ then } \mathbb{E}[X_n | Y_0, Y_1, \dots, Y_k] =
   </math>
   <math display="inline">
    \mathbb{E}[X_n|\mathcal{F}_k].
   </math>
  </p>
  <p block-type="TextInlineMath">
   A sequence of random variables
   <math display="inline">
    X = \{X_n | n =
   </math>
   <math display="inline">
    [0, 1, 2, \ldots]
   </math>
   on the filtered probability space
   <math display="inline">
    (\Omega, \mathcal{F}, \mathcal{F})
   </math>
   <math display="inline">
    \mathbb{F}, \mathbb{P}
   </math>
   ) is said to be
   <i>
    adapted
   </i>
   if
   <math display="inline">
    X_n
   </math>
   is
   <math display="inline">
    \mathcal{F}_n
   </math>
   -measurable for each
   <i>
    n
   </i>
   , which means that given
   <math display="inline">
    \mathcal{F}_n
   </math>
   , there is no randomness in
   <math display="inline">
    X_n
   </math>
   . An adapted X is called a discrete-time martingale (respectively submartingale,
   <i>
    supermartingale
   </i>
   ) with respect to the filtration
   <math display="inline">
    \mathbb{F}
   </math>
   , if for each n,
   <math display="inline">
    \mathbb{E}[|X_n|] &lt; \infty
   </math>
   , and
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}[X_n|\mathcal{F}_k] = X_k \quad \text{(respectively } \ge X_k, \quad \le X_k),
   </math>
   <br/>
   for any
   <math>
    k &lt; n
   </math>
   (4)
  </p>
  <p block-type="TextInlineMath">
   <b>
    Example 1
   </b>
   (Closed Martingales). Let
   <math display="inline">
    Z
   </math>
   be a random variable with
   <math display="inline">
    \mathbb{E}|Z| &lt; \infty
   </math>
   , then for any filtration
   <math display="inline">
    \mathbb{F} = (\mathcal{F}_n), X_n = \mathbb{E}[Z|\mathcal{F}_n]
   </math>
   is a martingale (also called a
   <i>
    martingale closed by
   </i>
   <math display="inline">
    Z
   </math>
   ). Conversely, for any martingale
   <math display="inline">
    X
   </math>
   on a finite probability space, there exists a random variable Z such that
   <math display="inline">
    X_n = \mathbb{E}[Z|\mathcal{F}_n]
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   Example 2 (Partial Sums of i.i.d. Random Vari
   <b>
    ables
   </b>
   ). Let
   <math display="inline">
    Z_1, Z_2, \ldots
   </math>
   be a sequence of independent, identically distributed (i.i.d.) random variables such that
   <math display="inline">
    \mathbb{E}[Z_n] = \mu
   </math>
   , and
   <math display="inline">
    \mathbb{E}[Z_n^2] = \sigma^2 &lt; \infty
   </math>
   , and that the moment generating function
   <math display="inline">
    \phi(\theta) = \mathbb{E}[\theta^{Z_1}]
   </math>
   exists for some
   <math display="inline">
    \theta &gt; 0
   </math>
   . Let
   <math display="inline">
    S_n
   </math>
   be the partial sum,
   <math display="inline">
    S_n = Z_1 + \cdots + Z_n
   </math>
   , also called a
   <i>
    random walk
   </i>
   . Let
   <math display="inline">
    \mathcal{F}_n = \sigma\{Z_1,\ldots,Z_n\}
   </math>
   . Then
  </p>
  <p block-type="Equation">
   <math display="block">
    S_n - n\mu, \quad (S_n - n\mu)^2 - n\sigma^2, \quad \frac{\theta^{S_n}}{[\phi(\theta)]^n} \qquad (5)
   </math>
  </p>
  <p block-type="TextInlineMath">
   are all martingales. If
   <math display="inline">
    \mathbb{P}(Z_k = +1) = p
   </math>
   ,
   <math display="inline">
    \mathbb{P}(Z_k =
   </math>
   <math display="inline">
    -1
   </math>
   =
   <math display="inline">
    q = 1 - p
   </math>
   , then
   <math display="inline">
    S_n
   </math>
   is called a
   <i>
    simple
   </i>
   random
  </p>
  <p block-type="TextInlineMath">
   walk and
   <math display="inline">
    (q/p)^{S_n}
   </math>
   is a martingale since
   <math display="inline">
    \phi(p/q) = 1
   </math>
   ; in particular, when
   <math display="inline">
    p = q = 1/2
   </math>
   ,
   <math display="inline">
    S_n
   </math>
   is called a simple symmetric random walk. If
   <math display="inline">
    Z_k
   </math>
   has the Bernoulli distribution,
   <math display="inline">
    \mathbb{P}(Z_k = +1) = p
   </math>
   ,
   <math display="inline">
    \mathbb{P}(Z_k =
   </math>
   <math display="inline">
    0 = q = 1 - p
   </math>
   , then
   <math display="inline">
    S_n
   </math>
   has the binomial distribution
   <math display="inline">
    (n, p)
   </math>
   , and
   <math display="inline">
    (q/p)^{2S_n-n}
   </math>
   is a martingale since
   <math display="inline">
    \phi([q/p]^2) = q/p.
   </math>
  </p>
  <p block-type="TextInlineMath">
   Example 3 (Polya's Urn). An urn initially contains
   <math display="inline">
    r
   </math>
   red and
   <math display="inline">
    b
   </math>
   blue marbles. One is chosen randomly. Then it is put back together with another one of the same color. Let
   <math display="inline">
    X_n
   </math>
   be the number of red marbles in the urn after
   <math display="inline">
    n
   </math>
   iterations of this procedure, and let
   <math display="inline">
    Y_n = X_n/(n + r + b)
   </math>
   . Then the sequence
   <math display="inline">
    Y_n
   </math>
   is a martingale.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Example 4
   </b>
   (A Convex Function of Martingales). By Jensen's inequality, a convex function of a martingale is a submartingale. Similarly, a convex and nondecreasing function of a submartingale is also submartingale. Examples of convex functions are
   <math display="inline">
    \max(x-k,0)
   </math>
   for constant k,
   <math display="inline">
    |x|^p
   </math>
   for
   <math display="inline">
    p\geq 1
   </math>
   and
   <math display="inline">
    e^{\theta x}
   </math>
   for constant
   <math display="inline">
    \theta
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Example 5
   </b>
   (Martingale Transforms). Let
   <math display="inline">
    X
   </math>
   be a martingale with respect to the filtration
   <math display="inline">
    \mathbb{F}
   </math>
   and
   <math display="inline">
    H
   </math>
   be a
   <i>
    predictable process
   </i>
   with respect to
   <math display="inline">
    \mathbb{F}
   </math>
   , that is,
   <math display="inline">
    H_n
   </math>
   is
   <math display="inline">
    \mathcal{F}_{n-1}
   </math>
   -measurable for
   <math display="inline">
    n \geq 1
   </math>
   , where
   <math display="inline">
    \mathcal{F}_0 = \{\emptyset, \Omega\}
   </math>
   . A martingale transform of
   <math display="inline">
    X
   </math>
   by
   <math display="inline">
    H
   </math>
   is defined by
  </p>
  <p block-type="Equation">
   <math display="block">
    \left(H \cdot X\right)_n = H_0 X_0 + \sum_{i=1}^n H_i (X_i - X_{i-1}) \quad (6)
   </math>
  </p>
  <p block-type="TextInlineMath">
   where the expression
   <math display="inline">
    H \cdot X
   </math>
   is the discrete analog of the stochastic integral
   <math display="inline">
    \int H \, dX
   </math>
   . If
   <math display="inline">
    \mathbb{E}|(H \cdot X)_n| &lt; \infty
   </math>
   for
   <math display="inline">
    n &gt; 1
   </math>
   , then
   <math display="inline">
    (H \cdot X)_n
   </math>
   is a martingale with respect to
   <math display="inline">
    \mathbb{F}
   </math>
   . The interpretation is that in a fair game X, if we choose our bet at each stage on the basis of the prior history, that is, the bet
   <math display="inline">
    H_n
   </math>
   for the
   <i>
    n
   </i>
   th gamble only depends on
   <math display="inline">
    \{X_0, X_1, \ldots, X_{n-1}\}
   </math>
   , then the game will continue to be fair. If
   <math display="inline">
    X_n
   </math>
   is the asset price at time
   <i>
    n
   </i>
   and
   <math display="inline">
    H_n
   </math>
   is the number of shares of the assets held by the investor during the time period from time
   <math display="inline">
    n
   </math>
   until time
   <math display="inline">
    n + 1
   </math>
   , more precisely, for the time interval
   <math display="inline">
    [n, n + 1)
   </math>
   , then
   <math display="inline">
    (H \cdot X)_n
   </math>
   is the total gain (or loss) up to time
   <math display="inline">
    n
   </math>
   (the value of the portfolio at time
   <math display="inline">
    n
   </math>
   with the trading strategy
   <math display="inline">
    H
   </math>
   ).
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   A random variable
   <math display="inline">
    T
   </math>
   taking values in
   <math display="inline">
    \{0, 1, 2,
   </math>
   <math display="inline">
    \ldots; \infty
   </math>
   is a
   <i>
    stopping time T
   </i>
   with respect to a filtration
   <math display="inline">
    \mathbb{F} = \{ \mathcal{F}_n \mid n = 0, 1, 2, \ldots \}
   </math>
   , if for each
   <i>
    n
   </i>
   , the
  </p>
  <p block-type="TextInlineMath">
   event
   <math display="inline">
    \{T = n\}
   </math>
   is
   <math display="inline">
    \mathcal{F}_n
   </math>
   -measurable, or equivalently, the event
   <math display="inline">
    \{T \le n\}
   </math>
   is
   <math display="inline">
    \mathcal{F}_n
   </math>
   -measurable. If S and T are stopping times, then
   <math display="inline">
    S + T
   </math>
   ,
   <math display="inline">
    S \vee T = \max(S, T)
   </math>
   , and
   <math display="inline">
    S \wedge T = \min(S, T)
   </math>
   are all stopping times. Particularly,
   <math display="inline">
    T \wedge n
   </math>
   is a bounded stopping time for any fixed time
   <i>
    n
   </i>
   .
   <math display="inline">
    X_n^T =: X_{T \wedge n}
   </math>
   is said to be the
   <i>
    process
   </i>
   <b>
    X
   </b>
   stopped at
   <math display="inline">
    \ddot{T}
   </math>
   , since on the event
   <math display="inline">
    \{\omega | T(\omega) = k\}
   </math>
   ,
   <math display="inline">
    X_n^T = X_k
   </math>
   for
   <math display="inline">
    n = k, k + 1, \ldots
   </math>
  </p>
  <h1>
   Doob's Optional Stopping Theorem
  </h1>
  <p block-type="Text">
   Let
   <math display="inline">
    X
   </math>
   be a martingale and
   <math display="inline">
    T
   </math>
   be a bounded stopping time with respect to the same filtration
   <math display="inline">
    \mathbb{F}
   </math>
   , then
   <math display="inline">
    \mathbb{E}[X_T] = \mathbb{E}[X_0]
   </math>
   . Conversely, for an adapted process X, if
   <math display="inline">
    \mathbb{E}[|X_T|] &lt; \infty
   </math>
   and
   <math display="inline">
    \mathbb{E}[X_T] = \mathbb{E}[X_0]
   </math>
   hold for all bounded stopping time
   <math display="inline">
    T
   </math>
   , then
   <math display="inline">
    X
   </math>
   is a martingale. This theorem says roughly that stopping a martingale at a stopping time
   <math display="inline">
    T
   </math>
   does not alter its expectation, provided that the decision when to stop is based only on information available up to time
   <math display="inline">
    T
   </math>
   . The theorem also shows that a martingale stopped at a stopping time is still a martingale, and there is no way to be sure to win in a fair game if the stopping time is bounded.
  </p>
  <h4>
   <b>
    Continuous-time Martingales
   </b>
  </h4>
  <p block-type="TextInlineMath">
   A continuous-time stochastic process
   <math display="inline">
    X
   </math>
   on filtered probability space
   <math display="inline">
    (\Omega, \mathcal{F}, \mathbb{F}, \mathbb{P})
   </math>
   is a collection of random variables
   <math display="inline">
    X = \{X_t : 0 &lt; t &lt; \infty\}
   </math>
   , where
   <math display="inline">
    X_t
   </math>
   is a random variable observed at time t, and the filtration
   <math display="inline">
    \mathbb{F} = \{ \mathcal{F}_t : 0 \le t \le \infty \}
   </math>
   , which is a family of increasing
   <math display="inline">
    \sigma
   </math>
   -algebras,
   <math display="inline">
    \mathcal{F}_s \subseteq \mathcal{F}_t \subseteq \mathcal{F}
   </math>
   for
   <math display="inline">
    s \leq t
   </math>
   . A process
   <i>
    X
   </i>
   is said to be
   <i>
    adapted
   </i>
   if
   <math display="inline">
    X_t
   </math>
   is
   <math display="inline">
    \mathcal{F}_t
   </math>
   measurable for each
   <math display="inline">
    t
   </math>
   . A random variable
   <math display="inline">
    T
   </math>
   taking values in
   <math display="inline">
    [0, \infty]
   </math>
   is called a
   <i>
    stopping time
   </i>
   , if the event
   <math display="inline">
    \{T \le t\}
   </math>
   is
   <math display="inline">
    \mathcal{F}_t
   </math>
   measurable for each t. The stopping time
   <math display="inline">
    \sigma
   </math>
   <i>
    algebra
   </i>
   <math display="inline">
    \mathcal{F}_T
   </math>
   is defined to be
   <math display="inline">
    \mathcal{F}_T = \{A \in \mathcal{F} \mid A \cap \{T \leq T\}
   </math>
   <math display="inline">
    t \in \mathcal{F}_t
   </math>
   , all
   <math display="inline">
    t \ge 0
   </math>
   , which represents the information up to the stopping time
   <math display="inline">
    T
   </math>
   .
  </p>
  <p block-type="Text">
   A real-valued, adapted process
   <math display="inline">
    X
   </math>
   is called a continuous-time
   <i>
    martingale
   </i>
   (respectively
   <i>
    supermartingale
   </i>
   ,
   <i>
    submartingale
   </i>
   ) with respect to the filtration
   <math display="inline">
    \mathbb{F}
   </math>
   if
  </p>
  <p block-type="TextInlineMath">
   1.
   <math display="inline">
    \mathbb{E}[|X_t|] &lt; \infty
   </math>
   , for
   <math display="inline">
    t &gt; 0
   </math>
   (7)
  </p>
  <p block-type="Equation">
   2.
   <math display="block">
    \mathbb{E}[X_t|\mathcal{F}_s] = X_s \text{ (respectively } \leq X_s, \geq X_s),
   </math>
  </p>
  <p block-type="Equation">
   a.s. for any
   <math display="block">
    0 \le s \le t
   </math>
   (8)
  </p>
  <p block-type="Text">
   Continuous-time martingales have the same properties as discrete-time martingales. For example, Doob's optional stopping theorem says that for a martingale
   <math display="inline">
    X_t
   </math>
   with right continuous paths, which is closed in
   <math display="inline">
    \mathbf{L}^1
   </math>
   by a random variable
   <math display="inline">
    X_{\infty}
   </math>
   , we have
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}[X_T|\mathcal{F}_S] = X_S \quad \text{a.s. for any two stopping times} 0 &lt; S &lt; T \tag{9}
   </math>
  </p>
  <p block-type="Text">
   The most important continuous-time martingale is Brownian motion, which was named for the Scottish botanist Robert Brown, who, in 1827, observed ceaseless and irregular movement of pollen grains suspended in water. It was studied by Albert Einstein in 1905 at the level of modern physics. Its mathematical model was first rigorously constructed in 1923 by Norbert Wiener. Brownian motion is also called a Wiener process. The Wiener process gave rise to the study of continuous-time martingales, and has been an example that helps mathematicians to understand stochastic calculus and diffusion processes.
  </p>
  <p block-type="TextInlineMath">
   It was Louis Bachelier (1870-1946), now recognized as the founder of mathematical finance (see [9]), who first, in 1900, used Brownian motion
   <math display="inline">
    B
   </math>
   to model short-term stock prices
   <math display="inline">
    S_t
   </math>
   at a time t in financial markets, that is,
   <math display="inline">
    S_t = S_0 + \sigma B_t
   </math>
   , where
   <math display="inline">
    \sigma &gt; 0
   </math>
   is a constant. Now we can see that if Brownian motion B is defined on
   <math display="inline">
    (\Omega, \mathcal{F}, \mathbb{F}, \mathbb{P})
   </math>
   , then the price process S is a martingale under the probability measure
   <math display="inline">
    \mathbb{P}
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   In 1965, the American economist Paul Samuelson rediscovered Bachelier's ideas and proposed the geometric Brownian motion
   <math display="inline">
    S_0 \exp\{(\mu - (\sigma^2/2))t +
   </math>
   <math display="inline">
    \sigma B_t
   </math>
   as a model for long-term stock prices
   <math display="inline">
    S_t
   </math>
   . That is,
   <math display="inline">
    S_t
   </math>
   follows the stochastic differential equation (SDE):
   <math display="inline">
    dS_t = \mu S_t dt + \sigma S_t dB_t
   </math>
   . From this simple structure, we get the famous Black-Scholes option price formulas for European calls and puts. This SDE is now called the Black-Scholes equation (model). Contrary to Bachelier's setting, the price process
   <math display="inline">
    S
   </math>
   is not a martingale under
   <math display="inline">
    \mathbb{P}
   </math>
   . However, by Girsanov's theorem, there is a unique probability measure
   <math display="inline">
    \mathbb{Q}
   </math>
   , which is equivalent to
   <math display="inline">
    \mathbb{P}
   </math>
   , such that the discounted stock price
   <math display="inline">
    e^{-rt}S_t
   </math>
   is a martingale under
   <math display="inline">
    \mathbb{Q}
   </math>
   for
   <math display="inline">
    0 \le t \le T
   </math>
   , where r is the riskless rate of interest, and
   <math display="inline">
    T &gt; 0
   </math>
   is a fixed constant.
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   The reality is not as simple as the above linear SDE. A simple generalization is
   <math display="inline">
    dS_t = \mu(t, S_t) dt +
   </math>
   <math display="inline">
    \sigma(t, S_t)
   </math>
   dB&lt;sub&gt;t&lt;/sub&gt;. If one believes that risky asset prices
  </p>
  <p block-type="Text">
   have jumps, an appropriate model might be
  </p>
  <p block-type="Equation">
   <math display="block">
    dS_t = \mu(t, S_t) dt + \sigma(t, S_t) dB_t + J(t, S_t) dN_t
   </math>
   (10)
  </p>
  <p block-type="TextInlineMath">
   where N is a Poisson process with intensity
   <math display="inline">
    \lambda
   </math>
   ,
   <math display="inline">
    J(t, S_t)
   </math>
   refers to the jump size, and N indicates when the jumps occur. Since
   <math display="inline">
    N
   </math>
   is a counting (pure jump) process with independent and stationary increments, both
   <math display="inline">
    N_t - \lambda t
   </math>
   and
   <math display="inline">
    (N_t - \lambda t)^2 - \lambda t
   </math>
   are martingales. For a more general model, we could replace
   <math display="inline">
    N
   </math>
   by a Lévy process that includes the Brownian motion and Poisson process as special cases.
  </p>
  <p block-type="TextInlineMath">
   Under these general mathematical models, it becomes hard to turn the fundamental principle of asset pricing into a precise mathematical theorem: the absence of arbitrage possibilities for a stochastic process S, a
   <i>
    semimartingale
   </i>
   defined on
   <math display="inline">
    (\Omega, \mathcal{F}, \mathbb{F}, \mathbb{P})
   </math>
   , is equivalent to the existence of an equivalent measure
   <math display="inline">
    \mathbb{Q}
   </math>
   , under which S is a
   <i>
    local martingale
   </i>
   , sometimes, a sigma martingale. See [2] or [3].
  </p>
  <h1>
   <b>
    Local Martingales and Finite Variation
   </b>
   Processes
  </h1>
  <p block-type="Text">
   There are two types of processes with only jump discontinuities. A process is said to be càdlàg if it almost surely (a.s.) has sample paths that are right continuous, with left limits. A process is said to be
   <i>
    càglàd
   </i>
   if it almost surely has sample paths that are left continuous, with right limits. The words càdlàg and càglàd are acronyms from the French for
   <i>
    continu
   </i>
   à droite, limites à gauche, and continu à gauche,
   <i>
    limites à droite
   </i>
   , respectively. Let
  </p>
  <p block-type="Text">
   <math display="inline">
    \mathbb{D}
   </math>
   = the space of adapted processes
  </p>
  <p block-type="Text">
   with càdlàg paths
  </p>
  <p block-type="Text">
   <math display="inline">
    \mathbb{L}
   </math>
   = the space of adapted processes
  </p>
  <p block-type="Equation">
   with càglàd paths
   <math display="block">
    (11)
   </math>
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   An adapted, càdlàg process
   <math display="inline">
    A
   </math>
   is called a
   <i>
    finite variation
   </i>
   (FV) process if sup
   <math display="inline">
    \sum_{i=1}^{N} |A_{t_i} - A_{t_{i-1}}|
   </math>
   is bounded almost surely for each constant
   <math display="inline">
    t &gt; 0
   </math>
   , where the supremum is taken over the set of all partitions
   <math display="inline">
    0 = t_0 \le t_1 \le \cdots \le t_N = t
   </math>
   . An FV process is a difference of two increasing processes. Although the Brownian motion
   <math display="inline">
    B
   </math>
   has continuous paths, it has
  </p>
  <p block-type="Text">
   paths of
   <i>
    infinite variation
   </i>
   on
   <math display="inline">
    [0, t]
   </math>
   , which prevents us from defining the stochastic integral
   <math display="inline">
    \int H \, dB
   </math>
   as a Riemann-Stieltjes integral, path by path.
  </p>
  <p block-type="TextInlineMath">
   An adapted, càdlàg process
   <math display="inline">
    M
   </math>
   is called a
   <i>
    local martingale
   </i>
   with respect to a filtration
   <math display="inline">
    \mathbb{F}
   </math>
   if there exists a sequence of increasing stopping time
   <math display="inline">
    T_n
   </math>
   with
   <math display="inline">
    \lim_{n\to\infty} T_n = \infty
   </math>
   almost surely, such that for each
   <math display="inline">
    n
   </math>
   ,
   <math display="inline">
    M_{t \wedge T_n}
   </math>
   is a martingale. A similar concept is that a function is
   <i>
    locally bounded
   </i>
   : for example,
   <math display="inline">
    1/t
   </math>
   is not bounded over
   <math display="inline">
    (0, 1]
   </math>
   , but it is bounded on the interval
   <math display="inline">
    [1/n, 1]
   </math>
   for any integer n. A process moving very rapidly though with continuous paths, or jumping unboundedly and frequently, might not be a martingale. However, we could modify it to be a martingale by stopping it properly, that is, it is a martingale up to a stopping time, but may not be a martingale for all time.
  </p>
  <p block-type="TextInlineMath">
   The class of local martingales includes martingales as special cases. For example, if for every
   <math display="inline">
    t &gt;
   </math>
   0,
   <math display="inline">
    \mathbb{E}\{\sup_{s\leq t}|M_{s}|\}&lt;\infty
   </math>
   , then
   <i>
    M
   </i>
   is a martingale; if for all
   <math display="inline">
    t &gt; 0
   </math>
   ,
   <math display="inline">
    \mathbb{E}\{[M, M]_t\} &lt; \infty
   </math>
   , then M is a martingale, and
   <math display="inline">
    \mathbb{E}\{M_t^2\} = \mathbb{E}\{[M, M]_t\}
   </math>
   . Conversely, if M is a martingale with
   <math display="inline">
    \mathbb{E}\{M_t^2\} &lt; \infty
   </math>
   for all
   <math display="inline">
    t &gt; 0
   </math>
   , then
   <math display="inline">
    \mathbb{E}\{[M, M]_t\} &lt; \infty
   </math>
   for all
   <math display="inline">
    t &gt; 0
   </math>
   . For the definition of quadratic variation
   <math display="inline">
    [M, M]_t
   </math>
   , see equation (14) in the next section.
  </p>
  <p block-type="TextInlineMath">
   Not all local martingales are martingales. Here is a typical
   <i>
    example
   </i>
   of a local martingale, but not a martingale. Lots of continuous-time martingales, supermartingales, and submartingales can be constructed from Brownian motion, since it has independent and stationary increments and it can be approximated by a random walk. For example, let
   <math display="inline">
    B
   </math>
   be a standard Brownian motion in
   <math display="inline">
    \mathbb{R}^3
   </math>
   with
   <math display="inline">
    B_0 = x \neq 0
   </math>
   . Let
   <math display="inline">
    u(y) = ||y||^{-1}
   </math>
   , be a
   <i>
    superharmonic
   </i>
   function on
   <math display="inline">
    \mathbb{R}^3
   </math>
   .
   <math display="inline">
    M_t = u(B_t)
   </math>
   is a positive supermartingale. Since
   <math display="inline">
    \lim_{t\to\infty}\sqrt{t}\ \mathbb{E}\{M_t\}=\sqrt{\pi}
   </math>
   and
   <math display="inline">
    \mathbb{E}\{M_0\}=u(x), M
   </math>
   does not have constant expectations and it cannot be a martingale.
   <math display="inline">
    M
   </math>
   is known as the inverse Bessel Process. For each n, we define a stopping time
   <math display="inline">
    T_n =
   </math>
   <math display="inline">
    \inf\{t&gt;0: \|B_t\| &lt; 1/n\}
   </math>
   . Since the function u is har
   <i>
    monic
   </i>
   outside of the ball of radius
   <math display="inline">
    1/n
   </math>
   centered at the origin, the process
   <math display="inline">
    \{M_{t \wedge T_n} : t \ge 0\}
   </math>
   is a martingale for each
   <math display="inline">
    n
   </math>
   . Therefore,
   <math display="inline">
    M
   </math>
   is a local martingale.
  </p>
  <h1>
   Semimartingales and Stochastic Integrals
  </h1>
  <p block-type="Text" class="has-continuation">
   Today stocks and bonds are traded globally almost 24 hours a day, and online trading happens every second.
  </p>
  <p block-type="Text">
   When trading takes place almost continuously, it is simpler to use a continuous-time stochastic processes to model the price
   <math display="inline">
    X
   </math>
   . The value of the portfolio at time
   <math display="inline">
    t
   </math>
   with the continuous-time trading strategy
   <math display="inline">
    H
   </math>
   becomes the limit of sums as shown in the martingale transform
   <math display="inline">
    (H \cdot X)_n
   </math>
   in equation (6), that is, the stochastic integral
   <math display="inline">
    \int_0^t H_s \, dX_s
   </math>
   . Stochastic calculus is more complicated than regular calculus because
   <math display="inline">
    X
   </math>
   can have paths of infinite variation, especially when
   <math display="inline">
    X
   </math>
   has unbounded jumps, for example, when
   <math display="inline">
    X
   </math>
   is Brownian motion, a continuous-time martingale, or a local martingale. For stochastic integration theory, see
   <b>
    Stochastic Integrals
   </b>
   or consult [8, 11] and [12], and other texts.
  </p>
  <p block-type="TextInlineMath">
   Let
   <math display="inline">
    0 = T_1 \leq \cdots \leq T_{n+1} &lt; \infty
   </math>
   be a sequence of stopping times and
   <math display="inline">
    H_i \in \mathcal{F}_{T_i}
   </math>
   with
   <math display="inline">
    |H_i| &lt; \infty
   </math>
   . A process
   <math display="inline">
    H
   </math>
   with a representation
  </p>
  <p block-type="Equation">
   <math display="block">
    H_{t} = H_{0}\mathbf{1}_{\{0\}}(t) + \sum_{i=1}^{n} H_{i}\mathbf{1}_{(T_{i}, T_{i+1})}(t)
   </math>
   (12)
  </p>
  <p block-type="TextInlineMath">
   is called a
   <i>
    simple predictable process
   </i>
   . A collection of simple predictable processes is denoted by
   <math display="inline">
    S
   </math>
   . For a process
   <math display="inline">
    X \in \mathbb{D}
   </math>
   and
   <math display="inline">
    H \in \mathbb{S}
   </math>
   having the representation
   <math display="inline">
    (12)
   </math>
   , we define a linear mapping as the martingale transforms in equation (6) in the discretetime case
  </p>
  <p block-type="Equation">
   <math display="block">
    (H \cdot X)_t = H_0 X_0 + \sum_{i=1}^n H_i (X_{t \wedge T_{i+1}} - X_{t \wedge T_i}) \quad (13)
   </math>
  </p>
  <p block-type="TextInlineMath">
   If for any
   <math display="inline">
    H \in \mathbf{S}
   </math>
   and each
   <math display="inline">
    t \geq 0
   </math>
   , the sequence of random variables
   <math display="inline">
    (H^n \cdot X)_t
   </math>
   converges to
   <math display="inline">
    (H \cdot
   </math>
   <math display="inline">
    (X)_t
   </math>
   in probability, whenever
   <math display="inline">
    H^n \in \mathbf{S}
   </math>
   converges to
   <math display="inline">
    H
   </math>
   uniformly, then
   <math display="inline">
    X
   </math>
   is called a
   <i>
    semimartingale
   </i>
   . For example, an FV process, a local martingale with continuous paths, and a Lévy process are all semimartingales.
  </p>
  <p block-type="TextInlineMath">
   Since the space
   <b>
    S
   </b>
   is dense in
   <math display="inline">
    \mathbb{L}
   </math>
   , for any
   <math display="inline">
    H \in \mathbb{L}
   </math>
   , there exists
   <math display="inline">
    H_n \in \mathbf{S}
   </math>
   such that
   <math display="inline">
    H_n
   </math>
   converges to
   <math display="inline">
    H
   </math>
   . For a semimartingale X and a process
   <math display="inline">
    H \in \mathbb{L}
   </math>
   , the
   <i>
    stochastic integral
   </i>
   <math display="inline">
    \int H \, dX
   </math>
   , also denoted by
   <math display="inline">
    (H \cdot X)
   </math>
   , is defined by
   <math display="inline">
    \lim_{n\to\infty}(H^n\cdot X)
   </math>
   . For any
   <math display="inline">
    H\in\mathbb{L},\ H\cdot X
   </math>
   is a semimartingale, it is an FV process if
   <math display="inline">
    X
   </math>
   is, and it is a local martingale if X is. But
   <math display="inline">
    H \cdot X
   </math>
   may not be a martingale even if
   <math display="inline">
    X
   </math>
   is.
   <math display="inline">
    H \cdot X
   </math>
   is a martingale if X is a local martingale and
   <math display="inline">
    \mathbb{E}\{\int_0^t H_s^2 d[X,X]_s\} &lt; \infty
   </math>
   for each
   <math display="inline">
    t &gt; 0
   </math>
   .
  </p>
  <p block-type="Text">
   For a semimartingale
   <math display="inline">
    X
   </math>
   , its
   <i>
    quadratic variation
   </i>
   <math display="inline">
    [X, X]
   </math>
   is defined by
  </p>
  <p block-type="Equation">
   <math display="block">
    [X, X]_t = X_t^2 - 2 \int_0^t X_{s-} \, \mathrm{d} X_s \tag{14}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    X_{s-}
   </math>
   denotes the left limit at s. Let
   <math display="inline">
    [X, X]^c
   </math>
   denote the path-by-path continuous part of
   <math display="inline">
    [X, X]
   </math>
   , and
   <math display="inline">
    \Delta X_s = X_s - X_{s-}
   </math>
   be the jump of X at s, then
   <math display="inline">
    [X, X]_t = [X, X]_t^c + \sum_{0 \le s \le t} (\Delta X_s)^2
   </math>
   . For an FV process
   <math display="inline">
    X
   </math>
   ,
   <math display="inline">
    [X, X]_t = \sum_{0 \le s \le t} (\bar{\Delta}X_s)^2
   </math>
   . In particular, if
   <math display="inline">
    X
   </math>
   is an FV process with continuous paths, then
   <math display="inline">
    [X, X]_t = X_0^2
   </math>
   for all
   <math display="inline">
    t \ge 0
   </math>
   . For a continuous local martingale X, then
   <math display="inline">
    X^2 - [X, X]_t
   </math>
   is a continuous local martingale. Moreover, if
   <math display="inline">
    [X, X]_t = X_0^2
   </math>
   for all t, then
   <math display="inline">
    X_t = X_0
   </math>
   for all t; in other words, if an FV process is also a continuous local martingale, then it is a constant process.
  </p>
  <h1>
   Lévy's Characterization of Brownian Motion
  </h1>
  <p block-type="TextInlineMath">
   A process
   <math display="inline">
    X
   </math>
   is a standard Brownian motion if and only if it is a continuous local martingale with
   <math display="inline">
    [X, X]_t = t.
   </math>
  </p>
  <p block-type="TextInlineMath">
   The theory of stochastic integration for integrands in
   <math display="inline">
    \mathbb{L}
   </math>
   is sufficient to establish Itô's formula, the Girsanov-Meyer theorem, and to study SDEs. For example, the
   <i>
    stochastic exponential
   </i>
   of a semimartingale
   <math display="inline">
    X
   </math>
   with
   <math display="inline">
    X_0 = 0
   </math>
   , written
   <math display="inline">
    \mathcal{E}(X)
   </math>
   , is the unique semimartingale Z that is a solution of the linear SDE:
   <math display="inline">
    Z_t =
   </math>
   <math display="inline">
    1 + \int_0^t Z_{s-} dX_s
   </math>
   . When X is a continuous local martingale, so is
   <math display="inline">
    \mathcal{E}(X)_t = \exp\{X_t - \frac{1}{2}[X,X]_t\}
   </math>
   . Furthermore, if
   <i>
    Kazamaki's Criterion
   </i>
   sup&lt;sub&gt;T&lt;/sub&gt;
   <math display="inline">
    \mathbb{E}\{\exp(\frac{1}{2}X_T)\}\
   </math>
   <math display="inline">
    \infty
   </math>
   holds, where the supremum is taken over all bounded stopping times, or if
   <i>
    Novikov's Criterion
   </i>
   <math display="inline">
    \mathbb{E}\{\exp(\frac{1}{2}[X,X]_{\infty})\} &lt; \infty
   </math>
   holds (stronger but easier to check in practice), then
   <math display="inline">
    \mathcal{E}(X)
   </math>
   is a martingale. See [10] for more on these conditions. When
   <math display="inline">
    X
   </math>
   is Brownian motion,
   <math display="inline">
    \mathcal{E}(X) = \exp\{X_t - \frac{1}{2}t\}
   </math>
   is referred to as geometric Brownian motion.
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   The space of integrands
   <math display="inline">
    \mathbb{L}
   </math>
   is not general enough to have
   <i>
    local times
   </i>
   and martingale representation theory, which is essential for hedging in finance. On the basis of the
   <i>
    Bichteler–Dellacherie theorem
   </i>
   ,
   <math display="inline">
    X
   </math>
   is a semimartingale if and only if
   <math display="inline">
    X = M + A
   </math>
   , where M is a local martingale and
   <math display="inline">
    A
   </math>
   is an FV process, we can extend the stochastic integration from
   <math display="inline">
    \mathbb{L}
   </math>
   to the space
   <math display="inline">
    \mathcal{P}
   </math>
   of predictable processes, which are measurable with respect to
   <math display="inline">
    \sigma\{H: H \in \mathbb{L}\}
   </math>
   . For a semimartingale
  </p>
  <p block-type="TextInlineMath">
   <math display="inline">
    X
   </math>
   , if a predictable
   <math display="inline">
    H
   </math>
   is
   <math display="inline">
    X
   </math>
   integrable, that is, we can define the stochastic integral
   <math display="inline">
    H \cdot X
   </math>
   , then we write
   <math display="inline">
    H \in L(X)
   </math>
   (see chapter 4 of [8]). If
   <math display="inline">
    H \in \mathcal{P}
   </math>
   is locally bounded then
   <math display="inline">
    H \in L(X)
   </math>
   and
   <math display="inline">
    H \cdot X
   </math>
   is a local martingale if X is. However, if
   <math display="inline">
    H \in \mathcal{P}
   </math>
   is not locally bounded or
   <math display="inline">
    H \notin \mathbb{L}
   </math>
   , then
   <math display="inline">
    H \cdot X
   </math>
   may not be a local martingale even if X is an
   <math display="inline">
    L^2
   </math>
   martingale. For such an example due to M. Émery, see pp 152 of [5] or pp 176 of [8]. If
   <math display="inline">
    X
   </math>
   is a local martingale and
   <math display="inline">
    H \in L(X)
   </math>
   , then
   <math display="inline">
    H \cdot X
   </math>
   is a sigma martingale.
  </p>
  <h3>
   <b>
    Sigma Martingales
   </b>
  </h3>
  <p block-type="Text">
   The concept of a sigma martingale was introduced by Chou [1] and further analyzed by Émery [5]. It has seen a revival in popularity owing to Delbaen and Schachermayer [2]; see [8] for a more detailed treatment. Sigma martingales relate to martingales analogously as sigma-finite measures relate to finite measures. A sigma martingale, which may not be a local martingale, has the essential features of a martingale.
  </p>
  <p block-type="TextInlineMath">
   A semimartingale
   <math display="inline">
    X
   </math>
   is called a
   <i>
    sigma martingale
   </i>
   if there exists a martingale
   <math display="inline">
    M
   </math>
   and a nonnegative
   <math display="inline">
    H \in \mathcal{P}
   </math>
   such that
   <math display="inline">
    X = H \cdot M
   </math>
   , or, equivalently, if there exists a nonnegative
   <math display="inline">
    H \in \mathcal{P}
   </math>
   such that
   <math display="inline">
    H \cdot X
   </math>
   is a martingale.
  </p>
  <p block-type="TextInlineMath">
   A local martingale is a sigma martingale, but a sigma martingale with large jumps might fail to be a local martingale. If
   <math display="inline">
    X
   </math>
   is a sigma martingale and if either
   <math display="inline">
    \sup_{s \le t} |X_s|
   </math>
   or
   <math display="inline">
    \sup_{s \le t} |\Delta X_s|
   </math>
   is
   <i>
    locally integrable
   </i>
   (for example,
   <math display="inline">
    X
   </math>
   has continuous paths or bounded jumps), then
   <math display="inline">
    X
   </math>
   is a local martingale. If
   <math display="inline">
    X
   </math>
   is a sigma martingale and
   <math display="inline">
    H \in L(X)
   </math>
   , then
   <math display="inline">
    H \cdot X
   </math>
   is always a sigma martingale.
  </p>
  <p block-type="Text">
   The concept of a sigma martingale is new in the context of mathematical finance. It was introduced to deal with possibly unbounded jumps of the asset price process
   <math display="inline">
    X
   </math>
   . When we consider the process
   <math display="inline">
    X
   </math>
   with jumps, it is often convenient to assume the jumps to be unbounded, for example, the Lévy processes and the family of ARCH, GARCH processes. If the conditional distribution of jumps is Gaussian, then the process is not locally bounded. In that case, the concept of a sigma martingale is unavoidable. On the other hand, if we are only interested in how to price and hedge some contingent claims, not the underlying assets
   <math display="inline">
    X
   </math>
   , then it might not be necessary to require the asset price
   <math display="inline">
    X
   </math>
   to be a (local) martingale
  </p>
  <p block-type="Text">
   and it suffices to require
   <math display="inline">
    H \cdot X
   </math>
   to be a martingale for some
   <math display="inline">
    H
   </math>
   , that is,
   <math display="inline">
    X
   </math>
   is a sigma martingale. Moreover, nonnegative sigma martingales are local martingales, so in particular for stock prices, we do need to consider sigma martingales.
  </p>
  <p block-type="Text">
   Finally, we cite two fundamental theorems of asset
   <i>
    pricing
   </i>
   from chapters 8 and 14 of [3] to see why we need sigma martingales in mathematical finance.
  </p>
  <p block-type="Text">
   <b>
    Theorem 1
   </b>
   Let the discounted price process S be
   <i>
    a locally bounded semimartingale defined on
   </i>
   <math display="inline">
    (\Omega,
   </math>
   <math display="inline">
    \mathcal{F}, \mathbb{F}, \mathbb{P})
   </math>
   . Then there exists a probability measure
   <math display="inline">
    \mathbb{Q}
   </math>
   (equivalent to
   <math display="inline">
    \mathbb{P}
   </math>
   ) under which S is a local martingale, if and only if
   <math display="inline">
    S
   </math>
   satisfies the condition of no free lunch with vanishing risk (NFLVR).
  </p>
  <p block-type="Text">
   Here the concept of NFLVR is a mild strengthening of the concept of no arbitrage, which is introduced by Delbaen and Schachermayer in [2].
  </p>
  <p block-type="Text">
   <b>
    Theorem 2
   </b>
   If we assume that
   <math display="inline">
    S
   </math>
   is a nonlocally bounded semimartingale, then we have a general theorem by replacing the term "local martingale" by the term "sigma martingale" in Theorem 1 above. However if
   <math display="inline">
    S \ge 0
   </math>
   , then "local martingale" suffices, because sigma martingales bounded below are a priori local martingales.
  </p>
  <h2>
   Conclusion
  </h2>
  <p block-type="Text">
   A local martingale is a martingale up to a sequence of stopping times that goes to
   <math display="inline">
    \infty
   </math>
   , while a sigma martingale is a countable sum (a mixture) of martingales.
  </p>
  <h4>
   References
  </h4>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     <math display="inline">
      [1]
     </math>
     Chou, C.S. (1977). Caractérisation d'une classe de semimartingales, Séminaire de Probabilit és XIII, LNM, Vol. 721, Springer, pp. 250-252.
    </li>
    <li block-type="ListItem">
     [2] Delbaen, F. &amp; Schachermayer, W. (1998). The Fundamental Theorem of Asset Pricing for Unbounded Stochastic Processes, Mathematicsche Annalen, Vol. 312, Springer, pp. 215-250.
    </li>
    <li block-type="ListItem">
     Delbaen, F. &amp; Schachermayer, W. (2006). The Mathe-[3] matics of Arbitrage, Springer Finance Series, Springer-Verlag, New York.
    </li>
    <li block-type="ListItem">
     [4] Dellacherie, C. &amp; Meyer, P.A. (1982). Probabilities and Potential, Vol. 29 of North-Holland Mathematics Studies, North-Holland, Amsterdam.
    </li>
    <li block-type="ListItem">
     [5] Émery, M. (1980). Compensation de processus à variation finie non localement int'egrales., Séminaire de Probabilités XIV, LNM, Vol. 784, Springer, pp. 152-160.
    </li>
   </ul>
  </p>
 </body>
</html>
