<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
 </head>
 <body>
  <h1>
   <b>
    Stochastic Integrals
   </b>
  </h1>
  <p block-type="Text">
   If
   <math display="inline">
    H_t
   </math>
   represents the number of shares of a certain asset held by an investor and
   <math display="inline">
    X_t
   </math>
   denotes the price of the asset, the gain on
   <math display="inline">
    [0, t]
   </math>
   from the trading strategy
   <math display="inline">
    H
   </math>
   is often represented as
  </p>
  <p block-type="Equation">
   <math display="block">
    \int_0^t H_t \, \mathrm{d}X_t \tag{1}
   </math>
  </p>
  <p block-type="Text">
   Here, our goal is to give a precise meaning to such "stochastic integrals", where
   <math display="inline">
    H
   </math>
   and
   <math display="inline">
    X
   </math>
   are stochastic processes verifying appropriate assumptions.
  </p>
  <p block-type="TextInlineMath">
   Looking at the time-series data for price evolution of, say, a stock, one realizes that placing smoothness assumptions, such as differentiability, on the paths of
   <math display="inline">
    X
   </math>
   would be unrealistic. Consequently, this puts us in a situation where the theory of ordinary integration is no longer sufficient for our purposes. In what follows, we construct the stochastic integral
   <math display="inline">
    \int H \, dX
   </math>
   for a class of integrands and integrators that are as large as possible while satisfying certain conditions. The stochastic processes that we use are defined on a complete probability space
   <math display="inline">
    (\Omega, \mathcal{F}, \mathbb{P})
   </math>
   . We always assume that all the processes are jointly measurable, that is, for any process
   <math display="inline">
    (Y_t)_{0 \le t &lt; \infty}
   </math>
   the map
   <math display="inline">
    (t, \omega) \mapsto
   </math>
   <math display="inline">
    Y_t(\omega)
   </math>
   is measurable with respect to
   <math display="inline">
    \mathcal{B}(\mathbb{R}_+) \times \mathcal{F}
   </math>
   , where
   <math display="inline">
    \mathcal{B}(\mathbb{R}_+)
   </math>
   is the Borel σ-algebra on [0, ∞). In addition, we are given a
   <i>
    filtration
   </i>
   <math display="inline">
    (\mathcal{F}_t)_{0 \le t \le \infty}
   </math>
   (see Filtrations), which models the accumulation of our information over time. The filtration
   <math display="inline">
    (\mathcal{F}_t)_{0 \le t \le \infty}
   </math>
   is usually denoted by
   <math display="inline">
    \mathbb{F}
   </math>
   for convenience. We say that a jointly measurable process,
   <math display="inline">
    Y
   </math>
   , is
   <i>
    adapted
   </i>
   (or
   <math display="inline">
    \mathbb{F}
   </math>
   <i>
    adapted
   </i>
   if we need to specify the filtration) if
   <math display="inline">
    Y_t \in \mathcal{F}_t
   </math>
   for all
   <math display="inline">
    t, 0 \le t &lt; \infty
   </math>
   . We assume that the following hypotheses hold true.
  </p>
  <h3>
   Assumption 1 The filtered complete probability space
   <math display="inline">
    (\Omega, \mathcal{F}, \mathbb{F}, \mathbb{P})
   </math>
   satisfies the usual hypotheses (see
   <b>
    Filtrations
   </b>
   )
  </h3>
  <p block-type="Text">
   Although the above hypotheses are restrictive, they are satisfied in many situations. The natural filtration of a Lévy process, in particular a Brownian motion, satisfies the usual hypotheses once completed. The same is true for the natural filtration of any counting process or "reasonable" strong Markov process (see, e.g., [7] for a more detailed discussion of the usual hypotheses and their consequences).
  </p>
  <p block-type="Text">
   Having fixed the stochastic base on which all the processes are defined, let us go back to our primary task of defining the integral
   <math display="inline">
    \int H \, dX
   </math>
   . If X is a process of finite variation, the theory is that of Lebesgue-Stieltjes integration.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 1
   </b>
   A stochastic process
   <math display="inline">
    X
   </math>
   is said to be càdlàg (for continu à droite, limites à gauche from French) if it a.s. has sample paths that are right con
   <i>
    tinuous on
   </i>
   <math display="inline">
    [0, \infty)
   </math>
   <i>
    with left limits on
   </i>
   <math display="inline">
    (0, \infty)
   </math>
   <i>
    . Similarly,
   </i>
   a stochastic process
   <math display="inline">
    X
   </math>
   is said to be càglàd (for continu à gauche, limites à droite) if it a.s. has sample paths that are left continuous on
   <math display="inline">
    (0,\infty)
   </math>
   with right limits on
   <math display="inline">
    [0, \infty)
   </math>
   . We denote the space of adapted, càdlàg (respectively, càglàd) processes by
   <math display="inline">
    \mathbb{D}
   </math>
   (respec
   <i>
    tively
   </i>
   ,
   <math display="inline">
    \mathbb{L}
   </math>
   ).
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 2
   </b>
   Let
   <math display="inline">
    X
   </math>
   be a càdlàg process. For a given
   <math display="inline">
    \omega \in \Omega
   </math>
   , the variation of the path
   <math display="inline">
    X(\omega)
   </math>
   on the compact interval
   <math display="inline">
    [a, b]
   </math>
   is defined as
  </p>
  <p block-type="Equation">
   <math display="block">
    \sup_{\pi \in P} \sum_{t_i \in \pi} \left| X_{t_{i+1}}(\omega) - X_{t_i}(\omega) \right| \tag{2}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    P
   </math>
   is the set of all finite partitions of
   <math display="inline">
    [a, b]
   </math>
   .
   <math display="inline">
    X
   </math>
   is said to be a finite variation
   <math display="inline">
    (FV)
   </math>
   process if X is
   <math display="inline">
    \dot{c}
   </math>
   àdlàg and almost all paths of
   <math display="inline">
    X
   </math>
   have finite variation on each compact interval of
   <math display="inline">
    [0, \infty)
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   If X is an FV process, for fixed
   <math display="inline">
    \omega
   </math>
   , it induces a signed measure on
   <math display="inline">
    \mathbb{R}_+
   </math>
   and thus we can define a jointly measurable integral
   <math display="inline">
    \int_0^t H_s(\omega) \, dX_s(\omega)
   </math>
   for any bounded and jointly measurable
   <math display="inline">
    H
   </math>
   . In other words, the integral
   <math display="inline">
    \int H \, dX
   </math>
   can be defined path by path as a Lebesgue-Stieltjes integral, if
   <math display="inline">
    H
   </math>
   is a jointly measurable process such that
   <math display="inline">
    \int_0^t H_s(\omega) \, dX_s(\omega)
   </math>
   exists and is finite for all
   <math display="inline">
    t &gt; 0
   </math>
   , a.s.
  </p>
  <p block-type="Text">
   Unfortunately, the set of FV processes is not rich enough if one wants to give a rigorous meaning to
   <math display="inline">
    \int H \, dX
   </math>
   using only Stieltjes integration. When we replace
   <math display="inline">
    X
   </math>
   with, say, a Brownian motion, the theory of Stieltjes integration fails to work since the Brownian motion is known to have paths of infinite variation in every compact interval of
   <math display="inline">
    \mathbb{R}_+
   </math>
   . Therefore, one needs to develop a concept of integration with respect to a class of processes that is large enough to cover processes such as the Brownian motion or the more general Lévy processes, which find frequent applications in different fields.
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   To find the weakest conditions on
   <math display="inline">
    X
   </math>
   so that
   <math display="inline">
    \int H \, dX
   </math>
   is well defined, we start with the simplest
  </p>
  <p block-type="Text">
   possible form for the integrand
   <math display="inline">
    H
   </math>
   and work gradually to extend the stochastic integral to more complex integrands by imposing conditions on
   <math display="inline">
    X
   </math>
   but making sure that these conditions are as minimal as possible at the same time.
  </p>
  <p block-type="Text">
   The simplest integrand one can think of is of the following form:
  </p>
  <p block-type="Equation">
   <math display="block">
    H_{t}(\omega) = \mathbf{1}_{(S(\omega), T(\omega)]}(t)
   </math>
   <br/>
   <math display="block">
    := \begin{cases} 1 &amp; \text{if } S(\omega) &lt; t \leq T(\omega) \\ 0 &amp; \text{otherwise} \end{cases}
   </math>
   (3)
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    S
   </math>
   and
   <math display="inline">
    T
   </math>
   are stopping times (see
   <b>
    Filtrations
   </b>
   ) with respect to
   <math display="inline">
    \mathbb{F}
   </math>
   . In financial terms, this corresponds to a buy-and-hold strategy, whereby one unit of the asset is bought at, possibly random, time
   <math display="inline">
    S
   </math>
   and sold at time
   <math display="inline">
    T
   </math>
   . If
   <math display="inline">
    X
   </math>
   is the stochastic process representing the price of the asset, the net profit of such a trading strategy after time T is equal to
   <math display="inline">
    X_T - X_S
   </math>
   . This leads us to define
   <math display="inline">
    \int H \, dX
   </math>
   as
  </p>
  <p block-type="Equation">
   <math display="block">
    \int_0^t H_s \, \mathrm{d}X_s = X_{t \wedge T} - X_{t \wedge S} \tag{4}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    t \wedge T := \min\{t, T\}
   </math>
   for all
   <math display="inline">
    t, 0 \le t &lt; \infty
   </math>
   , and stopping times
   <math display="inline">
    T
   </math>
   . Clearly, the process
   <math display="inline">
    H
   </math>
   in equation
   <math display="inline">
    (3)
   </math>
   has paths that are left continuous and possess right limits. We could similarly have defined
   <math display="inline">
    \int H \, dX
   </math>
   for H of the form, say,
   <math display="inline">
    \mathbf{1}_{[S,T)}
   </math>
   . However, there is a good reason for insisting on paths that are continuous from the left on
   <math display="inline">
    (0, \infty)
   </math>
   as we see in Example 1. Let us denote
   <math display="inline">
    \int_0^t H_s \, \mathrm{d}X_s
   </math>
   by
   <math display="inline">
    (H \cdot X)_t
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 1
   </b>
   Let
   <math display="inline">
    H
   </math>
   be of the form (3) and
   <math display="inline">
    M
   </math>
   be a martingale (see
   <b>
    Martingales
   </b>
   ). Then
   <math display="inline">
    H \cdot M
   </math>
   is a martingale.
  </p>
  <p block-type="Text">
   Later, we will see that the above theorem holds for a more general class of integrands so that the stochastic integrals preserve the martingale property. The following example shows why the left continuity for
   <math display="inline">
    H
   </math>
   is a reasonable restriction from a financial perspective.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Example 1
   </b>
   Let
   <math display="inline">
    N
   </math>
   be a Poisson process with intensity
   <math display="inline">
    \lambda
   </math>
   and define X by
   <math display="inline">
    X_t = \lambda t - N_t
   </math>
   . It is well known that
   <math display="inline">
    X
   </math>
   is a martingale. Suppose that there exists a traded asset with a price process given by
   <math display="inline">
    X
   </math>
   . Under normal circumstances, one should not be able to make arbitrage profits by trading in this
  </p>
  <p block-type="TextInlineMath">
   asset since its price does not change over time on average. Indeed, if H is of the form (3), then
   <math display="inline">
    H \cdot X
   </math>
   is a martingale with expected value zero so that the traders earn zero profit on average, as expected. Now consider another strategy
   <math display="inline">
    H = \mathbf{1}_{[0,T_1)}
   </math>
   , where
   <math display="inline">
    T_1
   </math>
   is the time of the first jump of N. Since X is an FV process,
   <math display="inline">
    H \cdot X
   </math>
   is well defined as a Stieltjes integral and is given by
   <math display="inline">
    (H \cdot X)_t = \lambda(t \wedge T_1) &gt; 0
   </math>
   , a.s., being the value of the portfolio at time
   <math display="inline">
    t
   </math>
   . Thus, this trading strategy immediately accumulates arbitrage profits. A moment of reflection reveals that such a trading strategy is not feasible under usual circumstances since it requires the knowledge of the time of a market crash, time
   <math display="inline">
    T_1
   </math>
   in this case, before it happens. If we use
   <math display="inline">
    H = \mathbf{1}_{[0,T_1]}
   </math>
   instead, this problem disappears.
  </p>
  <p block-type="TextInlineMath">
   Naturally, one will want the stochastic integral to be linear. Given a linear integral operator, we can define
   <math display="inline">
    H \cdot X
   </math>
   for integrands that are linear combinations of processes of the form
   <math display="inline">
    (3)
   </math>
   .
  </p>
  <p block-type="Text">
   <b>
    Definition 3
   </b>
   A process
   <math display="inline">
    H
   </math>
   is said to be simple predictable if
   <math display="inline">
    H
   </math>
   has a representation
  </p>
  <p block-type="Equation">
   <math display="block">
    H_{t} = H_{0}\mathbf{1}_{\{0\}}(t) + \sum_{i=1}^{n} H_{i}\mathbf{1}_{(T_{i},T_{i+1}]}(t) \qquad (5)
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    0 = T_1 \leq \cdots \leq T_{n+1} &lt; \infty
   </math>
   is a finite sequence of stopping times,
   <math display="inline">
    H_0 \in \mathcal{F}_0
   </math>
   ,
   <math display="inline">
    H_i \in \mathcal{F}_{T_i}
   </math>
   ,
   <math display="inline">
    1 \leq i \leq n
   </math>
   with
   <math display="inline">
    |H_i| &lt; \infty
   </math>
   , a.s.,
   <math display="inline">
    0 \le i \le n
   </math>
   . The collection of simple predictable processes is denoted by
   <math display="inline">
    S
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   Let
   <math display="inline">
    \mathbf{L}^0
   </math>
   be the space of finite-valued random variables endowed with the topology of convergence in probability. Define the linear mapping
   <math display="inline">
    I_X : \mathbf{S} \mapsto
   </math>
   <math display="inline">
    \mathbf{L}^0
   </math>
   as
  </p>
  <p block-type="Equation">
   <math display="block">
    I_X(H) = (H \cdot X)_{\infty}
   </math>
   <br/>
   <math display="block">
    := H_0 X_0 + \sum_{i=1}^n H_i (X_{T_{i+1}} - X_{T_i}) \qquad (6)
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    H
   </math>
   has the representation given in equation (5). Note that this definition does not depend on the particular choice of representation for
   <math display="inline">
    H
   </math>
   .
  </p>
  <p block-type="Text" class="has-continuation">
   Another property that the operator
   <math display="inline">
    I_X
   </math>
   must have is that it should satisfy some version of the bounded convergence theorem. This will inevitably place some restrictions on the stochastic process
   <math display="inline">
    X
   </math>
   . Thus, to have a large enough class of integrators, we choose a
  </p>
  <p block-type="TextInlineMath">
   reasonably weak version. A particularly weak version of the bounded convergence theorem is that the
   <i>
    uniform
   </i>
   convergence of
   <math display="inline">
    H^n
   </math>
   to H in S implies the convergence of
   <math display="inline">
    I_X(H^n)
   </math>
   to
   <math display="inline">
    I_X(H)
   </math>
   only in probability. Let
   <math display="inline">
    S_u
   </math>
   be the space S topologized by uniform convergence and recall that for a process
   <math display="inline">
    X
   </math>
   and a stopping time T, the notation
   <math display="inline">
    X^T
   </math>
   denotes the process
   <math display="inline">
    (X_{t\wedge T})_{t&gt;0}.
   </math>
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 4
   </b>
   A process
   <math display="inline">
    X
   </math>
   is a total semimartingale if
   <i>
    X
   </i>
   is càdlàg, adapted and
   <math display="inline">
    I_X : \mathbf{S}_u \mapsto \mathbf{L}^0
   </math>
   is continuous.
   <math display="inline">
    X
   </math>
   is a semimartingale (see
   <b>
    Semimartingale
   </b>
   ) if, for each
   <math display="inline">
    t \in [0, \infty)
   </math>
   ,
   <math display="inline">
    X^t
   </math>
   is a total semimartingale.
  </p>
  <p block-type="Text">
   This continuity property of
   <math display="inline">
    I_X
   </math>
   allows us to extend the definition of stochastic integrals to a class of integrands that is larger than
   <math display="inline">
    S
   </math>
   when the integrator is a semimartingale.
  </p>
  <p block-type="Text">
   It follows from the definition of a semimartingale that semimartingales form a vector space. One can also show that all square integrable martingales and all adapted FV processes are semimartingales (see Semimartingale). Therefore, the sum of a square integrable martingale and an adapted FV process would also be a semimartingale. The converse of this statement is also "essentially" true. The precise statement is the following theorem.
  </p>
  <p block-type="TextInlineMath">
   Theorem 2 (Bichteler–Dellacherie Theorem). Let
   <math display="inline">
    X
   </math>
   be a semimartingale. Then there exist processes M, A, with
   <math display="inline">
    M_0 = A_0 = 0
   </math>
   such that
  </p>
  <p block-type="Equation">
   <math display="block">
    X_t = X_0 + M_t + A_t \tag{7}
   </math>
  </p>
  <p block-type="Text">
   where
   <math display="inline">
    M
   </math>
   is a local martingale and
   <math display="inline">
    A
   </math>
   is an adapted FV process.
  </p>
  <p block-type="TextInlineMath">
   Here, we emphasize that this decomposition is not necessarily unique. Indeed, suppose that
   <math display="inline">
    X
   </math>
   has the decomposition
   <math display="inline">
    X = X_0 + M + A
   </math>
   and the space
   <math display="inline">
    (\Omega, \mathcal{F}, \mathbb{F}, \mathbb{P})
   </math>
   supports a Poisson process N with intensity
   <math display="inline">
    \lambda
   </math>
   . Then
   <math display="inline">
    Y_t = N_t - \lambda t
   </math>
   will define a martingale, which is also an FV process. Therefore,
   <math display="inline">
    X
   </math>
   can also be written as
   <math display="inline">
    X = X_0 + (M + Y) + (A - Y)
   </math>
   . The reason for the nonuniqueness is the existence of martingales that are of finite variation. However, if X has a decomposition
   <math display="inline">
    X = X_0 + M + A
   </math>
   , where
   <math display="inline">
    M
   </math>
   is a local martingale and
   <math display="inline">
    A
   </math>
   is
   <i>
    predictable
   </i>
   &lt;sup&gt;a&lt;/sup&gt; and FV with
   <math display="inline">
    M_0 = A_0 = 0
   </math>
   , then such a decomposition is unique since all predictable local martingales that are of finite variation have to be constant.
  </p>
  <p block-type="Text">
   Arguably, Brownian motion is the most well known of all semimartingales. In the following section, we develop stochastic integration with respect to a Brownian motion.
  </p>
  <h1>
   <math display="inline">
    L^2
   </math>
   Theory of Stochastic Integration with
   <b>
    Respect to Brownian Motion
   </b>
  </h1>
  <p block-type="TextInlineMath">
   We assume that there exists a Brownian motion,
   <math display="inline">
    B
   </math>
   , on
   <math display="inline">
    (\Omega, \mathcal{F}, \mathbb{F}, \mathbb{P})
   </math>
   with
   <math display="inline">
    B_0 = 0
   </math>
   , and that
   <math display="inline">
    \mathcal{F}_0
   </math>
   only contains the
   <math display="inline">
    (\mathcal{F}, \mathbb{P})
   </math>
   -null sets. First, we define the notion of predictability, which is the key concept in defining the stochastic integral.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 5
   </b>
   The predictable
   <math display="inline">
    \sigma
   </math>
   -algebra
   <math display="inline">
    \mathcal{P}
   </math>
   on
   <math display="inline">
    [0,\infty)\times\Omega
   </math>
   is defined to be the smallest
   <math display="inline">
    \sigma
   </math>
   -algebra on
   <math display="inline">
    [0,\infty) \times \Omega
   </math>
   with respect to which every adapted càglàd process is measurable. A process is said to be predictable if it is a
   <math display="inline">
    P
   </math>
   -measurable map from
   <math display="inline">
    [0,\infty)\times\Omega
   </math>
   to
   <math display="inline">
    \mathbb{R}
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   Clearly,
   <math display="inline">
    S \subset \mathcal{P}
   </math>
   . Actually, there is more to this as is shown by the next theorem.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 3
   </b>
   Let
   <math display="inline">
    bS
   </math>
   be the set of elements of
   <math display="inline">
    S
   </math>
   that are bounded a.s. Then,
   <math display="inline">
    \mathcal{P} = \sigma(\mathbf{bS})
   </math>
   , that is,
   <math display="inline">
    \mathcal{P}
   </math>
   is
   <math display="inline">
    generated by the processes in
    <b>
     bS
    </b>
    .
   </math>
  </p>
  <p block-type="Text">
   By linearity of the stochastic integral and Theorem 1 and using the fact that Brownian motion has increments independent from the past with a certain Gaussian distribution, we have the following.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 4
   </b>
   Let
   <math display="inline">
    H \in \mathbf{bS}
   </math>
   and define
   <math display="inline">
    (H \cdot B)_t = (H \cdot B)_t
   </math>
   <math display="inline">
    (B^t)_{\infty}
   </math>
   , that is,
   <math display="inline">
    (H \cdot B)_t
   </math>
   is the stochastic integral of H with respect to
   <math display="inline">
    B^t
   </math>
   . Then
   <math display="inline">
    H \cdot B
   </math>
   is a martingale and
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\left[ (H \cdot B)_t^2 \right] = \int_0^t \mathbb{E}[H_s^2] \, \mathrm{d}s \tag{8}
   </math>
  </p>
  <p block-type="Text">
   In the following, we construct the stochastic integral with respect to Brownian motion for a subset of predictable processes. To keep the exposition simple, we restrict our attention to a finite interval
   <math display="inline">
    [0, T]
   </math>
   , where
   <math display="inline">
    T
   </math>
   is arbitrary but deterministic. Define
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathcal{L}^{2}(B^{T}) := \left\{ H \in \mathcal{P} : \int_{0}^{T} \mathbb{E}[H_{s}^{2}] \, \mathrm{d}s &lt; \infty \right\} \quad (9)
   </math>
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   which is a Hilbert space. Note that
   <math display="inline">
    \mathbf{bS} \subset \mathcal{L}^2(B^T)
   </math>
   . Letting
   <math display="inline">
    L^2(\mathcal{F}_T)
   </math>
   denote the space of square integrable
  </p>
  <p block-type="Text">
   <math display="inline">
    \mathcal{F}_T
   </math>
   -measurable random variables, Theorem 4 now implies the map
  </p>
  <p block-type="Equation">
   <math display="block">
    I_{B^T} : \mathbf{bS} \mapsto \mathcal{L}^2(\mathcal{F}_T) \tag{10}
   </math>
  </p>
  <p block-type="Text">
   defined by
  </p>
  <p block-type="Equation">
   <math display="block">
    I_{B^T}(H) = (H \cdot B)_T \tag{11}
   </math>
  </p>
  <p block-type="TextInlineMath">
   is an isometry. Consequently, we can extend the definition of the stochastic integral uniquely to the closure of
   <b>
    bS
   </b>
   in
   <math display="inline">
    \mathcal{L}^2(B^T)
   </math>
   . An application of monotone class theorem along with Theorem 3 yields that the closure is the whole
   <math display="inline">
    \mathcal{L}^2(B^T)
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 5
   </b>
   Let
   <math display="inline">
    H \in \mathcal{L}^2(B^T)
   </math>
   . Then the Itô integral
   <math display="inline">
    (H \cdot B)_T
   </math>
   of H with respect to
   <math display="inline">
    B^T
   </math>
   is the image of H under the extension of the isometry
   <math display="inline">
    I_{B^T}
   </math>
   to the whole of
   <math display="inline">
    \mathcal{L}^2(B^T)
   </math>
   . In particular,
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\left[ (H \cdot B)_T^2 \right] = \int_0^T \mathbb{E}[H_s^2] \, \mathrm{d}s \tag{12}
   </math>
  </p>
  <p block-type="TextInlineMath">
   Moreover, the process Y defined by
   <math display="inline">
    Y_t = (H \cdot B)_{t \wedge T}
   </math>
   is a square integrable martingale.
  </p>
  <p block-type="Text">
   The property (12) is often called the
   <i>
    Itô isometry
   </i>
   .
  </p>
  <h2>
   <b>
    Stochastic Integration with Respect to General Semimartingales
   </b>
  </h2>
  <p block-type="TextInlineMath">
   In the previous section, we developed the stochastic integration for Brownian motion over the interval
   <math display="inline">
    [0, T]
   </math>
   . We need to mention here that the method employed works not only for Brownian motion but also for any martingale
   <math display="inline">
    M
   </math>
   that is square integrable over
   <math display="inline">
    [0, T]
   </math>
   , the latter case requiring some extra effort mainly for establishing the existence of the so-called
   <i>
    quadratic variation
   </i>
   process associated with
   <math display="inline">
    M
   </math>
   . This would, in turn, allow us to extend the definition of the stochastic integral with respect to
   <math display="inline">
    X
   </math>
   of the form
   <math display="inline">
    X = M + A
   </math>
   , where M is a square integrable martingale and
   <math display="inline">
    A
   </math>
   is a process of finite variation on compacts by defining, under some conditions on
   <math display="inline">
    H
   </math>
   ,
  </p>
  <p block-type="Equation">
   <math display="block">
    H \cdot X = H \cdot M + H \cdot A \tag{13}
   </math>
  </p>
  <p block-type="Text" class="has-continuation">
   where
   <math display="inline">
    H \cdot A
   </math>
   can be computed as a path-by-path Lebesgue-Stieltjes integral. In this section, we establish the stochastic integral with respect to a general semimartingale. The idea would be similar to the construction of the stochastic integral with respect to
  </p>
  <p block-type="Text">
   Brownian motion. We show that the integral operator is a continuous mapping from the set of simple predictable process into an appropriate space so that we can extend the set of possible integrands to the closure of
   <math display="inline">
    S
   </math>
   in a certain topology.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 6
   </b>
   A sequence of processes
   <math display="inline">
    (H^n)_{n&gt;1}
   </math>
   converges to a process
   <math display="inline">
    H
   </math>
   uniformly on compacts in probability (UCP) if, for each
   <math display="inline">
    t &gt; 0
   </math>
   ,
   <math display="inline">
    \sup_{0 \le s \le t} |H_s^n - H_s|
   </math>
   converges to 0 in probability.
  </p>
  <p block-type="Text">
   The following result is not surprising and one can refer to, for example,
   <math display="inline">
    [7]
   </math>
   for a proof.
  </p>
  <p block-type="Text">
   <b>
    Theorem 6
   </b>
   The space
   <math display="inline">
    S
   </math>
   is dense in
   <math display="inline">
    \mathbb{L}
   </math>
   under the
   <i>
    UCP topology.
   </i>
  </p>
  <p block-type="Text">
   The following mapping is key to defining the stochastic integral with respect to a general semimartingale.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 7
   </b>
   For
   <math display="inline">
    H \in \mathbf{S}
   </math>
   and
   <math display="inline">
    X
   </math>
   being a càdlàg process, define the linear mapping
   <math display="inline">
    J_X : \mathbf{S} \mapsto \mathbb{D}
   </math>
   by
  </p>
  <p block-type="Equation">
   <math display="block">
    J_X(H) = H_0 X_0 + \int_{i=1}^n H_i(X^{T_{i+1}} - X^{T_i}) \qquad (14)
   </math>
  </p>
  <p block-type="Text">
   where
   <math display="inline">
    H
   </math>
   has the representation as in equation (5).
  </p>
  <p block-type="Text">
   Note the difference between
   <math display="inline">
    J_X
   </math>
   and
   <math display="inline">
    I_X
   </math>
   .
   <math display="inline">
    I_X
   </math>
   maps processes into random variables, whereas
   <math display="inline">
    J_X
   </math>
   maps processes into processes.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 8
   </b>
   For
   <math display="inline">
    H \in \mathbf{S}
   </math>
   and X being an adapted càdlàg process, we call
   <math display="inline">
    J_X(H)
   </math>
   the stochastic integral of H with respect to
   <math display="inline">
    X
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   Observe that
   <math display="inline">
    J_X(H)_t = I_{X^t}(H)
   </math>
   . This property, combined with the definition of a semimartingale, yields the following continuity property for
   <math display="inline">
    J_X
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 7
   </b>
   Let X be a semimartingale and
   <math display="inline">
    \mathbf{S}_{\text{UCP}}
   </math>
   (respectively
   <math display="inline">
    \mathbb{D}_{\text{UCP}}
   </math>
   ) denote the space
   <b>
    S
   </b>
   (respectively,
   <math display="inline">
    \mathbb{D}
   </math>
   ) endowed with the UCP topology. Then the map-
   <math display="inline">
    \text{ping } J_X : \mathbf{S}_{\text{UCP}} \mapsto \mathbb{D}_{\text{UCP}} \text{ is continuous.}
   </math>
  </p>
  <p block-type="Text">
   Using Theorem 6, we can now extend the integration operator
   <math display="inline">
    J_X
   </math>
   from
   <b>
    S
   </b>
   to
   <math display="inline">
    \mathbb{L}
   </math>
   by continuity, since
   <math display="inline">
    \mathbb{D}_{\text{UCP}}
   </math>
   is a complete metric space&lt;sup&gt;b&lt;/sup&gt;.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 9
   </b>
   Let
   <math display="inline">
    X
   </math>
   be a semimartingale. The continuous linear mapping
   <math display="inline">
    J_X : \mathbb{L}_{\text{UCP}} \mapsto \mathbb{D}_{\text{UCP}}
   </math>
   obtained as the extension of
   <math display="inline">
    J_X: \mathbf{S}_{\text{UCP}} \mapsto \mathbb{D}_{\text{UCP}}
   </math>
   is called the stochastic integral.
  </p>
  <p block-type="TextInlineMath">
   Note that, in contrast to the
   <math display="inline">
    L^2
   </math>
   theory utilized in the previous section, we do not need to impose any integrability conditions on either
   <math display="inline">
    X
   </math>
   or
   <math display="inline">
    H
   </math>
   to establish the existence of the stochastic integral
   <math display="inline">
    H \cdot X
   </math>
   as long as H remains in
   <math display="inline">
    \mathbb{L}
   </math>
   . The above continuity property of the stochastic integrals moreover allows us to approximate the
   <math display="inline">
    H \cdot X
   </math>
   using the Riemann sums.
  </p>
  <p block-type="Text">
   <b>
    Definition 10
   </b>
   Let
   <math display="inline">
    \sigma
   </math>
   denote a finite sequence of finite stopping times:
  </p>
  <p block-type="Equation">
   <math display="block">
    0 = T_0 \le T_1 \le \dots \le T_k &lt; \infty. \tag{15}
   </math>
  </p>
  <p block-type="Text">
   The sequence of
   <math display="inline">
    \sigma
   </math>
   is called a random partition. A sequence of random partitions
   <math display="inline">
    \sigma_n
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    \sigma_n: 0 = T_0^n \le T_1^n \le \dots \le T_{k_n}^n \tag{16}
   </math>
  </p>
  <p block-type="Text">
   is said to tend to identity if
  </p>
  <p block-type="Text">
   1.
   <math display="inline">
    \lim_{n\to\infty} \sup_j T_j^n = \infty
   </math>
   , a.s. and&lt;br&gt;2.
   <math display="inline">
    \sup_j |T_{j+1}^n - T_j^n|
   </math>
   converges to 0 a.s.
  </p>
  <p block-type="Text">
   Let Y be a process and
   <math display="inline">
    \sigma
   </math>
   be a random partition. Define the process
  </p>
  <p block-type="Equation">
   <math display="block">
    Y^{\sigma} := Y_0 \mathbf{1}_{\{0\}} + \sum_j Y_{T_j} \mathbf{1}_{(T_j, T_{j+1}]} \tag{17}
   </math>
  </p>
  <p block-type="Text">
   Consequently, if Y is in
   <math display="inline">
    \mathbb{D}
   </math>
   or
   <math display="inline">
    \mathbb{L}
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    Y^{\sigma} \cdot X = Y_0 X_0 + \sum_j Y_{T_j} \left( X^{T_{j+1}} - X^{T_j} \right) \tag{18}
   </math>
  </p>
  <p block-type="Text">
   for any semimartingale
   <math display="inline">
    X
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 8
   </b>
   Let
   <math display="inline">
    X
   </math>
   be a semimartingale and let
   <math display="inline">
    \int_{0+}^{t} H_s \, \mathrm{d}X_s \text{ denote } (H \cdot X)_t - H_0 X_0 \text{ for any } H \in \mathbb{L}.
   </math>
   If
   <math display="inline">
    Y
   </math>
   is a process in
   <math display="inline">
    \mathbb D
   </math>
   or in
   <math display="inline">
    \mathbb L
   </math>
   , and
   <math display="inline">
    (\sigma_n)
   </math>
   is a sequence of random partitions tending to identity, then the process
   <math display="inline">
    \left(\int_{0+}^{t} Y^{\sigma_n}_{s} dX_{s}\right)_{t\geq 0}
   </math>
   converges to the stochastic integral
   <math display="inline">
    (Y_{-}) \cdot X
   </math>
   in
   <math display="inline">
    \overset{\sim}{UCP}
   </math>
   , where
   <math display="inline">
    Y_{-}
   </math>
   is the process defined as
   <math display="inline">
    (Y_{-})_s = \lim_{r \to s, r \lt s} Y_r
   </math>
   , for
   <math display="inline">
    s &gt; 0
   </math>
   , and
   <math display="inline">
    (Y_{-})_{0} = 0
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Example 2
   </b>
   As an application of the above theorem, we calculate
   <math display="inline">
    \int_0^t B_s \, dB_s
   </math>
   , where B is a standard Brownian motion with
   <math display="inline">
    B_0 = 0
   </math>
   . Let
   <math display="inline">
    (\sigma_n)
   </math>
   be a sequence of random partitions of the form
   <math display="inline">
    (16)
   </math>
   tending to identity and let
   <math display="inline">
    B^n = B^{\sigma_n}
   </math>
   . Note that
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{split} \int_{0}^{t} B_{s}^{n} \, \mathrm{d}B_{s} &amp;= \sum_{\substack{t_{j} \in \sigma_{n} \\ t_{j} &lt; t}} B_{t_{j}} (B_{t \wedge t_{j+1}} - B_{t_{j}}) \\ &amp;= \sum_{\substack{t_{j} \in \sigma_{n} \\ t_{j} &lt; t}} \frac{1}{2} (B_{t \wedge t_{j+1}} + B_{t_{j}}) (B_{t \wedge t_{j+1}} - B_{t_{j}}) \\ &amp;- \sum_{\substack{t_{j} \in \sigma_{n} \\ t_{j} &lt; t}} \frac{1}{2} (B_{t \wedge t_{j+1}} - B_{t_{j}})^{2} \\ &amp;= \frac{1}{2} B_{(t \wedge T_{k_{n}}^{n})}^{2} - \frac{1}{2} \sum_{\substack{t_{j} \in \sigma_{n} \\ t_{j} &lt; t}} (B_{t_{j+1}} - B_{t_{j}})^{2} \tag{19} \end{split}
   </math>
  </p>
  <p block-type="TextInlineMath">
   As
   <i>
    n
   </i>
   tends to
   <math display="inline">
    \infty
   </math>
   , the sum&lt;sup&gt;c&lt;/sup&gt; in equation (19) is known to converge to t. Obviously,
   <math display="inline">
    B_{T_{t}^{n} \wedge t}^{2}
   </math>
   tends to
   <math display="inline">
    B_t^2
   </math>
   since
   <math display="inline">
    \sigma_n
   </math>
   tends to identity. Thus, we conclude via Theorem 8 that
  </p>
  <p block-type="Equation">
   <math display="block">
    \int_0^t B_s \, \mathrm{d}B_s = \frac{1}{2} B_t^2 - \frac{t}{2} \tag{20}
   </math>
  </p>
  <p block-type="TextInlineMath">
   since
   <i>
    B
   </i>
   is continuous with
   <math display="inline">
    B_0 = 0
   </math>
   . Thus, the integration rules for a stochastic integral are quite different from those for an ordinary integral. Indeed, if
   <math display="inline">
    A
   </math>
   were a continuous process of finite variation with
   <math display="inline">
    A_0 = 0
   </math>
   , then the Riemann–Stieltjes integral of
   <math display="inline">
    A \cdot A
   </math>
   will yield the following formula:
  </p>
  <p block-type="Equation">
   <math display="block">
    \int_{0}^{t} A_{s} \, \mathrm{d}A_{s} = \frac{1}{2} A_{t}^{2} \tag{21}
   </math>
  </p>
  <p block-type="Text">
   As in the case of Brownian motion, stochastic integration with respect to a semimartingale preserves the martingale property.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 9
   </b>
   Let
   <math display="inline">
    H \in \mathbb{L}
   </math>
   such that
   <math display="inline">
    \lim_{t \downarrow 0} |H_t| &lt; \infty
   </math>
   and
   <math display="inline">
    X
   </math>
   be a local martingale (see
   <b>
    Martingales
   </b>
   ). Then
   <math display="inline">
    H \cdot X
   </math>
   is also a local martingale.
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   Next, we would like to weaken the restriction that an integrand must be in
   <math display="inline">
    \mathbb{L}
   </math>
   . If we want the stochastic integral to still preserve the martingale property with this extended class of integrands, we inevitably need to restrict our attention to predictable processes. To see this, consider the process
   <math display="inline">
    H = \mathbf{1}_{[0,T_1)}
   </math>
   in Example 1. This process is not predictable since the jump times of a Poisson process are not predictable stopping times. As we have shown in Example 1, the
  </p>
  <p block-type="Text">
   integral of
   <math display="inline">
    H
   </math>
   with respect to a particular martingale is not a martingale.
  </p>
  <p block-type="Text">
   Before we allow more general predictable integrands in a stochastic integral, we need to develop the notion of
   <i>
    quadratic variation
   </i>
   of a semimartingale. This is discussed in the following section.
  </p>
  <h4>
   <b>
    Properties of Stochastic Integrals
   </b>
  </h4>
  <p block-type="TextInlineMath">
   In this section, H denotes an element of
   <math display="inline">
    \mathbb{L}
   </math>
   and X denotes a semimartingale. For a process
   <math display="inline">
    Y \in \mathbb{D}
   </math>
   , we define
   <math display="inline">
    \Delta Y_t = Y_t - Y_{t-}
   </math>
   , the jump at t. Recall that two process
   <math display="inline">
    Y
   </math>
   and
   <math display="inline">
    Z
   </math>
   are said to be
   <i>
    indistinguishable
   </i>
   if
   <math display="inline">
    \mathbb{P}\{\omega: Y_t(\omega) = Z_t(\omega), \ \forall t\} = 1.
   </math>
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 10
   </b>
   Let T be a stopping time. Then
   <math display="inline">
    (H \cdot
   </math>
   <math display="inline">
    (X)^{T} = H\mathbf{1}_{[0,T]} \cdot X = H \cdot (X^{T}).
   </math>
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 11
   </b>
   The jump process
   <math display="inline">
    (\Delta (H \cdot X)_t)_{t&gt;0}
   </math>
   is
   <i>
    indistinguishable from
   </i>
   <math display="inline">
    (H_t \Delta X_t)_{t \ge 0}
   </math>
   .
  </p>
  <p block-type="Text">
   In finance theory, one often needs to work under the so-called
   <i>
    risk-neutral
   </i>
   measure rather than the empirical or objective measure
   <math display="inline">
    \mathbb{P}
   </math>
   . Recall that definitions of a semimartingale and its stochastic integral are given in spaces topologized by convergence in probability. Thus, one may wonder whether the value of a stochastic integral remains unchanged under an equivalent change of measure. The following theorem shows that this is indeed the case. Let
   <math display="inline">
    \mathbb{Q}
   </math>
   be another probability measure on
   <math display="inline">
    (\Omega, \mathcal{F})
   </math>
   and let
   <math display="inline">
    H_{\mathbb{Q}} \cdot X
   </math>
   denote the stochastic integral of
   <math display="inline">
    H
   </math>
   with respect to
   <math display="inline">
    X
   </math>
   computed under
   <math display="inline">
    \mathbb{Q}
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 12
   </b>
   Let
   <math display="inline">
    \mathbb{Q} \ll \mathbb{P}
   </math>
   . Then,
   <math display="inline">
    H_{\mathbb{Q}} \cdot X
   </math>
   is indistin
   <i>
    guishable from
   </i>
   <math display="inline">
    H_{\mathbb{P}} \cdot X
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 13
   </b>
   Let
   <math display="inline">
    \mathbb{G} = (\mathcal{G}_t)_{t \ge 0}
   </math>
   be another filtration such that H is in both
   <math display="inline">
    L(\mathbb{G})
   </math>
   and
   <math display="inline">
    L(\mathbb{F})
   </math>
   , and such that X is also a
   <math display="inline">
    \mathbb{G}
   </math>
   -semimartingale. Then
   <math display="inline">
    H_{\mathbb{G}} \cdot X
   </math>
   is indistinguishable from
   <math display="inline">
    H_{\mathbb{F}} \cdot X
   </math>
   .
  </p>
  <p block-type="Text">
   The following theorem shows the stochastic integral is an extension of the Lebesgue-Stieltjes integral.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 14
   </b>
   If X is an FV process, then
   <math display="inline">
    H \cdot X
   </math>
   is indistinguishable from the Lebesgue-Stieltjes integral, computed path by path. Consequently,
   <math display="inline">
    H \cdot X
   </math>
   is an FV process.
  </p>
  <p block-type="Text">
   <b>
    Theorem 15
   </b>
   The stochastic integral is associative. That is,
   <math display="inline">
    H \cdot X
   </math>
   is also a semimartingale and if
   <math display="inline">
    G \in \mathbb{L}
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    G \cdot (H \cdot X) = (GH) \cdot X \tag{22}
   </math>
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 11
   </b>
   <i>
    The quadratic variation process of
   </i>
   <math display="inline">
    X
   </math>
   <i>
    ,
   </i>
   denoted by
   <math display="inline">
    [X, X] = ([X, X]_t)_{t&gt;0}
   </math>
   , is defined as
  </p>
  <p block-type="Equation">
   <math display="block">
    [X, X] = X^2 - 2X_{-} \cdot X \tag{23}
   </math>
  </p>
  <p block-type="TextInlineMath">
   Recall that
   <math display="inline">
    X_{0-} = 0
   </math>
   . Let Y be another semimartingale. The quadratic covariation of
   <math display="inline">
    X
   </math>
   and
   <math display="inline">
    Y
   </math>
   , denoted by
   <math display="inline">
    [X, Y]
   </math>
   , is defined as
  </p>
  <p block-type="Equation">
   <math display="block">
    [X, Y] = XY - Y_{-} \cdot X - X_{-} \cdot Y \tag{24}
   </math>
  </p>
  <p block-type="TextInlineMath">
   Since
   <math display="inline">
    X_{-}
   </math>
   (and
   <math display="inline">
    Y_{-}
   </math>
   ) belongs to
   <math display="inline">
    \mathbb{L}
   </math>
   , we can use Theorem 8 to deduce the following.
  </p>
  <p block-type="Text">
   <b>
    Theorem 16
   </b>
   Let
   <math display="inline">
    Y
   </math>
   be a semimartingale. The quadratic covariation
   <math display="inline">
    [X, Y]
   </math>
   of
   <math display="inline">
    X
   </math>
   and
   <math display="inline">
    Y
   </math>
   is an adapted càdlàg process that satisfies the following:
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     1.
     <math display="inline">
      [X, Y]_0 = X_0Y_0
     </math>
     and
     <math display="inline">
      \Delta[X, Y] = \Delta X \Delta Y
     </math>
     .
    </li>
    <li block-type="ListItem">
     2. If
     <math display="inline">
      (\sigma_n)
     </math>
     is a sequence of partitions tending to identity, then
    </li>
   </ul>
  </p>
  <p block-type="Equation">
   <math display="block">
    X_0 Y_0 + \sum_{j} (X^{T_{j+1}^n} - X^{T_j^n})
   </math>
   <math display="block">
    \times (Y^{T_{j+1}^n} - Y^{T_j^n}) \to [X, Y] \qquad (25)
   </math>
  </p>
  <p block-type="TextInlineMath">
   with convergence in UCP, where
   <math display="inline">
    \sigma_n
   </math>
   is of the form
   <math display="inline">
    (16).
   </math>
  </p>
  <p block-type="Text">
   3. If T is any stopping time, then
   <math display="inline">
    [X^T, Y] =
   </math>
   <math display="inline">
    [X, Y^T] = [X, Y]^T.
   </math>
   Moreover,
   <math display="inline">
    [X, X]
   </math>
   is increasing.
  </p>
  <p block-type="Text">
   Since
   <math display="inline">
    [X, X]
   </math>
   is increasing and càdlàg by definition, we immediately deduce that
   <math display="inline">
    [X, X]
   </math>
   is of finite variation. Moreover, the following polarization identity
  </p>
  <p block-type="Equation">
   <math display="block">
    [X,Y] = \frac{1}{2}([X+Y,X+Y] - [X,X] - [Y,Y])
   </math>
   (26)
  </p>
  <p block-type="Text">
   reveals that
   <math display="inline">
    [X, Y]
   </math>
   is the difference of two increasing processes; therefore,
   <math display="inline">
    [X, Y]
   </math>
   is an FV process as well. This, in turn, implies
   <math display="inline">
    XY
   </math>
   is also a semimartingale and yields the
   <i>
    integration by parts
   </i>
   formula:
  </p>
  <p block-type="Equation">
   <math display="block">
    X_t Y_t = (X_- \cdot Y)_t + (Y_- \cdot X)_t + [X, Y]_t \qquad (27)
   </math>
  </p>
  <p block-type="Text">
   When
   <math display="inline">
    X
   </math>
   and
   <math display="inline">
    Y
   </math>
   are FV processes, the classical integration by parts formula reads as follows:
  </p>
  <p block-type="Equation">
   <math display="block">
    X_t Y_t = X_0 Y_0 + (X_- \cdot Y)_t + (Y_- \cdot X)_t + \sum_{0 &lt; s \le t} \Delta X_s \Delta Y_s \qquad (28)
   </math>
  </p>
  <p block-type="TextInlineMath">
   Therefore, if
   <math display="inline">
    X
   </math>
   or
   <math display="inline">
    Y
   </math>
   is a continuous processes of finite variation, then
   <math display="inline">
    [X, Y] = X_0Y_0
   </math>
   . In particular, if
   <math display="inline">
    X
   </math>
   is a continuous FV process, then its quadratic variation is equal to
   <math display="inline">
    X_0^2
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 17
   </b>
   Let
   <math display="inline">
    X
   </math>
   and
   <math display="inline">
    Y
   </math>
   be two semimartingales, and let
   <math display="inline">
    H
   </math>
   and
   <math display="inline">
    K
   </math>
   be two measurable processes. Then one has a.s.
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{split} &amp; \int_{0}^{\infty} |H_{s}| |K_{s}| \mid \mathrm{d}[X,Y]_{s} | \\ &amp; \leq \left( \int_{0}^{\infty} H_{s}^{2} \mathrm{d}[X,X]_{s} \right)^{\frac{1}{2}} \left( \int_{0}^{\infty} K_{s}^{2} \mathrm{d}[Y,Y]_{s} \right)^{\frac{1}{2}} \text{ (29)} \end{split}
   </math>
  </p>
  <p block-type="TextInlineMath">
   The above inequality is called
   <i>
    Kunita-Watanabe
   </i>
   inequality. An immediate consequence of this inequality is that if
   <math display="inline">
    X
   </math>
   or
   <math display="inline">
    Y
   </math>
   has zero quadratic variation, then
   <math display="inline">
    [X, Y] = 0
   </math>
   . The following theorem follows from the definition of quadratic variation and Theorem 9.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 18
   </b>
   Let
   <math display="inline">
    X
   </math>
   be a local martingale. Then,
   <math display="inline">
    X^2 - [X, X]
   </math>
   is a local martingale. Moreover,
   <math display="inline">
    [X, X]
   </math>
   is the unique adapted càdlàg and FV process A such that
   <math display="inline">
    X^2 - A
   </math>
   is a local martingale and
   <math display="inline">
    \Delta A = (\Delta X)^2
   </math>
   with
   <math display="inline">
    A_0 = X_0^2
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   Note that the uniqueness in the above theorem is lost if we do not impose
   <math display="inline">
    \Delta A = (\Delta X)^2
   </math>
   . Roughly speaking, the above theorem infers
   <math display="inline">
    \mathbb{E}(X_t^2) = \mathbb{E}([X, X]_t)
   </math>
   when
   <math display="inline">
    X
   </math>
   is a martingale. The following theorem formalizes this intuition.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Corollary 1
   </b>
   Let
   <math display="inline">
    X
   </math>
   be a local martingale. Then,
   <math display="inline">
    X
   </math>
   is a martingale with
   <math display="inline">
    \mathbb{E}(X_t^2) &lt; \infty
   </math>
   , for all
   <math display="inline">
    t \geq 0
   </math>
   , if and only if
   <math display="inline">
    \mathbb{E}([X,X]_t) &lt; \infty
   </math>
   , for all
   <math display="inline">
    t &gt; 0
   </math>
   . If
   <math display="inline">
    \mathbb{E}([X,X]_t) &lt;
   </math>
   <math display="inline">
    \infty
   </math>
   , then
   <math display="inline">
    \mathbb{E}(X_t^2) = \mathbb{E}([X,X]_t)
   </math>
   .
  </p>
  <p block-type="Text">
   The following corollary to Theorem 18 is of fundamental importance in the theory of martingales.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Corollary 2
   </b>
   Let
   <math display="inline">
    X
   </math>
   be a continuous local martingale, and
   <math display="inline">
    S &lt; T &lt; \infty
   </math>
   be stopping times. If X has paths of finite variation on the stochastic interval
   <math display="inline">
    (S, T)
   </math>
   ,
  </p>
  <p block-type="TextInlineMath">
   then
   <math display="inline">
    X
   </math>
   is constant on
   <math display="inline">
    [S, T]
   </math>
   . Moreover, if
   <math display="inline">
    [X, X]
   </math>
   is
   <i>
    constant on
   </i>
   <math display="inline">
    [S, T] \cap [0, \infty)
   </math>
   <i>
    , then X is also constant
   </i>
   there.
  </p>
  <p block-type="Text">
   The following result is quite handy when it comes to the calculation of the quadratic covariation of two stochastic integrals.
  </p>
  <p block-type="Text">
   <b>
    Theorem 19
   </b>
   Let Y be a semimartingale and
   <math display="inline">
    K \in \mathbb{L}
   </math>
   . Then
  </p>
  <p block-type="Equation">
   <math display="block">
    [H \cdot X, K \cdot Y]_t = \int_0^t H_s K_s \, d[X, Y]_s \qquad (30)
   </math>
  </p>
  <p block-type="Text">
   In the following section, we define the stochastic integral for predictable integrals. However, we already have all the results to present the celebrated
   <math display="inline">
    It\hat{o}'s
   </math>
   formula.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 20
   </b>
   (Itô's Formula). Let X be a semimartingale and
   <math display="inline">
    f
   </math>
   be a
   <math display="inline">
    C^2
   </math>
   real function. Then
   <math display="inline">
    f(X)
   </math>
   is again a semimartingale and the following formula holds:
  </p>
  <p block-type="Equation">
   <math display="block">
    f(X_{t}) - f(X_{0}) = \int_{0+}^{t} f'(X_{s-}) \, dX_{s}
   </math>
   <br/>
   +
   <math>
    \frac{1}{2} \int_{0+}^{t} f''(X_{s-}) \, d[X, X]_{s}
   </math>
   <br/>
   +
   <math>
    \sum_{0 &lt; s \le t} \left\{ f(X_{s}) - f(X_{s-}) - f'(X_{s-}) \Delta X_{s} - \frac{1}{2} f''(X_{s-}) (\Delta X_{s})^{2} \right\}
   </math>
   (31)
  </p>
  <h1>
   <b>
    Stochastic Integration for Predictable
   </b>
   Integrands
  </h1>
  <p block-type="TextInlineMath" class="has-continuation">
   In this section, we weaken the hypothesis that
   <math display="inline">
    H \in \mathbb{L}
   </math>
   in order for
   <math display="inline">
    H \cdot X
   </math>
   to be well defined for a semimartingale
   <math display="inline">
    X
   </math>
   . As explained earlier, we restrict our attention to predictable processes since we want the stochastic integral to preserve the martingale property. We will not be able to show the existence of stochastic integral
   <math display="inline">
    H \cdot X
   </math>
   for all
   <math display="inline">
    H \in \mathcal{P}
   </math>
   but, as in the section
   <math display="inline">
    L^2
   </math>
   Theory of Stochastic Integration with Respect to Brownian Motion, we give a meaning to
   <math display="inline">
    H \cdot X
   </math>
   for the appropriately integrable processes in
   <math display="inline">
    \mathcal{P}
   </math>
   . First, we assume that
   <math display="inline">
    X
   </math>
   is a special semimartingale, that is, there exist processes
   <math display="inline">
    M
   </math>
   and
   <math display="inline">
    A
   </math>
   such that
   <math display="inline">
    M
   </math>
   is a
  </p>
  <p block-type="TextInlineMath">
   local martingale and
   <math display="inline">
    A
   </math>
   is predictable and of finite variation with
   <math display="inline">
    M_0 = A_0 = 0
   </math>
   and
   <math display="inline">
    X = X_0 + M + A
   </math>
   . This decomposition of a special semimartingale is unique and called the
   <i>
    canonical decomposition
   </i>
   . Without loss of generality, let us assume that
   <math display="inline">
    X_0 = 0
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 12
   </b>
   Let
   <math display="inline">
    X
   </math>
   be a special semimartingale with the canonical decomposition
   <math display="inline">
    X = M + A
   </math>
   . The
   <math display="inline">
    \mathcal{H}^2
   </math>
   norm of X is defined as
  </p>
  <p block-type="Equation">
   <math display="block">
    \parallel X \parallel_{\mathcal{H}^{2}} := \parallel [M, M]_{\infty}^{1/2} \parallel_{L^{2}} + \parallel \int_{0}^{\infty} \mid \mathrm{d}A_{s} \mid \parallel_{L^{2}}
   </math>
   (32)
  </p>
  <p block-type="TextInlineMath">
   The space of
   <math display="inline">
    \mathcal{H}^2
   </math>
   semimartingales consists of special semimartingales with finite
   <math display="inline">
    \mathcal{H}^2
   </math>
   norm. We write
   <math display="inline">
    X \in
   </math>
   <math display="inline">
    \mathcal{H}^2
   </math>
   to indicate that X belongs to the space of
   <math display="inline">
    \mathcal{H}^2
   </math>
   semimartingales.
  </p>
  <p block-type="Text">
   One can show that the space of
   <math display="inline">
    \mathcal{H}^2
   </math>
   semimartingales is a Banach space, which is the key property to extend the definition of stochastic integrals for a more general class of integrands. Let
   <math display="inline">
    \mathbf{b} \mathbb{L}
   </math>
   denote the space of bounded adapted processes with càglàd paths and
   <math display="inline">
    \mathbf{b}\mathcal{P}
   </math>
   denote the space of bounded predictable processes.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 13
   </b>
   Let
   <math display="inline">
    X \in \mathcal{H}^2
   </math>
   with the canonical decomposition
   <math display="inline">
    X = N + A
   </math>
   and let
   <math display="inline">
    H, J \in \mathbf{b}\mathcal{P}
   </math>
   . We define the metric
   <math display="inline">
    d_X(H, J)
   </math>
   as
  </p>
  <p block-type="Equation">
   <math display="block">
    d_X(H, J) := \left\| \left( \int_0^\infty (H_s - J_s)^2 \, \mathrm{d}[M, M]_s \right)^{1/2} \right\|_{L^2} + \left\| \int_0^\infty |H_s - J_s|| \, \mathrm{d}A_s| \right\|_{L^2} \tag{33}
   </math>
  </p>
  <p block-type="Text">
   From the monotone class theorem, we obtain the following.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 21
   </b>
   For
   <math display="inline">
    X \in \mathcal{H}^2
   </math>
   , the space
   <b>
    b
   </b>
   L is dense in
   <b>
    b
   </b>
   <math display="inline">
    \mathcal{P}
   </math>
   under
   <math display="inline">
    d_{\mathcal{X}}(\cdot,\cdot)
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   It is straightforward to show that if
   <math display="inline">
    H \in \mathbf{b} \mathbb{L}
   </math>
   and
   <math display="inline">
    X \in
   </math>
   <math display="inline">
    \mathcal{H}^2
   </math>
   , then
   <math display="inline">
    H \cdot X \in \mathcal{H}^2
   </math>
   . The following is an immediate consequence of the definition of
   <math display="inline">
    d_X(\cdot, \cdot)
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 22
   </b>
   Let
   <math display="inline">
    X \in \mathcal{H}^2
   </math>
   and
   <math display="inline">
    (H^n) \subset \mathbf{b} \mathbb{L}
   </math>
   such that
   <math display="inline">
    (H^n)
   </math>
   is Cauchy under
   <math display="inline">
    d_X(\cdot, \cdot)
   </math>
   . Then,
   <math display="inline">
    (H^n \cdot X)
   </math>
   is Cauchy in
   <math display="inline">
    \mathcal{H}^2
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   Moreover, it is easy to show that if
   <math display="inline">
    (H^n) \subset \mathbf{b} \mathbb{L}
   </math>
   and
   <math display="inline">
    (J^n) \subset \mathbf{b} \mathbb{L}
   </math>
   converge to the same limit under
   <math display="inline">
    d_X(\cdot, \cdot)
   </math>
   , then
   <math display="inline">
    (H^n \cdot X)
   </math>
   and
   <math display="inline">
    (J^n \cdot X)
   </math>
   converge to the same limit in
   <math display="inline">
    \mathcal{H}^2
   </math>
   . Thus, we can now define the stochastic integral
   <math display="inline">
    H \cdot X
   </math>
   for any
   <math display="inline">
    H \in \mathbf{b}\mathcal{P}
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 14
   </b>
   Let
   <math display="inline">
    X \in \mathcal{H}^2
   </math>
   and
   <math display="inline">
    H \in \mathbf{b}\mathcal{P}
   </math>
   . Let
   <math display="inline">
    (H^n) \subset
   </math>
   <b>
    b
   </b>
   L
   <i>
    such that
   </i>
   <math display="inline">
    \lim_{n\to\infty} d_X(H^n, H) = 0
   </math>
   .
   <i>
    The stochastic
   </i>
   integral
   <math display="inline">
    H \cdot X
   </math>
   is the unique semimartingale
   <math display="inline">
    Y \in \mathcal{H}^2
   </math>
   such that
   <math display="inline">
    \lim_{n\to\infty} H^n \cdot X = Y
   </math>
   in
   <math display="inline">
    \mathcal{H}^2
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   Note that if
   <math display="inline">
    B
   </math>
   is a standard Brownian motion,
   <math display="inline">
    B
   </math>
   is not in
   <math display="inline">
    \mathcal{H}^2
   </math>
   but
   <math display="inline">
    B^T \in \mathcal{H}^2
   </math>
   for any deterministic and finite T. Therefore, for any
   <math display="inline">
    H \in \mathbf{b}\mathcal{P}
   </math>
   ,
   <math display="inline">
    H \cdot B^T
   </math>
   is well defined. Moreover,
   <math display="inline">
    H \in \mathbf{b}\mathcal{P}
   </math>
   implies
   <math display="inline">
    H \in \mathcal{L}^2(B^T)
   </math>
   where
   <math display="inline">
    \mathcal{L}^2(B^T)
   </math>
   is the space defined in the section
   <math display="inline">
    L^2
   </math>
   Theory of Stochastic Integration with Respect to Brownian Motion. One can easily check that the stochastic integral
   <math display="inline">
    H \cdot B^T
   </math>
   defined by Definition 14 is indistinguishable from the stochastic integral
   <math display="inline">
    H \cdot B^T
   </math>
   defined in the section
   <math display="inline">
    L^2
   </math>
   Theory of Stochastic Integration with Respect to Brownian Motion. Clearly,
   <math display="inline">
    \mathbf{b}\mathcal{P}
   </math>
   is strictly contained in
   <math display="inline">
    \mathcal{L}^2(B^T)
   </math>
   , and we know from the section
   <math display="inline">
    L^2
   </math>
   Theory of Stochastic Integration with Respect to Brownian Motion that it is possible to define the stochastic integral with respect to
   <math display="inline">
    B^T
   </math>
   for any process in
   <math display="inline">
    \mathcal{L}^2(B^T)
   </math>
   . Thus, it is natural to ask whether we can extend the stochastic integral given by Definition 14 to integrands that satisfy a certain square integrability condition.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 15
   </b>
   Let
   <math display="inline">
    X \in \mathcal{H}^2
   </math>
   with the canonical decomposition
   <math display="inline">
    X = M + A
   </math>
   . We say that
   <math display="inline">
    H \in \mathcal{P}
   </math>
   is
   <math display="inline">
    (\mathcal{H}^2, X)
   </math>
   integrable if
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\left(\int_{0}^{\infty}H_{s}^{2}\mathrm{d}[M,M]_{s}\right) + \mathbb{E}\left(\left\{\int_{0}^{\infty}|H_{s}||\mathrm{d}A_{s}|\right\}^{2}\right) &lt; \infty \qquad (34)
   </math>
  </p>
  <p block-type="TextInlineMath">
   It can be shown that if
   <math display="inline">
    H \in \mathcal{P}
   </math>
   is
   <math display="inline">
    (\mathcal{H}^2, X)
   </math>
   integrable,
   <math display="inline">
    (H^n \cdot X)
   </math>
   is a Cauchy sequence in
   <math display="inline">
    \mathcal{H}^2
   </math>
   where
   <math display="inline">
    H^n =
   </math>
   <math display="inline">
    H\mathbf{1}_{\{|H| \le n\}}
   </math>
   is in
   <b>
    b
   </b>
   <math display="inline">
    \mathcal{P}
   </math>
   , which means that we can define the stochastic integral for such
   <math display="inline">
    H
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 16
   </b>
   Let
   <math display="inline">
    X \in \mathcal{H}^2
   </math>
   and let
   <math display="inline">
    H \in \mathcal{P}
   </math>
   be
   <math display="inline">
    (\mathcal{H}^2, X)
   </math>
   integrable. The stochastic integral
   <math display="inline">
    H \cdot X
   </math>
   is defined to be the
   <math display="inline">
    \lim_{n\to\infty} H^n \cdot X
   </math>
   , with convergence in
   <math display="inline">
    \mathcal{H}^2
   </math>
   , where
   <math display="inline">
    H^n = H\mathbf{1}_{\{|H| &lt; n\}}.
   </math>
  </p>
  <p block-type="TextInlineMath">
   In the case
   <math display="inline">
    X = B^T
   </math>
   ,
   <math display="inline">
    M = B^T
   </math>
   , and
   <math display="inline">
    A = 0
   </math>
   ; therefore, H being
   <math display="inline">
    (\mathcal{H}^2, X)
   </math>
   integrable is equivalent to the condition
  </p>
  <p block-type="Equation">
   <math display="block">
    \int_0^I \mathbb{E}(H_s^2) \, \mathrm{d}s &lt; \infty \tag{35}
   </math>
  </p>
  <p block-type="TextInlineMath">
   which gives exactly the elements of
   <math display="inline">
    \mathcal{L}^2(B^T)
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   So far, we have been able to define the stochastic integral with predictable integrands only for semimartingales in
   <math display="inline">
    \mathcal{H}^2
   </math>
   . This seems to be a major restriction. However, as the following theorem shows, it is not. Recall that for a stopping time T,
   <math display="inline">
    X^{T-}
   </math>
   =
   <math display="inline">
    X\mathbf{1}_{[0,T)} + X_{T-}\mathbf{1}_{[T,\infty]}.
   </math>
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 23
   </b>
   Let X be a semimartingale,
   <math display="inline">
    X_0 =
   </math>
   0. Then X is prelocally in
   <math display="inline">
    \mathcal{H}^2
   </math>
   . That is, there exists a nondecreasing sequence of stopping times
   <math display="inline">
    (T^n)
   </math>
   ,
   <math display="inline">
    \lim_{n\to\infty} T^n = \infty
   </math>
   a.s., such that
   <math display="inline">
    X^{T^n -} \in \mathcal{H}^2
   </math>
   , for each
   <math display="inline">
    n \geq 1
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 17
   </b>
   Let
   <math display="inline">
    X
   </math>
   be a semimartingale and
   <math display="inline">
    H \in \mathcal{P}
   </math>
   . The stochastic integral
   <math display="inline">
    H \cdot X
   </math>
   is said to exist if there exists a sequence of stopping times
   <math display="inline">
    (T^n)
   </math>
   increasing to
   <math display="inline">
    \infty
   </math>
   a.s. such that
   <math display="inline">
    X^{T^{n-}} \in \mathcal{H}^2
   </math>
   , for each
   <math display="inline">
    n \ge 1
   </math>
   , and such that
   <math display="inline">
    H
   </math>
   is
   <math display="inline">
    (\mathcal{H}^2, X^{T^n-})
   </math>
   integrable for each
   <math display="inline">
    n \geq 1
   </math>
   . In this case, we write
   <math display="inline">
    H \in L(X)
   </math>
   and define the stochastic integral as
  </p>
  <p block-type="Equation">
   <math display="block">
    H \cdot X = H \cdot (X^{T^{n}}), \qquad on \ [0, T^{n}) \tag{36}
   </math>
  </p>
  <p block-type="Text">
   for each n.
  </p>
  <p block-type="Text">
   A particular case when
   <math display="inline">
    H \cdot X
   </math>
   is well defined is when
   <math display="inline">
    H
   </math>
   is locally bounded.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 24
   </b>
   Let
   <i>
    X
   </i>
   be a semimartingale and
   <math display="inline">
    H \in \mathcal{P}
   </math>
   be locally bounded. Then,
   <math display="inline">
    H \in L(X)
   </math>
   .
  </p>
  <p block-type="Text">
   We also have the martingale preservation property.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 25
   </b>
   Let
   <math display="inline">
    M
   </math>
   be a local martingale and
   <math display="inline">
    H \in \mathcal{P}
   </math>
   be locally bounded. Then,
   <math display="inline">
    H \cdot M
   </math>
   is a local martingale.
  </p>
  <p block-type="TextInlineMath">
   The general result that
   <math display="inline">
    M
   </math>
   a local martingale and
   <math display="inline">
    H \in L(M)
   </math>
   implies that
   <math display="inline">
    H \cdot M
   </math>
   is a local martingale is not true. The following example is due to Emery and can be taken as a starting point for a study of
   <i>
    sigma
   </i>
   martingales (see Equivalent Martingale Measures).
  </p>
  <p block-type="Text" class="has-continuation">
   <b>
    Example 3
   </b>
   Let
   <math display="inline">
    T
   </math>
   be an exponential random variable with parameter 1 and let
   <math display="inline">
    U
   </math>
   be an independent
  </p>
  <p block-type="TextInlineMath">
   random variable with
   <math display="inline">
    \mathbb{P}(U=1) = \mathbb{P}(U=-1) =
   </math>
   <math display="inline">
    1/2
   </math>
   , and set
   <math display="inline">
    X = U\mathbf{1}_{[T,\infty)}
   </math>
   . Then, X is a martingale in its own filtration. Let
   <i>
    H
   </i>
   be defined as
   <math display="inline">
    H_t = \frac{1}{t} \mathbf{1}_{\{t&gt;0\}}
   </math>
   .
   <math display="inline">
    H
   </math>
   is a deterministic predictable integral. Note that
   <math display="inline">
    H
   </math>
   is not locally bounded, being only continuous on
   <math display="inline">
    (0, \infty)
   </math>
   .
   <math display="inline">
    H \cdot X
   </math>
   exists as a Lebesgue-Stieltjes integral since X has paths of finite variation. However,
   <math display="inline">
    H \cdot X
   </math>
   is not a local martingale since, for any stopping time S with
   <math display="inline">
    P(S &gt; 0) &gt; 0
   </math>
   ,
   <math display="inline">
    \mathbb{E}(|(H \cdot X)_S|) = \infty
   </math>
   .
  </p>
  <p block-type="Text">
   When
   <math display="inline">
    M
   </math>
   is a continuous local martingale, the theory becomes nicer.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 26
   </b>
   Let
   <math display="inline">
    M
   </math>
   be a continuous local martingale and let
   <math display="inline">
    H \in \mathcal{P}
   </math>
   be such that
   <math display="inline">
    \int_0^t H_s^2 d[M, M]_s &lt;
   </math>
   <math display="inline">
    \infty
   </math>
   , for each
   <math display="inline">
    t \geq 0
   </math>
   . Then
   <math display="inline">
    H \in L(M)
   </math>
   and
   <math display="inline">
    H \cdot M
   </math>
   is a continuous local martingale.
  </p>
  <p block-type="Text">
   The question may arise as to whether the properties of stochastic integral stated for left-continuous integrands in the section Properties of Stochastic Integrals continue to hold when we allow predictable integrands. The answer is positive except for Theorems 13 and 14. Still, if
   <math display="inline">
    X
   </math>
   is a semimartingale with paths of finite variation on compacts and if
   <math display="inline">
    H \in L(X)
   </math>
   is such that the Stieltjes integral
   <math display="inline">
    \int_0^t |H_s| |dX_s|
   </math>
   exists a.s. for each
   <math display="inline">
    t \ge 0
   </math>
   , then the stochastic integral
   <math display="inline">
    H \cdot X
   </math>
   agrees with the Stieltjes integral computed path by path. However,
   <math display="inline">
    H \cdot X
   </math>
   is not necessarily an FV process. See [7, Exercise 45] in Chapter IV] of [7] for a counterexample. The analogous result for Theorem 13 is the following, which is particularly useful when one needs to study asymmetric information in financial markets where some traders possess extra information compared to others.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 27
   </b>
   Let
   <math display="inline">
    \mathbb{G}
   </math>
   be another filtration satisfying the usual hypotheses and suppose that
   <math display="inline">
    \mathcal{F}_t \subset \mathcal{G}_t
   </math>
   , each
   <math display="inline">
    t &gt; 0
   </math>
   , and that X remains a semimartingale with respect to
   <math display="inline">
    \mathbb{G}
   </math>
   . Let H be locally bounded and predictable for
   <math display="inline">
    \mathbb{F}
   </math>
   . Then H is locally bounded and predictable for
   <math display="inline">
    \mathbb{G}
   </math>
   , the stochastic integral
   <math display="inline">
    H_{\mathbb{G}} \cdot X
   </math>
   exists and is equal to
   <math display="inline">
    H_{\mathbb{F}} \cdot X
   </math>
   .
  </p>
  <p block-type="Text">
   It is important to have
   <math display="inline">
    H
   </math>
   locally bounded in the above theorem; see [4] for a counterexample in the context of enlargement of filtrations.
  </p>
  <p block-type="Text">
   We end this section with the
   <i>
    dominated conver
   </i>
   gence theorem for stochastic integrals.
  </p>
  <p block-type="TextInlineMath">
   <b>
    Theorem 28
   </b>
   Let
   <math display="inline">
    X
   </math>
   be a semimartingale and
   <math display="inline">
    (H^n) \subset \mathcal{P}
   </math>
   be a sequence converging a.s. to a limit
   <math display="inline">
    H \in \mathcal{P}
   </math>
   . If there exists a process
   <math display="inline">
    G \in L(X)
   </math>
   such that
   <math display="inline">
    |H^n| \leq G
   </math>
   , for all n, then
   <math display="inline">
    H^n \in L(X)
   </math>
   for all
   <math display="inline">
    n, H \in
   </math>
   <math display="inline">
    L(X)
   </math>
   and
   <math display="inline">
    (H^n \cdot X)
   </math>
   converges to
   <math display="inline">
    H \cdot X
   </math>
   in UCP.
  </p>
  <h3>
   <b>
    Concluding Remarks
   </b>
  </h3>
  <p block-type="Text">
   In this article, we used the approach of Protter [7] to define the semimartingale as a good integrator and construct its stochastic integral. Another approach that is closely related is given by Chou
   <i>
    et al.
   </i>
   [1], who developed the stochastic integration for general predictable integrands with respect to a semimartingale in a space endowed with the semimartingale topology. Historically, the stochastic integral was first proposed for Brownian motion by Itô [3], then for continuous martingales, then for square integrable martingales, and finally for càdlàg processes that can be written as the sum of a locally square integrable local martingale and an FV process by J.L. Doob, H. Kunita, S. Watanabe, P. Courrège, P.A. Meyer, and others. Later in 1970, Doléans-Dade and Meyer [2] showed that the local square integrability condition could be relaxed, which led to the traditional definition of a semimartingale as a sum of a local martingale and an FV process. A different theory of stochastic integration, the
   <i>
    Itô-belated integral
   </i>
   , was developed by McShane [5]. It imposed different restrictions on the integrators and the integrands and used a theory of "gauges" and appeared to be very different from the approach here. It turns out, however, that when the integral
   <math display="inline">
    \int H dX
   </math>
   made sense both as a stochastic integral in the sense developed here and as an Itô-belated integral, they were indistinguishable. See [6] for a comparison of these two integrals. Another related stochastic integral is called the Fisk-Stratonovich (FS) integral that was developed by Fisk and Stratonovich independently. The FS integral obeys the integration by parts formula for FV
  </p>
  <p block-type="Text">
   processes when at least one of the integrand or the integrator is continuous.
  </p>
  <h3>
   <b>
    End Notes
   </b>
  </h3>
  <p block-type="Text">
   &lt;sup&gt;a.&lt;/sup&gt; See Definition 5 for the definition of a predictable process. &lt;sup&gt;b.&lt;/sup&gt;For a proof of the fact that
   <math display="inline">
    \mathbb{D}_{\text{UCP}}
   </math>
   is metrizable and complete under that metric, see [7].
  </p>
  <p block-type="Text">
   &lt;sup&gt;c.&lt;/sup&gt;This sum converges to the
   <i>
    quadratic variation
   </i>
   of
   <math display="inline">
    B
   </math>
   over the interval
   <math display="inline">
    [0, t]
   </math>
   as we see in Theorem 16.
  </p>
  <h4>
   References
  </h4>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     [1] Chou, C.S., Meyer, P.A. &amp; Stricker, C. (1980). Sur les intégrales stochastiques de processus prévisibles non bornés, Séminaire de Probabilités, XIV. Lecture Notes in Mathematics, 784, Springer, Berlin, pp. 128-139.
    </li>
    <li block-type="ListItem">
     [2] Doléans-Dade, C. &amp; Meyer, P.-A. (1970). Intégrales stochastiques par rapport aux martingales locales, Séminaire de Probabilités, IV. Lecture Notes in Mathematics, 124, Springer, Berlin, pp. 77-107.
    </li>
    <li block-type="ListItem">
     [3] Itô, K. (1944). Stochastic integral, Proceedings of the Imperial Academy of Tokyo 20, 519-524.
    </li>
    <li block-type="ListItem">
     [4] Jeulin, T. (1980). Semi-martingales et Grossissement d'une Filtration, Lecture Notes in Mathematics, Springer, Berlin, Vol. 833.
    </li>
    <li block-type="ListItem">
     [5] McShane, E.J. (1974).
     <i>
      Stochastic Calculus and Stochastic
     </i>
     Models, Probability and Mathematical Statistics, Academic Press, New York, Vol. 25.
    </li>
    <li block-type="ListItem">
     [6] Protter, P. (1979). A comparison of stochastic integrals, The Annals of Probability 7(2), 276–289.
    </li>
    <li block-type="ListItem">
     [7] Protter, P. (2005). Stochastic Integration and Differential
     <i>
      Equations
     </i>
     , 2nd Edition, Version 2.1, Springer, Berlin.
    </li>
   </ul>
  </p>
  <h3>
   <b>
    Related Articles
   </b>
  </h3>
  <p block-type="Text">
   Arbitrage Strategy; Complete Markets; Equivalent Martingale Measures: Filtrations: Itô's Formula; Martingale Representation Theorem; Semimartingale.
  </p>
  <p block-type="Text">
   Umut Cetin
  </p>
 </body>
</html>
