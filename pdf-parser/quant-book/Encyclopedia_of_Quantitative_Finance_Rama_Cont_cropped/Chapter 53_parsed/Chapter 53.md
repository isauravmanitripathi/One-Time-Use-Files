# Semimartingale

Semimartingales form an important class of processes in probability theory, especially in the theory of stochastic integration and its applications. They serve as natural models for asset pricing, since under no-arbitrage assumptions a price process must be a semimartingale  $[1, 3]$ .

Let  $(\Omega, \mathcal{F}, \mathbb{F} = (\mathcal{F}_t)_{t>0}, P)$  be a complete probability space that satisfies the *usual assumptions* (i.e.,  $\mathcal{F}_0$  contains all *P*-null sets of  $\mathcal{F}$  and the filtration  $\mathbb{F}$ is right continuous). A càglàd, adapted process  $X$  is called a *semimartingale* if it admits a decomposition

$$X_t = X_0 + A_t + M_t \tag{1}$$

where  $X_0$  is  $\mathcal{F}_0$ -measurable, A is a process with finite variation, *M* is a local martingale, and  $A_0 =$  $M_0 = 0$ . If, moreover, A is predictable (i.e., measurable with respect to the  $\sigma$ -algebra generated by all left-continuous processes),  $X$  is called a *special* semimartingale. In this case, the decomposition (1) is unique and we call it the canonical decomposi*tion*. Clearly, the set of all semimartingales is a vector space.

For any  $a > 0$ , a semimartingale X can be further decomposed as

$$X_t = X_0 + A_t + D_t + N_t \tag{2}$$

where  $D$  and  $N$  are local martingales such that  $D$  is a process with finite variation and the jumps of  $N$  are bounded by  $2a$  (see [6] p. 126).

Alternatively, semimartingales can be defined as a class of "good integrators". Let  $S$  be a collection of all simple predictable processes equipped with the uniform convergence in  $(t, \omega)$ . A process H is called simple predictable if it has the representation

$$H_{t} = H_{0}1_{\{0\}}(t) + \sum_{i=1}^{n} H_{i}1_{(T_{i},T_{i+1}]}(t) \qquad (3)$$

where  $0 = T_1 \leq \cdots \leq T_{n+1} < \infty$  are stopping times,  $H_i$  are  $\mathcal{F}_{T_i}$ -measurable and  $|H_i| < \infty$  almost surely. Let  $L^0$  be the space of (finite-valued) random variables topologized by convergence in probability. For a given process  $X$ , we define a linear mapping (*stochastic integral*)  $I_X: S \to L^0$  by

$$I_X(H) = H_0 X_0 + \sum_{i=1}^n H_i (X_{T_{i+1}} - X_{T_i}) \qquad (4)$$

A process  $X$  is defined to be a semimartingale if it is càglàd, adapted, and the mapping  $I_X: S \to L^0$ is continuous. Such processes are "good integrators", because they satisfy the following bounded convergence theorem: the uniform convergence of  $H^n$  to  $H$  (in  $S$ ) implies the convergence in probability of  $I_X(H^n)$  to  $I_X(H)$ . As a consequence, when X is a semimartingale, the domain of the stochastic integral  $I_X$  can be extended to the space of all predictable processes  $H$  (see Stochastic Integrals).

Indeed, these two definitions are equivalent. This result is known as the *Bichteler–Dellacherie theorem* [2, 4].

# Examples

- Càglàd adapted processes with finite variation . are semimartingales.
- All càglàd, adapted martingales, submartingales, and supermartingales are semimartingales.
- Brownian motion is a continuous martingale. Hence, it is a semimartingale.
- Lévy processes are semimartingales.
- Itô diffusions of the form

$$X_t = X_0 + \int_0^t a_s \mathrm{d}s + \int_0^t \sigma_s \mathrm{d}W_s \tag{5}$$

where  $W$  is a Brownian motion, are (continuous) semimartingales. In particular, solutions of stochastic differential equations of the type  $dX_t = a(t, X_t)dt +$  $\sigma(t, X_t) dW_t$  are semimartingales.

## **Quadratic Variation of Semimartingales**

Ouadratic variation is an important characteristic of a semimartingale. It is also one of the crucial objects in financial econometrics as it serves as a measure of the variability of a price process.

Let  $X, Y$  be semimartingales. The quadratic variation process  $[X, X] = ([X, X]_t)_{t \ge 0}$  is given as

$$[X, X]_t = X_t^2 - X_0^2 - 2\int_0^t X_{s-} \mathrm{d}X_s \qquad (6)$$

where  $X_{s-} = \lim_{u \le s, u \to s} X_s$   $(X_{0-} = X_0)$ . The quadratic covariation of  $X$  and  $Y$  is defined by

$$[X, Y]_{t} = X_{t}Y_{t} - X_{0}Y_{0} - \int_{0}^{t} X_{s-}dY_{s} - \int_{0}^{t} Y_{s-}dX_{s}$$
(7)

which is also known as the integration by parts formula (see [5] p. 51). Obviously, the operator  $(X, Y) \to [X, Y]$  is symmetric and bilinear. We therefore have the polarization identity

$$[X,Y] = \frac{1}{2}([X+Y,X+Y] - [X,X] - [Y,Y])$$
(8)

The quadratic (co-)variation process has the following properties:

- with  $\Delta Z_s = Z_s Z_{s-}$ 1.  $\Delta[X, Y] = \Delta X \Delta Y$  $(\Delta Z_0 = 0)$  for any càglàd process Z.
- 2.  $[X, Y]$  has finite variation and  $[X, X]$  is an increasing process.
- 3. Let  $A, B$  be càglàd, adapted processes. Then it holds that

$$\left[\int A_s \, \mathrm{d}X_s, \int B_s \, \mathrm{d}Y_s\right]_t = \int_0^t A_s B_s \, \mathrm{d}[X, Y]_s \tag{9}$$

Furthermore, the quadratic variation process can be written as a sum of its continuous and discontinuous parts:

$$[X, X]_t = [X, X]_t^c + \sum_{0 \le s \le t} |\Delta X_s|^2 \qquad (10)$$

where  $[X, X]^c$  denotes the continuous part of  $[X, X]$ . A semimartingale  $X$  is called *quadratic pure jump* if  $[X, X]^{c} = 0.$ 

For any subdivision  $0 = t_0^n < \cdots < t_{k_n}^n = t$  with  $\max_i |t_i^n - t_{i-1}^n| \to 0$ , it holds that

$$\sum_{i=1}^{k_n} (X_{t_i^n} - X_{t_{i-1}^n})(Y_{t_i^n} - Y_{t_{i-1}^n}) \xrightarrow{p} [X, Y]_t \quad (11)$$

The latter suggests the *realized variance* as a natural consistent estimator of the quadratic variation (see **Realized Volatility and Multipower Variation**).

### **Stability Properties of Semimartingales**

Semimartingales turn out to be invariant under change of measure. Indeed, if  $O$  is a probability measure that is absolutely continuous with respect to  $P$ , then every  $P$ -semimartingale is a  $Q$ -semimartingale. When  $X$  is a  $P$ -semimartingale with decomposition (1) and  $P$ ,  $Q$  are equivalent probability measures, then  $X$  is a  $Q$ -semimartingale with the decomposition  $X_t = X_0 + \tilde{A}_t + \tilde{M}_t$ , where

$$\tilde{M}_{t} = M_{t} - \int_{0}^{t} \frac{1}{Z_{s}} d[Z, M]_{s} \qquad (12)$$

 $Z_t = E_P\left(\frac{\mathrm{d}Q}{\mathrm{d}P}|\mathcal{F}_t\right)$  and  $\tilde{A}_t = X_t - X_0 - \tilde{M}_t$ . The latter result is known as Girsanov's Theorem (see [6] p. 133).

Furthermore, semimartingales are stable under certain changes of filtration. Let  $X$  be a semimartingale for the filtration  $\mathbb{F}$ . If  $\mathbb{G} \subset \mathbb{F}$  is a subfiltration and  $X$  is adapted to  $\mathbb{G}$ , then  $X$  is a semimartingale for  $\mathbb{G}$  (*Stricker's Theorem*). Semimartingales are also invariant to certain enlargement of filtration. Let  $\mathcal{A} \subset$  $\mathcal{F}$  be a collection of events such that  $A, B \in \mathcal{A}, A \neq$ B, implies  $A \cap B = \emptyset$ . Let  $\mathcal{H}_t$  be generated by  $\mathcal{F}_t$  and A. Then every  $(\mathbb{F}, P)$ -semimartingale is a  $(\mathbb{H}, P)$ semimartingale (Jacod's Countable Expansion).

## Itô's Formula

Semimartingales are stable under  $C^2$ -transformation. Let  $X = (X^1, \ldots, X^d)$  be a d-dimensional semimartingale and  $f: \mathbb{R}^d \to \mathbb{R}$  be a function with continuous second-order partial derivatives. Then  $f(X)$ is again a semimartingale and the Itô's Formula holds:

$$\begin{split} f(X_t) - f(X_0) \\ &= \sum_{i=1}^d \int_0^t \frac{\partial f}{\partial x_i} (X_{s-}) \, \mathrm{d}X_s \\ &+ \frac{1}{2} \sum_{i,j=1}^d \int_0^t \frac{\partial^2 f}{\partial x_i \partial x_j} (X_{s-}) \, \mathrm{d}[X^i, X^j]_s^c \\ &+ \sum_{0 \le s \le t} \left( f(X_s) - f(X_{s-}) \right. \\ &\left. - \sum_{i=1}^d \frac{\partial f}{\partial x_i} (X_{s-}) \Delta X_s^i \right) \end{split} \tag{13}$$

One of the most interesting applications of Itô's formula is the so-called *Doléans–Dade exponen* $tial$  (see Stochastic Exponential). Let  $X$  be a (one-dimensional) semimartingale with  $X_0 = 0$ . Then there exists a unique semimartingale  $Z$  that satisfies the equation  $Z_t = 1 + \int_0^t Z_{s-} \, dX_s$ . This solution is denoted by  $\mathcal{E}(X)$  (the Doléans–Dade exponential) and is given by

$$\mathcal{E}(X)_t = \exp\left(X_t - \frac{1}{2}[X, X]_t\right) \prod_{0 \le s \le t} (1 + \Delta X_s)$$
$$\times \exp\left(-\Delta X_s + \frac{1}{2} |\Delta X_s|^2\right) \tag{14}$$

Moreover, we obtain the identity  $\mathcal{E}(X)\mathcal{E}(Y) = \mathcal{E}(X +$  $Y + [X, Y]$ .

An important example is  $X_t = at + \sigma W_t$ , where W denotes the Brownian motion and  $a, \sigma$  are constant. In this case, the continuous solution  $\mathcal{E}(X)_t =$  $\exp\left(\left(a-\frac{\sigma^2}{2}\right)t+\sigma W_t\right)$  is known as the *Black–Scholes model*.

## References

[1] Back, K. (1991). Asset prices for general processes, Journal of Mathematical Economics 20(4), 371-395.

- [2] Bichteler, K. (1981). Stochastic integration and  $Lp$ -theory of semimartingales, Annals of Probability 9, 49-89.
- [3] Delbaen, F. & Schachermayer, W. (1994). A general version of the fundamental theorem of asset pricing, Mathematische Annalen 300, 463-520.
- Dellacherie, C. (1980). Un survol de la théorie de [4] l'intégrale stochastique, Stochastic Processes and their Applications 10, 115-144.
- [5] Jacod, J. & Shiryaev, A.N. (2003). Limit Theorems for Stochastic Processes, 2nd Edition, Springer-Verlag.
- [6] Protter, P.E. (2005). Stochastic Integration and Differential Equations, 2nd Edition, Springer-Verlag.

# **Further Reading**

Revuz, D. & Yor, M. (2005). Continuous Martingales and Brownian Motion, 3rd Edition, Springer-Verlag.

### **Related Articles**

Doob-Meyer Decomposition; Equivalence of Probability Measures; Filtrations; Itô's Formula; Martingales; Poisson Process; Stochastic Exponential; **Stochastic Integrals.** 

MARK PODOLSKIJ