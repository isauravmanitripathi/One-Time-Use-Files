<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
 </head>
 <body>
  <h1>
   Filtering
  </h1>
  <h1>
   <b>
    The Filtering Problem
   </b>
  </h1>
  <p block-type="TextInlineMath">
   Consider a randomly evolving system, the state of which is denoted by
   <math display="inline">
    x_t
   </math>
   and this state may not be directly observable. Denote by
   <math display="inline">
    y_t
   </math>
   the observation at time
   <math display="inline">
    t \in [0, T]
   </math>
   (
   <math display="inline">
    x_t
   </math>
   and
   <math display="inline">
    y_t
   </math>
   may be vector-valued):
   <math display="inline">
    y_t
   </math>
   is supposed to be probabilistically related to
   <math display="inline">
    x_t
   </math>
   . For instance,
   <math display="inline">
    y_t
   </math>
   may represent a noisy measurement of
   <math display="inline">
    x_t
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   The process
   <math display="inline">
    x_t
   </math>
   is generally supposed to evolve in a Markovian way according to a given (
   <i>
    a priori
   </i>
   ) distribution
   <math display="inline">
    p(x_t | x_s)
   </math>
   ,
   <math display="inline">
    s &lt; t
   </math>
   . The dynamics of
   <math display="inline">
    y_t
   </math>
   are given in terms of the process
   <math display="inline">
    x_t
   </math>
   ; a general assumption is that, given
   <math display="inline">
    x_t
   </math>
   , the process
   <math display="inline">
    y_t
   </math>
   is independent of its past and so one may consider as given the distribution
   <math display="inline">
    p(y_t | x_t)
   </math>
   . The information on
   <math display="inline">
    x_t
   </math>
   at a given
   <math display="inline">
    t \in [0, T]
   </math>
   is thus represented by the past and present observations of
   <math display="inline">
    y_t
   </math>
   , that is, by
   <math display="inline">
    y_0^t := \{y_s; s \leq
   </math>
   <i>
    t
   </i>
   } or, equivalently, by the filtration
   <math display="inline">
    \mathcal{F}_t^y := \sigma\{y_s; s \leq t\}
   </math>
   <math display="inline">
    t
   </math>
   }. This information, combined with the
   <i>
    a priori
   </i>
   dynamics of x given by
   <math display="inline">
    p(x_t | x_s)
   </math>
   can, via a Bayestype formula, be synthesized in the conditional or posterior distribution
   <math display="inline">
    p(x_t | y_0^t)
   </math>
   of
   <math display="inline">
    x_t
   </math>
   , given
   <math display="inline">
    y_0^t
   </math>
   , and this distribution is called the
   <i>
    filter distribution
   </i>
   .
  </p>
  <p block-type="TextInlineMath">
   The filtering problem consists now in determining, possibly in a recursive way, the filter distribution at each
   <math display="inline">
    t \leq T
   </math>
   . It can also be seen as a dynamic extension of Bayesian statistics: for
   <math display="inline">
    x_t \equiv x
   </math>
   an unknown parameter, the dynamic model for x given by
   <math display="inline">
    p(x_t)
   </math>
   <math display="inline">
    x_s
   </math>
   ) reduces to a prior distribution for x and the filter
   <math display="inline">
    p(x \mid y_0^t)
   </math>
   is then simply the posterior distribution of x, given the observations
   <math display="inline">
    y_s
   </math>
   ,
   <math display="inline">
    s \le t
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   In many applications, it suffices to determine a synthetic value of the filter distribution
   <math display="inline">
    p(x_t | y_0^t)
   </math>
   . In particular, given an (integrable) function
   <math display="inline">
    f(\cdot)
   </math>
   , one may want to compute
  </p>
  <p block-type="Equation">
   <math display="block">
    E\{f(x_t) \mid y_0^t\} = E\{f(x_t) \mid \mathcal{F}_t^y\}
   </math>
   <math display="block">
    = \int f(x) \, \mathrm{d}p(x \mid y_0^t) \qquad (1)
   </math>
  </p>
  <p block-type="TextInlineMath">
   The quantity in equation
   <math display="inline">
    (1)
   </math>
   may be seen as the best estimate of
   <math display="inline">
    f(x_t)
   </math>
   , given
   <math display="inline">
    y_0^t
   </math>
   , with respect to the mean square error criterion in the sense that
   <math display="inline">
    E\{(E\{f(x_t) | \}
   </math>
   <math display="inline">
    y_0^t
   </math>
   -
   <math display="inline">
    f(x_t)^2 \le E\{(g(y_0^t) - f(x_t))^2\}
   </math>
   for all measurable (and integrable) functions
   <math display="inline">
    g(y_0^t)
   </math>
   of the available information. In this sense, one may also consider
  </p>
  <p block-type="TextInlineMath">
   <math display="inline">
    E\{f(x_t) \mid \mathcal{F}_t^y\}
   </math>
   as the
   <i>
    optimal filter
   </i>
   for
   <math display="inline">
    f(x_t)
   </math>
   . Notice that determining
   <math display="inline">
    E\{f(x_t) | \mathcal{F}_t^y\}
   </math>
   is no more restrictive than determining the entire filter distribution
   <math display="inline">
    p(x_t | y_0^t)
   </math>
   ; in fact, by taking
   <math display="inline">
    f(x) = e^{i\lambda x}
   </math>
   for a generic
   <math display="inline">
    \lambda
   </math>
   , the
   <math display="inline">
    E\{f(x_t) \mid \mathcal{F}_t^y\}
   </math>
   in equation (1) leads to the conditional characteristic function of
   <math display="inline">
    x_t
   </math>
   given
   <math display="inline">
    y_0^t
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   Related to the filtering problem, are the
   <i>
    prediction problem
   </i>
   , that is, that of determining
   <math display="inline">
    p(x_t | y_0^s)
   </math>
   for
   <math display="inline">
    s &lt; t
   </math>
   , and the interpolation or smoothing problem concerning
   <math display="inline">
    p(x_t | y_0^s)
   </math>
   for
   <math display="inline">
    t &lt; s
   </math>
   . Given the Bayesian nature of the filtering problem, one can also consider the so-called
   <i>
    combined filtering and parameter estimation problem
   </i>
   : if the dynamics
   <math display="inline">
    p(x_t | x_s)
   </math>
   for x include an unknown parameter
   <math display="inline">
    \theta
   </math>
   , one may consider the problem of determining the joint conditional distribution
   <math display="inline">
    p(x_t, \theta \mid \mathcal{F}_t^y)
   </math>
   .
  </p>
  <h1>
   Models for the Filtering Problem
  </h1>
  <p block-type="TextInlineMath">
   To solve a given filtering problem, one has to specify the two basic inputs, namely,
   <math display="inline">
    p(x_t | x_s)
   </math>
   and
   <math display="inline">
    p(y_t |
   </math>
   <math display="inline">
    x_t
   </math>
   ). A classical model in discrete time is
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{cases}\n x_{t+1} = a(t, x_t) + b(t, x_t) w_t \\
 y_t = c(t, x_t) + v_t\n\end{cases} \n
   </math>
   (2)
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    w_t
   </math>
   and
   <math display="inline">
    v_t
   </math>
   are (independent) sequences of independent random variables and the distribution of
   <math display="inline">
    x_0
   </math>
   is given. Notice that in equation (2) the process
   <math display="inline">
    x_t
   </math>
   is Markov and
   <math display="inline">
    y_t
   </math>
   represents the indirect observations of
   <math display="inline">
    x_t
   </math>
   , affected by additive noise.
  </p>
  <p block-type="Text">
   The continuous time counterpart is
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{cases} \mathrm{d}x_t = a(t, x_t) \, \mathrm{d}t + b(t, x_t) \, \mathrm{d}w_t \\ \mathrm{d}y_t = c(t, x_t) \, \mathrm{d}t + \mathrm{d}v_t \end{cases} \tag{3}
   </math>
  </p>
  <p block-type="Text">
   and notice that, here,
   <math display="inline">
    y_t
   </math>
   represents the cumulative observations up to
   <math display="inline">
    t
   </math>
   . These basic models allow for various extensions:
   <math display="inline">
    x_t
   </math>
   may, for example, be a jump-diffusion process or a Markov process with a finite number of states, characterized by its transition intensities. Also the observations may more generally be a jump-diffusion such as
  </p>
  <p block-type="Equation">
   <math display="block">
    dy_t = c(t, x_t) dt + dv_t + dN_t
   </math>
   (4)
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    N_t
   </math>
   is a doubly stochastic Poisson process, the intensity
   <math display="inline">
    \lambda_t = \lambda(x_t)
   </math>
   of which depends on
   <math display="inline">
    x_t
   </math>
   . Further generalizations are, of course, possible.
  </p>
  <h2>
   Analytic Solutions of the Filtering Problem
  </h2>
  <p block-type="Text">
   <b>
    Discrete Time.
   </b>
   By the Markov property of the process
   <math display="inline">
    x_t
   </math>
   and the fact that, given
   <math display="inline">
    x_t
   </math>
   , the process
   <math display="inline">
    v_t
   </math>
   is independent of its past, with the use of Bayes' formula one easily obtains the following two-step recursions
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{cases} p(x_t \mid y_0^{t-1}) = \int p(x_t \mid x_{t-1}) \, \mathrm{d}p(x_{t-1} \mid y_0^{t-1}) \\ p(x_t \mid y_0^t) \propto p(y_t \mid x_t) p(x_t \mid y_0^{t-1}) \end{cases} \tag{5}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    \propto
   </math>
   denotes "proportional to" and the first step corresponds to the
   <i>
    prediction step
   </i>
   while the second one is the updating step. The recursions start with
   <math display="inline">
    p(x_0 | y_0^0) = p(x_0)
   </math>
   . Although equation (5) represents a fully recursive relation, its actual computation is made difficult not only by the presence of the integral in
   <math display="inline">
    x_{t-1}
   </math>
   , but also by the fact that this integral is parameterized by
   <math display="inline">
    x_t
   </math>
   that, in general, takes infinitely many values. Depending on the model, one can however obtain explicit solutions as will be shown below. The most general of such situations arises when one can find a finitely parameterized class of distributions of
   <math display="inline">
    x_t
   </math>
   that is closed under the operator implicit in equation
   <math display="inline">
    (5)
   </math>
   , that is, such that, whenever
   <math display="inline">
    p(x_{t-1} | y_0^{t-1})
   </math>
   belongs to this class, then
   <math display="inline">
    p(x_t | y_0^t)
   </math>
   also belongs to it. A classical case is the linear conditionally Gaussian case that corresponds to a model of the form
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{cases}\n x_{t+1} = A_t(y_0^t)x_t + B_t(y_0^t) w_t \\
 y_t = C_t(y_0^t)x_t + R_t(y_0^t) v_t\n\end{cases} \n
   </math>
   (6)
  </p>
  <p block-type="TextInlineMath">
   where the coefficients may depend on the entire past of the observations
   <math display="inline">
    y_t
   </math>
   , and
   <math display="inline">
    w_t
   </math>
   ,
   <math display="inline">
    v_t
   </math>
   are independent i.i.d. sequences of standard Gaussian random variables. For such a model,
   <math display="inline">
    p(x_t | y_0^t)
   </math>
   is Gaussian at each
   <math display="inline">
    t
   </math>
   and therefore characterized by mean and (co)variance that can be recursively computed by the well-known Kalman-Bucy filter. Denoting
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{aligned}\n\hat{x}_{t|t-1} &amp;:= E\{x_t \mid y_0^{t-1}\}; \hat{x}_{t|t} := E\{x_t \mid y_0^t\} \\
P_{t|t-1} &amp;:= E\{(x_t - \hat{x}_{t|t-1})(x_t - \hat{x}_{t|t-1})' \mid y_0^{t-1}\} \tag{7} \\
P_{t|t} &amp;:= E\{(x_t - \hat{x}_{t|t})(x_t - \hat{x}_{t|t})' \mid y_0^t\}\n\end{aligned}
   </math>
  </p>
  <p block-type="Text">
   the Kalman-Bucy filter is given by (dropping for simplicity the dependence on
   <math display="inline">
    y_0^t
   </math>
   ),
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{cases}\n\hat{x}_{t|t-1} = A_{t-1}\,\hat{x}_{t-1|t-1} \\
P_{t|t-1} = A_{t-1}\,P_{t-1|t-1}A'_{t-1} + B_{t-1}B'_{t-1}\n\end{cases} \n\tag{8}
   </math>
  </p>
  <p block-type="Text">
   which represents the
   <i>
    prediction step
   </i>
   , and
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{aligned}\n\hat{x}_{t|t} &amp;= \hat{x}_{t|t-1} + L_t[y_t - C_t \hat{x}_{t|t-1}] \\
P_{t|t} &amp;= P_{t|t-1} - L_t C_t P_{t|t-1} \n\end{aligned} \tag{9}
   </math>
  </p>
  <p block-type="TextInlineMath">
   which represents the
   <i>
    updating step
   </i>
   with
   <math display="inline">
    \hat{x}_{0|-1}
   </math>
   the mean of
   <math display="inline">
    x_0
   </math>
   and
   <math display="inline">
    P_{0|-1}
   </math>
   its variance. Furthermore,
  </p>
  <p block-type="Equation">
   <math display="block">
    L_t := P_{t|t-1}C'_t[C_t P_{t|t-1}C'_t + R_t R'_t]^{-1}
   </math>
   (10)
  </p>
  <p block-type="Text">
   Notice that, in the prediction step, the estimate of
   <math display="inline">
    x_t
   </math>
   is propagated one step further on the basis of the given
   <i>
    a priori
   </i>
   dynamics of
   <math display="inline">
    x_t
   </math>
   , while in the updating step one takes into account the additional information coming from the current observation. A crucial role in the updating step given by equation
   <math display="inline">
    (9)
   </math>
   is played by
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{aligned} y_t - C_t \hat{x}_{t|t-1} &amp;= y_t - C_t A_{t-1} \hat{x}_{t-1|t-1} \\ &amp;= y_t - C_t E\{x_t \mid y_0^{t-1}\} \\ &amp;= y_t - E\{y_t \mid y_0^{t-1}\} \end{aligned} \tag{11}
   </math>
  </p>
  <p block-type="TextInlineMath">
   which represents the new information given by
   <math display="inline">
    y_t
   </math>
   with respect to its best estimate
   <math display="inline">
    E\{y_t \mid y_0^{t-1}\}
   </math>
   and is therefore called
   <i>
    innovation
   </i>
   .
  </p>
  <p block-type="Text">
   The Kalman-Bucy filter has been extremely successful and has also been applied to Gaussian models that are nonlinear by simply linearizing the nonlinear coefficient functions around the current best estimate of
   <math display="inline">
    x_t
   </math>
   . In this way, one obtains an approximate filter, called the
   <i>
    extended Kalman filter
   </i>
   .
  </p>
  <p block-type="TextInlineMath">
   Exact solutions for the discrete time filtering problem can also be obtained for the case when
   <math display="inline">
    x_t
   </math>
   is a finite-state Markov chain with, say,
   <math display="inline">
    N
   </math>
   states defined by its transition probability matrix. In this case, the filter is characterized by its conditional state probability vector that we denote by
   <math display="inline">
    \pi_t =
   </math>
   <math display="inline">
    (\pi_t^1, \ldots, \pi_t^N)
   </math>
   with
   <math display="inline">
    \pi_t^i := P\{x_t = i \mid \mathcal{F}_t^y\}.
   </math>
  </p>
  <p block-type="Text" class="has-continuation">
   Continuous Time. For the solution of a general continuous time problem, we have two main approaches, namely, the
   <i>
    innovations approach
   </i>
   that extends the innovation representation of the Kalman
  </p>
  <p block-type="Text">
   filter where, combining equations (8) and (9), this latter representation is given by
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{x}_{t|t} = A_{t-1} \, \hat{x}_{t-1|t-1} + L_t [y_t - C_t A_{t-1} \, \hat{x}_{t-1|t-1}] \tag{12}
   </math>
  </p>
  <p block-type="Text">
   and the so-called
   <i>
    reference probability approach
   </i>
   . For the sake of brevity, we discuss here only the innovations approach (Kushner-Stratonovich equation) and we do it for the case of the model in equation
   <math display="inline">
    (3)
   </math>
   mentioning briefly possible extensions to other cases. For the reference probability approach (Zakai equation), we refer to the literature (for instance,
   <math display="inline">
    [8, 19]
   </math>
   ).
  </p>
  <p block-type="TextInlineMath">
   We denote by
   <math display="inline">
    \mathcal{L}
   </math>
   the generator of the Markov diffusion
   <math display="inline">
    x_t
   </math>
   in equation (3), that is, assuming
   <math display="inline">
    x \in \mathbb{R}^n
   </math>
   , for a function
   <math display="inline">
    \phi(t, x) \in \mathbb{C}^{1,2}
   </math>
   , we have
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathcal{L}\phi(t,x) = a(t,x)\phi_x(t,x) + \frac{1}{2} \sum_{i,j=1}^n \sigma_{ij}(t,x)\phi_{x_ix_j}(t,x) \quad (13)
   </math>
  </p>
  <p block-type="TextInlineMath">
   with
   <math display="inline">
    \sigma(t,x) := b(t,x)b'(t,x)
   </math>
   . Furthermore, for a generic (integrable)
   <math display="inline">
    f(\cdot)
   </math>
   , we let
   <math display="inline">
    f_t := E\{f(x_t) \mid \mathcal{F}_t^y\}
   </math>
   . The innovations approach now leads, in case of model given by equation
   <math display="inline">
    (3)
   </math>
   , to the following dynamics, also called the
   <i>
    Kushner–Stratonovich equation
   </i>
   (see e.g., [19, 8]):
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathrm{d}\hat{f}_t = \widehat{\mathcal{L}f(x_t)} \, \mathrm{d}t + [c(t, \widehat{x_t}) \widehat{f(x_t)} - \widehat{c(t, x_t)} \widehat{f_t}]' [\, \mathrm{d}y_t - \widehat{c(t, x_t)} \, \mathrm{d}t] \quad (14)
   </math>
  </p>
  <p block-type="TextInlineMath">
   which (see equation
   <math display="inline">
    (3)
   </math>
   ) is based on the innovations
   <math display="inline">
    \mathrm{d}y_t - c(t, x_t) \, \mathrm{d}t = \mathrm{d}y_t - E\{dy_t \mid \mathcal{F}_t^y\}
   </math>
   . In addition to the stochastic integral, the main difficulty with equation (14) is that, to compute
   <math display="inline">
    \hat{f}
   </math>
   , one needs
   <math display="inline">
    \widehat{cf}
   </math>
   , which, in turn, requires
   <math display="inline">
    \widehat{c^2 f}
   </math>
   , and so on. In other words, equation (14) is not a closed system of stochastic differential equations. Again, for particular models, equation (14) leads to a closed system as it happens with the linear-Gaussian version of equation (3) that leads to the continuous time Kalmann-Bucy filter, which is analogous to its discrete time counterpart. A further case arises when
   <math display="inline">
    x_t
   </math>
   is finite-state Markov with transition intensity matrix
   <math display="inline">
    Q = \{q_{ij}\}, i, j = 1, \dots, N.
   </math>
   Putting
   <math display="inline">
    \pi_t(i) := P\{x_t = i \mid \mathcal{F}_t^y\}
   </math>
   and taking
   <math display="inline">
    f(\cdot)
   </math>
   as the indicator function of the various values of
   <math display="inline">
    x_t
   </math>
   ,
  </p>
  <p block-type="Text">
   equation (14) becomes (on replacing
   <math display="inline">
    \mathcal{L}
   </math>
   by
   <math display="inline">
    Q
   </math>
   )
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathrm{d}\pi_t(j) = \sum_{i=1}^N \pi_t(i) q_{ij} \, \mathrm{d}t
   </math>
   <math display="block">
    + \pi_t(j) \left[ c(t,j) - \sum_{i=1}^N \pi_t(i) c(t,i) \right]
   </math>
   <math display="block">
    \times \left[ \mathrm{d}y_t - \sum_{i=1}^N \pi_t(i) c(t,i) \, \mathrm{d}t \right] \qquad (15)
   </math>
  </p>
  <p block-type="Text">
   For more results when
   <math display="inline">
    x_t
   </math>
   is finite-state Markov, we refer to
   <math display="inline">
    [10]
   </math>
   , and, in particular, see
   <math display="inline">
    [11]
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   We just mention that one can write the dynamics of
   <math display="inline">
    \hat{f}_t
   </math>
   also in the case of jump-diffusion observations as in equation
   <math display="inline">
    (4)
   </math>
   (see [17]) and one can, furthermore, obtain an evolution equation, a stochastic partial differential equation (PDE), for the conditional density
   <math display="inline">
    p(x_t) = p(x_t | y_0^t)
   </math>
   , whenever it exists, that involves the formal adjoint
   <math display="inline">
    \mathcal{L}^*
   </math>
   of the
   <math display="inline">
    \mathcal{L}
   </math>
   in equation (13) (see [19]).
  </p>
  <h1>
   Numerical Solutions of the Filtering Problem
  </h1>
  <p block-type="Text">
   As we have seen, an explicit analytic solution to the filtering problem can be obtained only for special models so that, remaining within analytic solutions, in general, one has to use an approximation approach. As already mentioned, one such approximation consists in linearizing the nonlinear model, both in discrete and continuous time, and this leads to the extended Kalman filter. Another approach consists in approximating the original model by one where
   <math display="inline">
    x_t
   </math>
   is finite-state Markov. The latter approach goes back mainly to Kushner and coworkers; see, for example, [18] (for a financial application, see also [13]). A more direct numerical approach is simulation-based and given by the so-called
   <i>
    particle approach to filtering
   </i>
   that has been successfully introduced more recently and that is summarized next.
  </p>
  <h4>
   Simulation-based Solution (Particle Filters).
  </h4>
  <p block-type="Text" class="has-continuation">
   Being simulation-based, this solution method as such is applicable only to discrete time models; continuous time models have to be first discretized in time. There are various variants of particle filters but, analogous to the analytical approaches, they all proceed along two steps, a prediction step and an updating step, and
  </p>
  <p block-type="Text">
   at each step the relevant distribution (predictive and filter distribution, respectively) is approximated by a discrete probability measure supported by a finite number of points. These approaches vary mainly in the updating step.
  </p>
  <p block-type="TextInlineMath">
   A simple version of a particle filter is as follows (see [3]): in the generic period
   <math display="inline">
    t-1
   </math>
   approximate
   <math display="inline">
    p(x_{t-1} | y_0^{t-1})
   </math>
   by a discrete distribution
   <math display="inline">
    ((x_{t-1}^1, p_{t-1}^1),
   </math>
   <math display="inline">
    \ldots, (x_{t-1}^L, p_{t-1}^L)
   </math>
   ) where
   <math display="inline">
    p_{t-1}^i
   </math>
   is the probability that
   <math display="inline">
    x_{t-1} = x_{t-1}^i
   </math>
   . Consider each location
   <math display="inline">
    x_{t-1}^i
   </math>
   as the position of a "particle".
  </p>
  <h2>
   1. Prediction step
  </h2>
  <p block-type="TextInlineMath">
   Propagate each of the particles
   <math display="inline">
    x_{t-1}^i \rightarrow \hat{x}_t^i
   </math>
   over one time period, using the given (discrete time) evolution dynamics of
   <math display="inline">
    x_t
   </math>
   : referring to the model in equation (2) just simulate independent trajectories of
   <math display="inline">
    x_t
   </math>
   starting from the various
   <math display="inline">
    x_{t-1}^i
   </math>
   . This leads to an approximation of
   <math display="inline">
    p(x_t | y_0^{t-1})
   </math>
   by the discrete distribution
   <math display="inline">
    ((\hat{x}_t^1, \hat{p}_t^1), \ldots, (\hat{x}_t^L, \hat{p}_t^L))
   </math>
   where one puts
   <math display="inline">
    \hat{p}^i_t = p^i_{t-1}.
   </math>
  </p>
  <h1>
   2. Updating step
  </h1>
  <p block-type="TextInlineMath">
   Update the weights using the new observation
   <math display="inline">
    y_t
   </math>
   by putting
   <math display="inline">
    p_t^i = cp_{t-1}^i p(y_t \mid \hat{x}_t^i)
   </math>
   where c is the normalization constant (see the second relation in equation
   <math display="inline">
    (5)
   </math>
   for an analogy).
  </p>
  <p block-type="Text">
   Notice that
   <math display="inline">
    p(y_t | \hat{x}_t^i)
   </math>
   may be viewed as the likelihood of particle
   <math display="inline">
    \hat{x}_t^i
   </math>
   , given the observation
   <math display="inline">
    y_t
   </math>
   , so that in the updating step one weighs each particle according to its likelihood. There exist various improvements of this basic setup. There are also variants, where in the updating step each particle is made to branch into a random number of offsprings, where the mean number of offsprings is taken to be proportional to the likelihood of that position. In this latter variant, the number of particles increases and one can show that, under certain assumptions, the empirical distribution of the particles converges to the true filter distribution. There is a vast literature on particle filters, of which we mention
   <math display="inline">
    [5]
   </math>
   and, in particular,
   <math display="inline">
    [1]
   </math>
   .
  </p>
  <h2>
   <b>
    Filtering in Finance
   </b>
  </h2>
  <p block-type="Text" class="has-continuation">
   There are various situations in finance where filtering problems may arise, but one typical situation is given by factor models. These models have proven to be useful for capturing the complicated nonlinear dynamics of real asset prices, while at the same time being parsimonious and numerically tractable. In
  </p>
  <p block-type="Text">
   addition, with Markovian factor processes, Markovprocess techniques can be fruitfully applied. In many financial applications of factor models, the investors have only incomplete information about the actual state of the factors and this may induce model risk. In fact, even if the factors are associated with economic quantities, some of them are difficult to observe precisely. Furthermore, abstract factors without economic interpretation are often included in the specification of a model to increase its flexibility. Under incomplete information of the factors, their values have to be inferred from observable quantities and this is where filtering comes in as an appropriate tool.
  </p>
  <p block-type="Text">
   Most financial problems concern pricing as well as portfolio management, in particular, hedging and portfolio optimization. While portfolio management is performed under the physical measure, for pricing, one has to use a martingale measure. Filtering problems in finance may therefore be considered under the physical or the martingale measures, or under both (see [22]). In what follows, we shall discuss filtering for pricing problems, with examples from term structure and credit risk, as well as for portfolio management. More general aspects can be found, for example, in the recent papers
   <math display="inline">
    [6, 7]
   </math>
   , and
   <math display="inline">
    [23]
   </math>
   .
  </p>
  <h4>
   Filtering in Pricing Problems
  </h4>
  <p block-type="TextInlineMath">
   This section is to a large extent based on [14]. In Markovian factor models, the price of an asset at a generic time
   <math display="inline">
    t
   </math>
   can, under full observation of the factors, be expressed as an instantaneous function
   <math display="inline">
    \Psi(t, x_t)
   </math>
   of time and the value of the factors. Let
   <math display="inline">
    \mathcal{G}_t
   </math>
   denote the full filtration that measures all the processes of interest, and let
   <math display="inline">
    \mathcal{F}_t \subset \mathcal{G}_t
   </math>
   be a subfiltration representing the information of an investor. What is an arbitrage-free price in the filtration
   <math display="inline">
    \mathcal{F}_t
   </math>
   ? Assume the asset to be priced is a European derivative with maturity T and claim
   <math display="inline">
    H \in \mathcal{F}_T
   </math>
   . Let N be a numeraire, adapted to the investor filtration
   <math display="inline">
    \mathcal{F}_t
   </math>
   , and let
   <math display="inline">
    Q^N
   </math>
   be the corresponding martingale measure. One can easily prove the following:
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   <b>
    Lemma 1
   </b>
   Let
   <math display="inline">
    \Psi(t, x_t) = N_t E^{Q^N} \left\{ \frac{H}{N_T} \mid \mathcal{G}_t \right\}
   </math>
   be the arbitrage-free price of the claim
   <math display="inline">
    \hat{H}
   </math>
   under the full
  </p>
  <p block-type="TextInlineMath">
   information
   <math display="inline">
    \mathcal{G}_t
   </math>
   and
   <math display="inline">
    \hat{\Psi}(t) = N_t E^{Q^N} \left\{ \frac{H}{N_T} \mid \mathcal{F}_t \right\}
   </math>
   the corresponding arbitrage-free price in the investor filtration. It then follows that
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{\Psi}(t) = E^{Q^N} \left\{ \Psi(t, x_t) \mid \mathcal{F}_t \right\} \tag{16}
   </math>
  </p>
  <p block-type="TextInlineMath">
   Furthermore, if the savings account
   <math display="inline">
    B_t = \exp\{\int_0^t
   </math>
   <math display="inline">
    r_s
   </math>
   ds} with corresponding martingale measure Q is
   <math display="inline">
    \mathcal{F}_t
   </math>
   -adapted, then
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{\Psi}(t) = E^{Q} \left\{ \Psi(t, x_t) \mid \mathcal{F}_t \right\} \tag{17}
   </math>
  </p>
  <p block-type="Text">
   We thus see that, to compute the right-hand sides in equation
   <math display="inline">
    (16)
   </math>
   or equation
   <math display="inline">
    (17)
   </math>
   , namely, the price of a derivative under restricted information given its price under full information, one has to solve the filtering problem for
   <math display="inline">
    x_t
   </math>
   given
   <math display="inline">
    \mathcal{F}_t
   </math>
   under a martingale measure. We present now two examples.
  </p>
  <p block-type="Text">
   <b>
    Example 1
   </b>
   (
   <i>
    Term structure of interests
   </i>
   ). The example is a simplified version adapted from [15]. Consider a factor model for the term structure where the unobserved (multivariate) factor process
   <math display="inline">
    x_t
   </math>
   satisfies the linear-Gaussian model
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathrm{d}x_t = Fx_t \,\mathrm{d}t + D \,\mathrm{d}w_t \tag{18}
   </math>
  </p>
  <p block-type="Text">
   In this case, the term structure is exponentially affine in
   <math display="inline">
    x_t
   </math>
   and one has
  </p>
  <p block-type="Equation">
   <math display="block">
    p(t, T; x_t) = \exp[A(t, T) - B(t, T) x_t] \qquad (19)
   </math>
  </p>
  <p block-type="TextInlineMath">
   with
   <math display="inline">
    A(t, T), B(t, T)
   </math>
   satisfying well-known firstorder ordinary differential equations to exclude arbitrage. Passing to log-prices for the bonds, one gets the linear relationship
   <math display="inline">
    y_t^T := \log p(t, T; x_t) = A(t, T)  B(t, T)x_t
   </math>
   . Assume now that investors cannot observe
   <math display="inline">
    x_t
   </math>
   , but they can observe the short rate and the logprices of a finite number
   <math display="inline">
    n
   </math>
   of zero-coupon bonds, perturbed by additive noise. This leads to a system of the form
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{cases}\n\mathrm{d}x_t = Fx_t \,\mathrm{d}t + D \,\mathrm{d}w_t \\
\mathrm{d}r_t = (\alpha_t^0 + \beta_t^0 x_t) \,\mathrm{d}t + \sigma_t^0 \,\mathrm{d}w_t + \mathrm{d}v_t^0 \\
\mathrm{d}y_t^i = (\alpha_t^i + \beta_t^i x_t) \,\mathrm{d}t + \sigma_t^i \,\mathrm{d}w_t + (T_i - t) \,\mathrm{d}v_t^i \\
\quad; i = 1, \dots, n\n\end{cases} \tag{20}
   </math>
  </p>
  <p block-type="Text">
   where
   <math display="inline">
    v^i
   </math>
   ,
   <math display="inline">
    i = 0, \ldots, n
   </math>
   are independent Wiener processes and the coefficients are related to those in equations
   <math display="inline">
    (18)
   </math>
   and
   <math display="inline">
    (19)
   </math>
   . The time-dependent volatility in the perturbations of the log-prices reflects the fact that it tends to zero as time approaches maturity.
  </p>
  <p block-type="TextInlineMath">
   From the filtering point of view, the system
   <math display="inline">
    (20)
   </math>
   is a linear-Gaussian model with
   <math display="inline">
    x_t
   </math>
   unobserved and the observations given by
   <math display="inline">
    (r_t, y_t^i)
   </math>
   . We shall thus put
   <math display="inline">
    \mathcal{F}_t =
   </math>
   <math display="inline">
    \sigma\{r_s, y_s^i; s \leq t, i = 1, \ldots, n\}
   </math>
   . The filter distribution is Gaussian and, via the Kalman filter, one can obtain its conditional mean
   <math display="inline">
    m_t
   </math>
   and (co)variance
   <math display="inline">
    \Sigma_t
   </math>
   . Applying Lemma 1 and using the momentgenerating function of a Gaussian random variable, we obtain the arbitrage-free price, in the investor filtration, of an illiquid bond with maturity
   <math display="inline">
    T
   </math>
   as follows:
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{p}(t,T) = E\{p(t,T;x_t) \mid \mathcal{F}_t\}\n
   </math>
   <math display="block">
    \n= \exp[A(t,T)] E\{\exp[-B(t,T)x_t] \mid \mathcal{F}_t\}\n
   </math>
   <math display="block">
    \n= \exp[A(t,T) - B(t,T)m_t\n
   </math>
   <math display="block">
    \n+ \frac{1}{2}B(t,T)\Sigma_t B'(t,T)]\n
   </math>
   (21)
  </p>
  <p block-type="TextInlineMath">
   For the given setup, the expectation is under the martingale measure
   <math display="inline">
    Q
   </math>
   with the money market account
   <math display="inline">
    B_t
   </math>
   as numeraire. To apply Lemma 1, we need the numeraire to be observable and this contrasts with the assumption that
   <math display="inline">
    r_t
   </math>
   is observable only in noise. This difficulty can be overcome (see [14]), but by suitably changing the drifts in equation (20) (corresponding to a translation of
   <math display="inline">
    w_t
   </math>
   ), one may however consider the model in equation
   <math display="inline">
    (20)
   </math>
   also under a martingale measure for which the numeraire is different from
   <math display="inline">
    B_t
   </math>
   and observable.
  </p>
  <p block-type="Text">
   A further filter application to the term structure of interest rates can be found in [2].
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   <b>
    Example 2
   </b>
   (
   <i>
    Credit risk
   </i>
   ). One of the main issues in credit risk is the modeling of the dynamic evolution of the default state of a given portfolio. To formalize the problem, given a portfolio of
   <math display="inline">
    m
   </math>
   obligors, let
   <math display="inline">
    y_t := (y_{t,1}, \ldots, y_{t,m})
   </math>
   be the default indicator process where
   <math display="inline">
    y_{t,i} := \mathbf{1}_{\{\tau_i &lt; t\}}
   </math>
   with
   <math display="inline">
    \tau_i
   </math>
   the random default time of obligor
   <math display="inline">
    i, i = 1, \ldots, m
   </math>
   . In line with the factor modeling philosophy, it is natural to assume that default intensities depend on an unobservable latent process
   <math display="inline">
    x_t
   </math>
   . In particular, if
   <math display="inline">
    \lambda_i(t)
   </math>
   is the default intensity of obligor
   <math display="inline">
    i, i = 1, ..., m
   </math>
   , assume
   <math display="inline">
    \lambda_i(t) =
   </math>
   <math display="inline">
    \lambda_i(x_t)
   </math>
   . Note that this generates information-driven
   <i>
    contagion
   </i>
   : it is, in fact, well known that the intensities with respect to
   <math display="inline">
    \mathcal{F}_t
   </math>
   are given by
   <math display="inline">
    \hat{\lambda}_i(t) = E\{\lambda_i(x_t) \mid
   </math>
   <math display="inline">
    \mathcal{F}_t
   </math>
   . Hence the news that an obligor has defaulted leads, via filtering, to an update of the distribution
  </p>
  <p block-type="Text">
   of
   <math display="inline">
    x_t
   </math>
   and thus to a jump in the default intensities of the still surviving obligors. In this context, we shall consider the pricing of illiquid credit derivatives on the basis of the investor filtration supposed to be given by the default history and noisily observed prices of liquid credit derivatives.
  </p>
  <p block-type="TextInlineMath">
   We assume that, conditionally on
   <math display="inline">
    x_t
   </math>
   , the defaults are independent with intensities
   <math display="inline">
    \lambda_i(x_t)
   </math>
   and that
   <math display="inline">
    (x_t, y_t)
   </math>
   is jointly Markov. A credit derivative has the payoff linked to default events in a given reference portfolio and so one can think of it as a random variable
   <math display="inline">
    H \in \mathcal{F}_T^y
   </math>
   with T being the maturity. Its full information price at the generic
   <math display="inline">
    t \leq T
   </math>
   , that is, in the filtration
   <math display="inline">
    \mathcal{G}_t
   </math>
   that measures also
   <math display="inline">
    x_t
   </math>
   , is given by
   <math display="inline">
    \tilde{H}_t = E\{e^{-r(T-t)}H \mid \mathcal{G}_t\}
   </math>
   where r is the short rate and the expectation is under a given martingale measure Q. By the Markov property of
   <math display="inline">
    (x_t, y_t)
   </math>
   , one gets a representation of the form
  </p>
  <p block-type="Equation">
   <math display="block">
    \tilde{H}_t = E\{e^{-r(T-t)}H \mid \mathcal{G}_t\} := a(t, x_t, y_t) \tag{22}
   </math>
  </p>
  <p block-type="Text">
   for a suitable
   <math display="inline">
    a(\cdot)
   </math>
   . In addition to the default history, we assume that the investor filtration also includes noisy observations of liquid credit derivatives. In view of equation (22), it is reasonable to model such observations as
  </p>
  <p block-type="Equation">
   <math display="block">
    dz_t = \gamma(t, x_t, y_t) dt + d\beta_t \tag{23}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where the various quantities may also be column vectors,
   <math display="inline">
    \beta_t
   </math>
   is an independent Wiener process and
   <math display="inline">
    \gamma(\cdot)
   </math>
   is a function of the type of
   <math display="inline">
    a(\cdot)
   </math>
   in equation (22). The investor filtration is then
   <math display="inline">
    \mathcal{F}_t = \mathcal{F}_t^y \vee \mathcal{F}_t^z
   </math>
   . The price at
   <math display="inline">
    t &lt; T
   </math>
   of the credit derivative in the investor filtration is now
   <math display="inline">
    H_t = E\{e^{-r(T-t)}H \mid \mathcal{F}_t\}
   </math>
   and by Lemma 1 we have
  </p>
  <p block-type="Equation">
   <math display="block">
    H_t = E\{e^{-r(T-t)}H \mid \mathcal{F}_t\} = E\{a(t, x_t, y_t) \mid \mathcal{F}_t\}
   </math>
   (24)
  </p>
  <p block-type="TextInlineMath">
   Again, if one knows the price
   <math display="inline">
    a(t, x_t, y_t)
   </math>
   in
   <math display="inline">
    \mathcal{G}_t
   </math>
   , one can thus obtain the price in
   <math display="inline">
    \mathcal{F}_t
   </math>
   by computing the right-hand side in equation
   <math display="inline">
    (24)
   </math>
   and for this we need the filter distribution of
   <math display="inline">
    x_t
   </math>
   given
   <math display="inline">
    \mathcal{F}_t
   </math>
   .
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   To define the corresponding filtering problem, we need a more precise model for
   <math display="inline">
    (x_t, y_t)
   </math>
   (the process
   <math display="inline">
    z_t
   </math>
   is already given by equation (23)). Since
   <math display="inline">
    y_t
   </math>
   is a jump process, the model cannot be one of those for which we had described an explicit analytic solution. Without entering into details, we refer to
   <math display="inline">
    [13]
   </math>
   (see also
   <math display="inline">
    [14]
   </math>
   ), where a jump-diffusion model is considered that allows for common jumps between
  </p>
  <p block-type="TextInlineMath">
   <math display="inline">
    x_t
   </math>
   and
   <math display="inline">
    y_t
   </math>
   . In [13] it is shown that an arbitrarily good approximation to the filter solution can be obtained both analytically and by particle filtering.
  </p>
  <p block-type="Text">
   We conclude this section with a couple of additional remarks:
  </p>
  <p block-type="Text">
   1. Traditional credit risk models are either structural models or reduced-form (intensity-based) models. Example 2 belongs to the latter class. In structural models, the default of the generic obligor/firm
   <math display="inline">
    i
   </math>
   is defined as the first passage time of the asset value
   <math display="inline">
    V_i(t)
   </math>
   of the firm at a given (possibly stochastic) barrier
   <math display="inline">
    K_i(t)
   </math>
   , that is,
  </p>
  <p block-type="Equation">
   <math display="block">
    \tau_i = \inf\{t \ge 0 \mid V_i(t) \le K_t(t)\}\tag{25}
   </math>
  </p>
  <p block-type="TextInlineMath">
   In such a context, filtering problems may arise when either
   <math display="inline">
    V_i(t)
   </math>
   or
   <math display="inline">
    K_i(t)
   </math>
   or both are not exactly known/observable (see e.g., [9]).
  </p>
  <p block-type="Text">
   2. Can a structural model also be seen as a reducedform model? At first sight, this is not clear since
   <math display="inline">
    \tau_i
   </math>
   in equation (25) is predictable, while in intensity-based models it is totally inaccessible. However, it turns out (see e.g., [16]) that, while
   <math display="inline">
    \tau_i
   </math>
   in equation
   <math display="inline">
    (25)
   </math>
   is predictable with respect to the full filtration (measuring also
   <math display="inline">
    V_i(t)
   </math>
   and
   <math display="inline">
    K_i(t)
   </math>
   ), it becomes totally inaccessible in the smaller investor filtration that, say, does not measure
   <math display="inline">
    V_i(t)
   </math>
   and, furthermore, it admits an intensity.
  </p>
  <h4>
   Filtering in Portfolio Management Problems
  </h4>
  <p block-type="Text">
   Rather than presenting a general treatment (for this, we refer to [21] and the references therein), we discuss here two specific examples in models with unobserved factors, one in discrete time and one in continuous time. Contrary to the previous section on pricing, here we shall work under the physical measure
   <math display="inline">
    P
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   A Discrete Time Case. To motivate the model, start from the classical continuous time asset price model
   <math display="inline">
    dS_t = S_t[a dt + x_t dw_t]
   </math>
   where
   <math display="inline">
    w_t
   </math>
   is Wiener and
   <math display="inline">
    x_t
   </math>
   is the nondirectly observable volatility process (factor). For
   <math display="inline">
    y_t := \log S_t
   </math>
   , one then has
  </p>
  <p block-type="Equation">
   <math display="block">
    dy_t = \left(a - \frac{1}{2}x_t^2\right) dt + x_t dw_t \qquad (26)
   </math>
  </p>
  <p block-type="Text">
   Passing to discrete time with step
   <math display="inline">
    \delta
   </math>
   , let for
   <math display="inline">
    t =
   </math>
   <math display="inline">
    0, \ldots, T
   </math>
   the process
   <math display="inline">
    x_t
   </math>
   be a Markov chain with m
  </p>
  <p block-type="TextInlineMath">
   states
   <math display="inline">
    x^1, \ldots, x^m
   </math>
   (may result from a time discretization of a continuous time
   <math display="inline">
    x_t
   </math>
   ) and
  </p>
  <p block-type="Equation">
   <math display="block">
    y_{t} = y_{t-1} + \left(a - \frac{1}{2}x_{t-1}^{2}\right)\delta + x_{t-1}\sqrt{\delta\varepsilon_{t}} \qquad (27)
   </math>
  </p>
  <p block-type="TextInlineMath">
   with
   <math display="inline">
    \varepsilon_t
   </math>
   i.i.d. standard Gaussian as it results from equation (26) by applying the Euler-Maruyama scheme. Notice that
   <math display="inline">
    (x_t, y_t)
   </math>
   is Markov. Having for simplicity only one stock to invest in, denote by
   <math display="inline">
    \phi_t
   </math>
   the number of shares of stock held in the portfolio in period
   <math display="inline">
    t
   </math>
   with the rest invested in a riskless bond
   <math display="inline">
    B_t
   </math>
   (for simplicity assume
   <math display="inline">
    r = 0
   </math>
   ). The corresponding self-financed wealth process then evolves according to
  </p>
  <p block-type="Equation">
   <math display="block">
    V_{t+1}^{\phi} = V_t^{\phi} + \phi_t \left( e^{y_{t+1}} - e^{y_t} \right) := F \left( V_t^{\phi}, \phi_t, y_t, y_{t+1} \right)
   </math>
   (28)
  </p>
  <p block-type="TextInlineMath">
   and
   <math display="inline">
    \phi_t
   </math>
   is supposed to be adapted to
   <math display="inline">
    \mathcal{F}_t^y
   </math>
   ; denote by
   <math display="inline">
    \mathcal{A}
   </math>
   the class of such strategies. Given a horizon T, consider the following investment criterion
  </p>
  <p block-type="Equation">
   <math display="block">
    J_{\text{opt}}(V_0) = \sup_{\phi \in \mathcal{A}} J(V_0, \phi)
   </math>
   <br/>
   =
   <math>
    \sup_{\phi \in \mathcal{A}} E \left\{ \sum_{t=0}^{T-1} r_t(x_t, y_t, V_t^{\phi}, \phi_t) + f(x_T, y_T, V_T^{\phi}) \right\}
   </math>
   (29)
  </p>
  <p block-type="Text">
   which, besides portfolio optimization, includes also hedging problems. The problem in equations
   <math display="inline">
    (27)
   </math>
   ,
   <math display="inline">
    (28)
   </math>
   , and
   <math display="inline">
    (29)
   </math>
   is now a stochastic control problem under partial/incomplete information given that
   <math display="inline">
    x_t
   </math>
   is an unobservable factor process.
  </p>
  <p block-type="TextInlineMath">
   A standard approach to dynamic optimization problems under partial information is to transform them into corresponding complete information ones whereby
   <math display="inline">
    x_t
   </math>
   is replaced by its filter distribution given
   <math display="inline">
    \mathcal{F}_t^y
   </math>
   . Letting
   <math display="inline">
    \pi_t^i := P\{x_t = x^i \mid \mathcal{F}_t^y\}, i =
   </math>
   <math display="inline">
    1, \ldots, m
   </math>
   we first adapt the filter dynamics in equa-
   <math display="inline">
    (5)
   </math>
   to our situation to derive a recursive relation for
   <math display="inline">
    \pi_t = (\pi_t^1, \ldots, \pi_t^m)
   </math>
   . Being
   <math display="inline">
    x_t
   </math>
   finite-state Markov,
   <math display="inline">
    p(x_{t+1} | x_t)
   </math>
   is given by the transition probability matrix and the integral in equation
   <math display="inline">
    (5)
   </math>
   reduces to a sum. On the other hand,
   <math display="inline">
    p(y_t | x_t)
   </math>
   in equation (5) corresponds to the model in equation (2) that does not include our model in equation (27) for
   <math display="inline">
    y_t
   </math>
   . One can however easily see that equation
   <math display="inline">
    (27)
   </math>
   leads to a
  </p>
  <p block-type="TextInlineMath">
   distribution of the form
   <math display="inline">
    p(y_t | x_{t-1}, y_{t-1})
   </math>
   , and equation
   <math display="inline">
    (5)
   </math>
   can be adapted to become here
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{cases} \pi_{0} = \mu \quad \text{(initial distribution for } x_{t}) \\ \pi_{t}^{i} \propto \sum_{j=1}^{m} p\left(y_{t} \mid x_{t-1} = j, y_{t-1}\right) \\ p\left(x_{t} = i \mid x_{t-1} = j\right) \pi_{t-1}^{j} \end{cases} \tag{30}
   </math>
  </p>
  <p block-type="TextInlineMath">
   In addition, we may consider the law of
   <math display="inline">
    y_t
   </math>
   conditional on
   <math display="inline">
    (\pi_{t-1}, y_{t-1}) = (\pi, y)
   </math>
   that is given by
  </p>
  <p block-type="Equation">
   <math display="block">
    Q_{t}(\pi, y, dy') = \sum_{i,j=1}^{m} p(y' | x_{t-1} = j, y)
   </math>
   <math display="block">
    p(x_{t} = i | x_{t-1} = j) \pi^{j} \quad (31)
   </math>
  </p>
  <p block-type="TextInlineMath">
   From equations
   <math display="inline">
    (30)
   </math>
   and
   <math display="inline">
    (31)
   </math>
   , it follows easily that
   <math display="inline">
    (\pi_t, y_t)
   </math>
   is a sufficient statistic and an
   <math display="inline">
    \mathcal{F}_t^y
   </math>
   -Markov process.
  </p>
  <p block-type="TextInlineMath">
   To transform the original partial information problem with criterion
   <math display="inline">
    (29)
   </math>
   into a corresponding complete observation problem, put
   <math display="inline">
    \hat{r}_t(\pi, y, v, \phi) = \sum_{i=1}^m r_t(x^i, y, v, \phi)
   </math>
   <math display="inline">
    y, v, \phi \pi^i
   </math>
   and
   <math display="inline">
    \hat{f}(\pi, y, v) = \sum_{i=1}^m f(x^i, y, v) \pi^i
   </math>
   so that, by double conditioning, one obtains
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{split} J(V_0, \phi) &amp;= E \left\{ \sum_{t=0}^{T-1} E \left\{ r_t(x_t, y_t, V_t^{\phi}, \phi_t) \mid \mathcal{F}_t^y \right\} \right. \\ &amp;\quad + E \left\{ f(x_T, y_T, V_T^{\phi}) \mid \mathcal{F}_T^y \right\} \right\} \\ &amp;= E \left\{ \sum_{t=0}^{T-1} \hat{r}_t(\pi_t, y_t, V_t^{\phi}, \phi_t) + \hat{f}(\pi_T, y_T, V_T^{\phi}) \right\} \end{split} \tag{32}
   </math>
  </p>
  <p block-type="Text">
   Owing to the Markov property of
   <math display="inline">
    (\pi_t, y_t)
   </math>
   , one can write the following (backward) dynamic programming recursions:
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{cases}\n u_{T}(\pi, y, v) = \hat{f}(\pi, y, v) \\
 u_{t}(\pi, y, v) = \sup_{\phi \in A} \left[ \hat{r}_{t}(\pi, y, v, \phi) \\
 + E \left\{ u_{t+1}(\pi_{t+1}, y_{t+1}, F(v, \phi, y, y_{t+1})) \mid (\pi_{t}, y_{t}) = (\pi, y) \right\} \right]\n\end{cases} \n
   </math>
   (33)
  </p>
  <p block-type="TextInlineMath">
   where the function
   <math display="inline">
    F(\cdot)
   </math>
   was defined in equation (28), and
   <math display="inline">
    \phi
   </math>
   here refers to the generic choice of
   <math display="inline">
    \phi = \phi_t
   </math>
   in period
   <math display="inline">
    t
   </math>
   . It leads to the optimal investment strategy
   <math display="inline">
    \phi^*
   </math>
   and the optimal value
   <math display="inline">
    J_{opt}(V_0) = u_0(\mu, y_0, V_0)
   </math>
   . It can, in fact, be shown that the strategy and value thus
  </p>
  <p block-type="TextInlineMath">
   obtained are optimal also for the original incomplete information problem when
   <math display="inline">
    \phi
   </math>
   there is required to be
   <math display="inline">
    \mathcal{F}_t^y
   </math>
   – adapted.
  </p>
  <p block-type="TextInlineMath">
   To actually compute the recursions in equation (33), one needs the conditional law of
   <math display="inline">
    (\pi_{t+1}, y_{t+1})
   </math>
   given
   <math display="inline">
    (\pi_t, y_t)
   </math>
   , which can be deduced from equations (30) and (31). In this context, notice that, even if
   <math display="inline">
    x
   </math>
   is
   <i>
    m
   </i>
   -valued,
   <math display="inline">
    \pi_t
   </math>
   takes values in the
   <i>
    m
   </i>
   -dimensional simplex that is
   <math display="inline">
    \infty
   </math>
   -valued. To actually perform the calculation, one needs an approximation leading to a finite-valued process
   <math display="inline">
    (\pi_t, y_t)
   </math>
   and to this effect various approaches have appeared in the literature (for an approach with numerical results see [4]).
  </p>
  <p block-type="Text">
   A Continuous Time Case. Consider the following market model where
   <math display="inline">
    x_t
   </math>
   is an unobserved factor process and
   <math display="inline">
    S_t
   </math>
   is the price of a single risky asset:
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{cases} \mathrm{d}x_t = F_t(x_t) \, \mathrm{d}t + R_t(x_t) \, \mathrm{d}M_t \\ \mathrm{d}S_t = S_t \left[ a_t(S_t, x_t) \, \mathrm{d}t + \sigma_t(S_t) \, \mathrm{d}w_t \right] \end{cases} \tag{34}
   </math>
  </p>
  <p block-type="TextInlineMath">
   with
   <math display="inline">
    w_t
   </math>
   a Wiener process and
   <math display="inline">
    M_t
   </math>
   a not necessarily continuous martingale, independent of
   <math display="inline">
    w_t
   </math>
   . Since, in continuous time,
   <math display="inline">
    \int_0^t \sigma_s^2 ds
   </math>
   can be estimated by the empirical quadratic variation of
   <math display="inline">
    S_t
   </math>
   , in order not to have degeneracy in the filter to be derived below for
   <math display="inline">
    x_t
   </math>
   , we do not let
   <math display="inline">
    \sigma(\cdot)
   </math>
   depend also on
   <math display="inline">
    x_t
   </math>
   . For the riskless asset, we assume for simplicity that its price is
   <math display="inline">
    B_t \equiv const
   </math>
   (short rate
   <math display="inline">
    r = 0
   </math>
   ). In what follows, it is convenient to consider log-prices
   <math display="inline">
    y_t = \log S_t
   </math>
   , for which
  </p>
  <p block-type="Equation">
   <math display="block">
    dy_t = [a_t(S_t, x_t) - \frac{1}{2}\sigma_t^2(S_t)] dt + \sigma(S_t) dw_t
   </math>
   <br/>
   :=
   <math>
    A_t(y_t, x_t) dt + B(y_t) dw_t
   </math>
   (35)
  </p>
  <p block-type="TextInlineMath">
   Investing in this market in a self-financing way and denoting by
   <math display="inline">
    \rho_t
   </math>
   the fraction of wealth invested in the risky asset, we have from
   <math display="inline">
    \frac{dV_t}{V_t} = \rho_t \frac{dS_t}{S_t} = \rho_t \frac{d}{e^{y_t}} e^{y_t}
   </math>
   that
  </p>
  <p block-type="Equation">
   <math display="block">
    dV_t = V_t \left[ \rho_t \left( A_t(y_t, x_t) + \frac{1}{2} B_t^2(y_t) \right) dt + \rho_t B_t(y_t) dw_t \right]
   </math>
   (36)
  </p>
  <p block-type="Text" class="has-continuation">
   We want to consider the problem of maximization of expected utility from terminal wealth, without
  </p>
  <p block-type="Text">
   consumption, and with a power utility function. Combining equations
   <math display="inline">
    (34)
   </math>
   ,
   <math display="inline">
    (35)
   </math>
   , and
   <math display="inline">
    (36)
   </math>
   we obtain the following portfolio optimization problem under incomplete information where the factor process
   <math display="inline">
    x_t
   </math>
   is not observed and where we shall require that
   <math display="inline">
    \rho_t
   </math>
   is
   <math display="inline">
    \mathcal{F}^Y_t
   </math>
   -adapted:
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{cases} \mathrm{d}x_t = F_t(x_t) \, \mathrm{d}t + R_t(x_t) \, \mathrm{d}M_t \quad \text{(unobserved)}\\ \mathrm{d}y_t = A_t(y_t, x_t) \, \mathrm{d}t + B(y_t) \, \mathrm{d}w_t \quad \text{(observed)}\\ \mathrm{d}V_t = V_t \left[ \rho_t \left( A_t(y_t, x_t) + \frac{1}{2} B_t^2(y_t) \right) \, \mathrm{d}t \right. \\ \left. + \rho_t B_t(y_t) \, \mathrm{d}w_t \right] \\ \mathrm{sup}_{\rho} E \left\{ (V_T)^{\mu} \right\}, \quad \mu \in (0, 1) \end{cases} \tag{37}
   </math>
  </p>
  <p block-type="TextInlineMath">
   As in the previous discrete time case, we shall now transform this problem into a corresponding one under complete information, thereby replacing the unobserved state variable
   <math display="inline">
    x_t
   </math>
   by its filter distribution, given
   <math display="inline">
    \mathcal{F}_t^y
   </math>
   , that is,
   <math display="inline">
    \pi_t(x) := p(x_t \mid \mathcal{F}_t^y)_{x_t = x}
   </math>
   . Even if
   <math display="inline">
    x_t
   </math>
   is finite-dimensional,
   <math display="inline">
    \pi_t(\cdot)
   </math>
   is
   <math display="inline">
    \infty
   </math>
   -dimensional. We have seen above cases where the filter distribution is finitely parameterized, namely, the linear-Gaussian case (
   <i>
    Kalman filter
   </i>
   ) and when
   <math display="inline">
    x_t
   </math>
   is finite-state Markov. The parameters characterizing the filter were seen to evolve over time driven by the innovations process (see equations
   <math display="inline">
    (8)
   </math>
   ,
   <math display="inline">
    (10)
   </math>
   and
   <math display="inline">
    (14)
   </math>
   ). In what follows, we then assume that the filter is parameterized by a vector process
   <math display="inline">
    \xi_t \in \mathbb{R}^p
   </math>
   , that is,
   <math display="inline">
    \pi_t(x) :=
   </math>
   <math display="inline">
    p(x_t \mid \mathcal{F}_t^y)_{x_t=x} = \pi(x; \xi_t)
   </math>
   and that
   <math display="inline">
    \xi_t
   </math>
   satisfies
  </p>
  <p block-type="Equation">
   <math display="block">
    d\xi_t = \beta_t(y_t, \xi_t) dt + \eta_t(y_t, \xi_t) d\bar{w}_t \qquad (38)
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    \bar{w}_t
   </math>
   is Wiener and given by the innovations process. We now specify this innovations process
   <math display="inline">
    \bar{w}_t
   </math>
   for our general model in equation (37). To this effect, putting
   <math display="inline">
    A_t(y_t, \xi_t) := \int A_t(y_t, x) d\pi_t(x; \xi_t)
   </math>
   , let
  </p>
  <p block-type="Equation">
   <math display="block">
    d\bar{w}_t := B_t^{-1}(y_t) \left[ dy_t - A_t(y_t, \xi_t) dt \right]
   </math>
   (39)
  </p>
  <p block-type="Text">
   and notice that, replacing
   <math display="inline">
    dy_t
   </math>
   from equation (35), this definition implies a translation of the original
   <math display="inline">
    (P, \mathcal{F}_t)
   </math>
   -Wiener
   <math display="inline">
    w_t
   </math>
   , that is,
  </p>
  <p block-type="Equation">
   <math display="block">
    d\bar{w}_t = dw_t + B_t^{-1}(y_t) \left[ A_t(y_t, x_t) - A_t(y_t, \xi_t) \right] dt
   </math>
   (40)
  </p>
  <p block-type="Text">
   and thus the implicit change of measure
   <math display="inline">
    P \rightarrow \bar{P}
   </math>
   with
  </p>
  <p block-type="Equation">
   <math display="block">
    \frac{\mathrm{d}\bar{P}}{\mathrm{d}P}_{|\mathcal{F}_T} = \exp\left\{\int_0^T \left[A_t(y_t, \xi_t) - A_t(y_t, x_t)\right]\right\}
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    \times B_t^{-1}(y_t) \, \mathrm{d}w_t - \frac{1}{2} \int_0^T \left[ A_t(y_t, \xi_t) \right]
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    -A_{t}(y_{t}, x_{t})]^{2} B_{t}^{-2}(y_{t}) dt
   </math>
   (41)
  </p>
  <p block-type="Text">
   We obtain thus as the complete information problem corresponding to equation
   <math display="inline">
    (37)
   </math>
   , the following, which is defined on the space
   <math display="inline">
    (\Omega, \mathcal{F}, \mathcal{F}_t, \bar{P})
   </math>
   with Wiener
   <math display="inline">
    \bar{w}_t
   </math>
   :
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{cases} \mathrm{d}\xi_{t} = \beta_{t}(y_{t}, \xi_{t}) \, \mathrm{d}t + \eta_{t}(y_{t}, \xi_{t}) \, \mathrm{d}\bar{w}_{t} \\ \mathrm{d}y_{t} = A_{t}(y_{t}, \xi_{t}) \, \mathrm{d}t + B_{t}(y_{t}) \, \mathrm{d}\bar{w}_{t} \end{cases}
   </math>
   <br/>
   <math display="block">
    \mathrm{d}V_{t} = V_{t} \left[ \rho_{t} \left( A_{t}(y_{t}, \xi_{t}) + \frac{1}{2} B_{t}^{2}(y_{t}) \right) \, \mathrm{d}t \right.
   </math>
   <br/>
   <math display="block">
    + \rho_{t} B_{t}(y_{t}) \, \mathrm{d}\bar{w}_{t} \right]
   </math>
   <br/>
   <math display="block">
    \sup_{\rho} \bar{E} \left\{ (V_{T})^{\mu} \right\}, \quad \mu \in (0, 1)
   </math>
   <br/>
   (42)
  </p>
  <p block-type="Text">
   One can now use methods for complete information problems to solve equation
   <math display="inline">
    (42)
   </math>
   , and it can also be shown that the solution to equation
   <math display="inline">
    (42)
   </math>
   gives a solution of the original problem for which
   <math display="inline">
    \rho_t
   </math>
   was assumed
   <math display="inline">
    \mathcal{F}^y_t
   </math>
   -adapted.
  </p>
  <p block-type="Text">
   We remark that other reformulations of the incomplete information problem as a complete information one are also possible (see e.g., [20]).
  </p>
  <p block-type="TextInlineMath">
   A final comment concerns hedging under incomplete information (incomplete market). When using the quadratic hedging criterion, that is,
   <math display="inline">
    \min_{\rho} E_{S_0, V_0}
   </math>
   <math display="inline">
    \{(H_T - V_T^{\rho})^2\}
   </math>
   , its quadratic nature implies that if
   <math display="inline">
    \phi_t^*(x_t, y_t)
   </math>
   is the optimal strategy (number of units invested in the risky asset) under complete information also of
   <math display="inline">
    x_t
   </math>
   , then, under the partial information
   <math display="inline">
    \mathcal{F}_t^y
   </math>
   , the optimal strategy is simply the projection
   <math display="inline">
    E\{\phi_t^*(x_t, y_t) \mid \mathcal{F}_t^y\}
   </math>
   that can be computed on the basis of the filter of
   <math display="inline">
    x_t
   </math>
   given
   <math display="inline">
    \mathcal{F}_t^y
   </math>
   (see [12]).
  </p>
  <h3>
   References
  </h3>
  <p block-type="Text">
   Bain, A. &amp; Crisan, D. (2009). Fundamentals of stochas-[1] tic filtering, in Series: Stochastic Modelling and Applied Probability, Vol. 60, Springer Science+Business Media, New York.
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     Bhar, R. Chiarella, C. Hung, H. &amp; Runggaldier, W. [2] (2005). The volatility of the instantaneous spot interest rate implied by arbitrage pricing—a dynamic Bayesian approach. Automatica 42, 1381-1393.
    </li>
    <li block-type="ListItem">
     Budhiraja, A., Chen, L. &amp; Lee, C. (2007). A survey [3] of nonlinear methods for nonlinear filtering problems. Physica D 230, 27-36.
    </li>
    <li block-type="ListItem">
     [4] Corsi, M., Pham, H. &amp; Runggaldier, W.J. (2008). Numerical approximation by quantization of control problems in finance under partial observations, to appear in Mathematical Modeling and Numerical Methods in Finance. Handbook of Numerical Analysis, A. Bensoussan &amp; Q. Zhang, eds, Elsevier, Vol. 15.
    </li>
    <li block-type="ListItem">
     Crisan, D., Del Moral, P. &amp; Lyons, T. (1999). Inter-[5] acting particle systems approximations of the Kushner-Stratonovich equation, Advances in Applied Probability 31, 819-838.
    </li>
    <li block-type="ListItem">
     [6] Cvitanic, J., Liptser, R. &amp; Rozovski, B. (2006). A filtering approach to tracking volatility from prices observed at random times, The Annals of Applied Probability 16, 1633-1652
    </li>
    <li block-type="ListItem">
     [7] Cvitanic, J., Rozovski, B. &amp; Zaliapin, I. (2006). Numerical estimation of volatility values from discretely observed diffusion data, Journal of Computational Finance
     <math display="inline">
      9, 1-36.
     </math>
    </li>
    <li block-type="ListItem">
     Davis, M.H.A. &amp; Marcus, S.I. (1981). An Introduction [8] to nonlinear filtering, in Stochastic Systems: The Mathematics of Filtering and Identification and Applications M. Hazewinkel &amp; J.C. Willems, eds, D.Reidel, Dordrecht, pp. 53-75.
    </li>
    <li block-type="ListItem">
     Duffie, D. &amp; Lando, D. (2001). Term structure of [9] credit risk with incomplete accounting observations, Econometrica 69, 633-664.
    </li>
    <li block-type="ListItem">
     [10] Elliott, R.J. (1993). New finite-dimensional filters and smoothers for noisily observed Markov chains, IEEE Transactions on Information Theory, IT-39, 265-271.
    </li>
    <li block-type="ListItem">
     Elliott, R.J., Aggoun, L. &amp; Moore, J.B. (1994). Hidden
     <math display="inline">
      [11]
     </math>
     Markov models: estimation and control, in Applications of Mathematics, Springer-Verlag, Berlin-Heidelberg-New York, Vol. 29.
    </li>
    <li block-type="ListItem">
     Frey, R. &amp; Runggaldier, W. (1999). Risk-minimizing [12] hedging strategies under restricted information: the case of stochastic volatility models observed only at discrete random times, Mathematical Methods of Operations Research 50(3), 339-350.
    </li>
    <li block-type="ListItem">
     [13] Frey, R. &amp; Runggaldier, W. (2008). Credit risk and incomplete information: a nonlinear filtering approach, preprint, Universitat Leipzig, Available from www.math. uni-leipzig.de/%7Efrey/publications-frey.html.
    </li>
    <li block-type="ListItem">
     [14] Frey, R. &amp; Runggaldier, W.R. Nonlinear filtering in models for interest-rate and credit risk, to appear in Handbook of Nonlinear Filtering, D. Crisan &amp; B. Rozovski, eds, Oxford University Press (to be published in 2009).
    </li>
    <li block-type="ListItem">
     [15] Gombani, A., Jaschke, S. &amp; Runggaldier, W. (2005). A filtered no arbitrage model for term structures with noisy data, Stochastic Processes and Applications 115,
     <math display="inline">
      381 - 400.
     </math>
    </li>
   </ul>
  </p>
 </body>
</html>
