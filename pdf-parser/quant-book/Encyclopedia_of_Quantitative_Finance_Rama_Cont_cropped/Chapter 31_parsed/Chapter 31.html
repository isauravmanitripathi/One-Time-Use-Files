<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
 </head>
 <body>
  <h1>
   <b>
    Poisson Process
   </b>
  </h1>
  <p block-type="Text">
   In this article, we present the main results on Poisson processes, which are standard examples of jump processes. The reader can refer to the books [2, 5] for the study of standard Poisson processes, or
   <math display="inline">
    [1, 3,
   </math>
   4, 6] for general Poisson processes.
  </p>
  <h1>
   <b>
    Counting Processes and Stochastic
   </b>
   Integrals
  </h1>
  <p block-type="TextInlineMath">
   Let
   <math display="inline">
    (T_n, n \ge 0)
   </math>
   be a strictly increasing sequence of random times (i.e., nonnegative random variables on a probability space
   <math display="inline">
    (\Omega, \mathcal{F}, \mathbb{P})
   </math>
   such that
   <math display="inline">
    \lim_{n\to\infty} T_n = \infty
   </math>
   , with
   <math display="inline">
    T_0 = 0
   </math>
   . The counting process N associated with
   <math display="inline">
    (T_n, n \ge 0)
   </math>
   is defined as
  </p>
  <p block-type="Equation">
   <math display="block">
    N_t = \begin{cases} n &amp; \text{if } t \in [T_n, T_{n+1}[\\ +\infty &amp; \text{otherwise} \end{cases} \tag{1}
   </math>
  </p>
  <p block-type="Text">
   or, equivalently,
  </p>
  <p block-type="Equation">
   <math display="block">
    N_t = \sum_{n\geq 1} \mathbb{1}_{\{T_n \leq t\}} = \sum_{n\geq 1} n \mathbb{1}_{\{T_n \leq t &lt; T_{n+1}\}} \qquad (2)
   </math>
  </p>
  <p block-type="TextInlineMath">
   It is an increasing, right-continuous process. We denote by
   <math display="inline">
    N_{t^-}
   </math>
   the left limit of
   <math display="inline">
    N_s
   </math>
   when
   <math display="inline">
    s \to t
   </math>
   ,
   <math display="inline">
    s &lt; t
   </math>
   and by
   <math display="inline">
    \Delta N_s = N_s - N_{s^-}
   </math>
   the jump process of N. The stochastic integral of a real-valued process
   <math display="inline">
    C
   </math>
   with respect to the increasing process
   <math display="inline">
    N
   </math>
   is defined as
  </p>
  <p block-type="Equation">
   <math display="block">
    (C \star N)_t := \int_0^t C_s \, \mathrm{d}N_s = \int_{]0,t]} C_s \, \mathrm{d}N_s
   </math>
   <math display="block">
    = \sum_{n=1}^\infty C_{T_n} \, 1\!\!1_{\{T_n \le t\}} \tag{3}
   </math>
  </p>
  <p block-type="Text">
   The natural filtration of
   <math display="inline">
    N
   </math>
   (i.e., the smallest rightcontinuous and complete filtration that makes the process N adapted) is denoted by
   <math display="inline">
    \mathbf{F}^N
   </math>
   .
  </p>
  <h1>
   <b>
    Standard Poisson Process
   </b>
  </h1>
  <p block-type="TextInlineMath">
   The standard Poisson process is a counting process
   <math display="inline">
    (N_t, t \ge 0)
   </math>
   with stationary and independent increments, that is,
  </p>
  <p block-type="Text">
   for every
   <math display="inline">
    s, t \ge 0, N_{t+s} - N_t
   </math>
   is independent of
   <math display="inline">
    \mathcal{F}_{t}^{N}
   </math>
   ; and
  </p>
  <p block-type="Text">
   • for every
   <math display="inline">
    s, t \ge 0
   </math>
   , the r.v.
   <math display="inline">
    N_{t+s} - N_t
   </math>
   has the same law as
   <math display="inline">
    N_{\rm s}
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   For any fixed
   <math display="inline">
    t \ge 0
   </math>
   , the random variable
   <math display="inline">
    N_t
   </math>
   has a Poisson law, with parameter
   <math display="inline">
    \lambda t
   </math>
   , that is,
   <math display="inline">
    \mathbb{P}(N_t = n) =
   </math>
   <math display="inline">
    e^{-\lambda t} ((\lambda t)^n/n!)
   </math>
   and, for every
   <math display="inline">
    x &gt; 0, t &gt; 0, u, \alpha \in \mathbb{R}
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}(N_t) = \lambda t, \quad \text{Var}(N_t) = \lambda t
   </math>
   <br/>
   <math display="block">
    \mathbb{E}(x^{N_t}) = e^{\lambda t (x-1)}; \mathbb{E}(e^{iuN_t}) = e^{\lambda t (e^{iu} - 1)};
   </math>
   <br/>
   <math display="block">
    \mathbb{E}(e^{\alpha N_t}) = e^{\lambda t (e^{\alpha} - 1)}
   </math>
   <br/>
   (4)
  </p>
  <p block-type="TextInlineMath">
   From the property of independence and stationarity of the increments, it follows that the process
   <math display="inline">
    (M_t)
   </math>
   <math display="inline">
    N_t - \lambda t, t \ge 0
   </math>
   is a martingale. More generally, if H is an
   <math display="inline">
    \mathbf{F}^N
   </math>
   -predictable&lt;sup&gt;a&lt;/sup&gt; bounded process, then the following processes are
   <math display="inline">
    \mathbf{F}^N
   </math>
   -martingales:
  </p>
  <p block-type="Equation">
   <math display="block">
    (H \star M)_t := \int_0^t H_s \, \mathrm{d}M_s = \int_0^t H_s \, \mathrm{d}N_s - \lambda \int_0^t H_s \, \mathrm{d}s
   </math>
   <math display="block">
    ((H \star M)_t)^2 - \lambda \int_0^t H_s^2 \, \mathrm{d}s
   </math>
   <math display="block">
    \exp\left(\int_0^t H_s \, \mathrm{d}N_s - \lambda \int_0^t (\mathrm{e}^{H_s} - 1) \, \mathrm{d}s\right) \tag{5}
   </math>
  </p>
  <p block-type="TextInlineMath">
   In particular, the processes
   <math display="inline">
    (M_t^2 - \lambda t, t \ge 0)
   </math>
   and
   <math display="inline">
    (M_t^2 - N_t, t \ge 0)
   </math>
   are martingales. The process
   <math display="inline">
    (\lambda t,
   </math>
   <math display="inline">
    t &gt; 0
   </math>
   ) is the predictable quadratic variation process of
   <i>
    M
   </i>
   (or the compensator of
   <i>
    N
   </i>
   ), denoted by
   <math display="inline">
    \langle N \rangle
   </math>
   , the process
   <math display="inline">
    (N_t, t \ge 0)
   </math>
   equals in this case its optional quadratic variation, denoted by
   <math display="inline">
    [N]
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   The above martingale properties do not extend to
   <math display="inline">
    \mathbf{F}^N
   </math>
   -adapted processes H. For example, from the simple equality
   <math display="inline">
    \int_0^t (N_s - N_{s-}) dM_s = N_t
   </math>
   , it follows that
   <math display="inline">
    \int_0^t N_s \, \mathrm{d}M_s
   </math>
   is not a martingale.
  </p>
  <h4>
   Predictable Representation Property
  </h4>
  <p block-type="TextInlineMath">
   <b>
    Proposition 1
   </b>
   Let
   <math display="inline">
    N
   </math>
   be a Poisson process, and
   <math display="inline">
    H_{\infty} \in L^2(\mathcal{F}^N_{\infty})
   </math>
   , a square-integrable random variable. Then, there exists an
   <math display="inline">
    \mathbf{F}^N
   </math>
   -predictable process (h.,
   <math display="inline">
    s \ge 0
   </math>
   ) such that
  </p>
  <p block-type="Equation">
   <math display="block">
    H_{\infty} = \mathbb{E}(H_{\infty}) + \int_{0}^{\infty} h_s \, \mathrm{d}M_s \tag{6}
   </math>
  </p>
  <p block-type="TextInlineMath">
   and
   <math display="inline">
    \mathbb{E}\left(\int_0^\infty h_s^2 \, \mathrm{d}s\right) &lt; \infty
   </math>
   , where
   <math display="inline">
    M_t = N_t - \lambda t
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   It follows that if X is a square-integrable
   <math display="inline">
    \mathbf{F}^N
   </math>
   martingale, there exists an
   <math display="inline">
    \mathbf{F}^N
   </math>
   - predictable process
   <math display="inline">
    (x_s, s \ge 0)
   </math>
   such that
   <math display="inline">
    X_t = X_0 + \int_0^t x_s \, \mathrm{d}M_s
   </math>
   .
  </p>
  <h2>
   Independent Poisson Processes
  </h2>
  <p block-type="Text">
   Here, we assume that the probability space
   <math display="inline">
    (\Omega, \mathcal{F}, \mathbb{P})
   </math>
   is endowed with a filtration
   <math display="inline">
    \mathbf{F}
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   A process
   <math display="inline">
    (N^1,\ldots,N^d)
   </math>
   is a d-dimensional
   <b>
    F
   </b>
   -Poisson process (with
   <math display="inline">
    d &gt; 1
   </math>
   ) if each
   <math display="inline">
    (N^j, i =
   </math>
   <math display="inline">
    1, \ldots, d)
   </math>
   is a right-continuous
   <b>
    F
   </b>
   -adapted process such that
   <math display="inline">
    N_0^j = 0
   </math>
   , and if there exist constants
   <math display="inline">
    (\lambda_j, j = 1, \ldots, d)
   </math>
   such that for every
   <math display="inline">
    t \ge s \ge 0
   </math>
   ,
   <math display="inline">
    \forall n_i \in \mathbb{N},
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{P}\left[\bigcap_{j=1}^{d}(N_t^j - N_s^j = n_j)|\mathcal{F}_s\right]
   </math>
   <math display="block">
    = \prod_{j=1}^{d} e^{-\lambda_j(t-s)} \frac{(\lambda_j(t-s))^{n_j}}{n_j!} \tag{7}
   </math>
  </p>
  <p block-type="TextInlineMath">
   <b>
    Proposition 2
   </b>
   An
   <math display="inline">
    \mathbf{F}
   </math>
   -adapted process N is a
   <math display="inline">
    d
   </math>
   -dimensional
   <b>
    F
   </b>
   -Poisson process if and only if
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     1. each
     <math display="inline">
      N^j
     </math>
     is an
     <b>
      F
     </b>
     -Poisson process
    </li>
    <li block-type="ListItem">
     2. no two
     <math display="inline">
      N^j
     </math>
     's jump simultaneously.
    </li>
   </ul>
  </p>
  <h4>
   Inhomogeneous Poisson Processes
  </h4>
  <p block-type="Text">
   We assume that the probability space
   <math display="inline">
    (\Omega, \mathcal{F}, \mathbb{P})
   </math>
   is endowed with a filtration
   <math display="inline">
    \mathbf{F}
   </math>
   .
  </p>
  <h2>
   Definition
  </h2>
  <p block-type="TextInlineMath">
   Let
   <math display="inline">
    \lambda
   </math>
   be an
   <b>
    F
   </b>
   -adapted nonnegative process satisfying
   <math display="inline">
    \mathbb{E}\left(\int_0^t \lambda_s \, \mathrm{d}s\right) &lt; \infty, \forall t, \text{ and } \int_0^\infty \lambda_s \, \mathrm{d}s = \infty.
   </math>
  </p>
  <p block-type="TextInlineMath">
   An inhomogeneous Poisson process
   <math display="inline">
    N
   </math>
   with stochastic intensity
   <math display="inline">
    \lambda
   </math>
   is a counting process such that for every nonnegative
   <b>
    F
   </b>
   -predictable process
   <math display="inline">
    (\phi_t,
   </math>
   <math display="inline">
    t \ge 0
   </math>
   ), the following equality is satisfied:
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\left(\int_0^\infty \phi_s \, \mathrm{d}N_s\right) = \mathbb{E}\left(\int_0^\infty \phi_s \lambda_s \, \mathrm{d}s\right) \qquad (8)
   </math>
  </p>
  <p block-type="TextInlineMath">
   Therefore
   <math display="inline">
    (M_t = N_t - \int_0^t \lambda_s \, ds, \, t \ge 0)
   </math>
   is an
   <b>
    F
   </b>
   martingale, and if
   <math display="inline">
    \phi
   </math>
   is an
   <b>
    F
   </b>
   -predictable process such that
   <math display="inline">
    \forall t, \ \mathbb{E}(\int_0^t |\phi_s| \lambda_s \, \mathrm{d}s) &lt; \infty
   </math>
   , then
   <math display="inline">
    (\int_0^t \phi_s \, \mathrm{d}M_s,
   </math>
   <math display="inline">
    t \ge 0
   </math>
   ) is an
   <b>
    F
   </b>
   -martingale. The process
   <math display="inline">
    \Lambda_t = \int_0^t \lambda_s \, ds
   </math>
   is called the
   <i>
    compensator of
   </i>
   <math display="inline">
    N
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   An inhomogeneous Poisson process with stochastic intensity
   <math display="inline">
    \lambda
   </math>
   can be viewed as a time change of
   <math display="inline">
    \widetilde{N}
   </math>
   , a standard Poisson process: indeed, the process
   <math display="inline">
    (N_t = N_{\Lambda_t}, t \ge 0)
   </math>
   is an inhomogeneous Poisson process with stochastic intensity
   <math display="inline">
    (\lambda_t, t \ge 0)
   </math>
   .
  </p>
  <p block-type="Text">
   For
   <math display="inline">
    H
   </math>
   an
   <b>
    F
   </b>
   -predictable process satisfying some integrability conditions, the following processes are martingales:
  </p>
  <p block-type="Equation">
   <math display="block">
    (H \star M)_t = \int_0^t H_s \, \mathrm{d}M_s = \int_0^t H_s \, \mathrm{d}N_s - \int_0^t \lambda_s H_s \, \mathrm{d}s
   </math>
   <math display="block">
    ((H \star M)_t)^2 - \int_0^t \lambda_s H_s^2 \, \mathrm{d}s
   </math>
   <math display="block">
    \exp\left(\int_0^t H_s \, \mathrm{d}N_s - \int_0^t \lambda_s (\mathrm{e}^{H_s} - 1) \, \mathrm{d}s\right) \tag{9}
   </math>
  </p>
  <h2>
   Stochastic Calculus
  </h2>
  <p block-type="TextInlineMath">
   <b>
    Integration by Parts Formula.
   </b>
   Let
   <math display="inline">
    dX_t = b_t dt +
   </math>
   <math display="inline">
    \varphi_t \, \mathrm{d}M_t
   </math>
   and
   <math display="inline">
    \mathrm{d}Y_t = c_t \, \mathrm{d}t + \psi_t \, \mathrm{d}M_t
   </math>
   , where
   <math display="inline">
    \varphi
   </math>
   and
   <math display="inline">
    \psi
   </math>
   are predictable processes, and
   <math display="inline">
    b, c
   </math>
   are adapted processes such that the processes
   <math display="inline">
    X
   </math>
   and
   <math display="inline">
    Y
   </math>
   are well defined. Then,
  </p>
  <p block-type="Equation">
   <math display="block">
    X_t Y_t = xy + \int_0^t Y_{s^-} dX_s + \int_0^t X_{s^-} dY_s + [X, Y]_t
   </math>
   (10)
  </p>
  <p block-type="Text">
   where
   <math display="inline">
    [X, Y]_t
   </math>
   is the quadratic covariation process, defined as
  </p>
  <p block-type="Equation">
   <math display="block">
    [X, Y]_t: = \int_0^t \varphi_s \psi_s \, \mathrm{d}N_s \tag{11}
   </math>
  </p>
  <p block-type="TextInlineMath">
   In particular, if
   <math display="inline">
    dX_t = \varphi_t dM_t
   </math>
   and
   <math display="inline">
    dY_t = \psi_t dM_t
   </math>
   (i.e., X and Y are local martingales), the process
   <math display="inline">
    (X_t Y_t  [X, Y]_t, t \ge 0
   </math>
   is a martingale. It can be noted that, in that case, the process
   <math display="inline">
    (X_t Y_t - \langle X, Y \rangle_t, t \ge 0)
   </math>
   ,&lt;br&gt;where
   <math display="inline">
    \langle X, Y \rangle_t = \int_0^t \varphi_s \psi_s \lambda_s \, ds
   </math>
   is also a martingale. The process
   <math display="inline">
    \langle X, Y \rangle
   </math>
   is the compensator of
   <math display="inline">
    [X, Y]
   </math>
   if
   <math display="inline">
    [X, Y]
   </math>
   is integrable (see
   <b>
    Compensators
   </b>
   ). The predictable process
   <math display="inline">
    (\langle X, Y \rangle_t, t \ge 0)
   </math>
   is called the
   <i>
    predictable covariation process
   </i>
   of the pair
   <math display="inline">
    (X, Y)
   </math>
   , or the
   <i>
    compensator
   </i>
   of the product XY. If
   <math display="inline">
    dX_t^i = x_t^i dN_t^i
   </math>
   , where
   <math display="inline">
    N^i
   </math>
   ,
   <math display="inline">
    i = 1, 2
   </math>
   are independent inhomogeneous Poisson processes, the covariation processes
   <math display="inline">
    [X^1, X^1]
   </math>
   and
   <math display="inline">
    \langle X^1, X^2 \rangle
   </math>
   are null, and
   <math display="inline">
    X^1 X^2
   </math>
   is a martingale.
  </p>
  <p block-type="Text" class="has-continuation">
   Itô's Formula. Itô's formula is a special case of the general one; it is a bit simpler and is used for the
  </p>
  <p block-type="Text">
   processes that are within bounded variation. Let
   <math display="inline">
    b
   </math>
   be an adapted process and
   <math display="inline">
    \varphi
   </math>
   a predictable process with adequate integrability conditions, and
  </p>
  <p block-type="Equation">
   <math display="block">
    dX_t = b_t dt + \varphi_t dM_t = (b_t - \varphi_t \lambda_t) dt + \varphi_t dN_t
   </math>
   (12)
  </p>
  <p block-type="TextInlineMath">
   and
   <math display="inline">
    F \in C^{1,1}(\mathbb{R}^+ \times \mathbb{R})
   </math>
   . Then, the process
   <math display="inline">
    (F(t, X_t),
   </math>
   <math display="inline">
    t &gt; 0
   </math>
   ) is a semimartingale with decomposition
  </p>
  <p block-type="Equation">
   <math display="block">
    F(t, X_t) = Z_t + A_t \tag{13}
   </math>
  </p>
  <p block-type="Text">
   where
   <math display="inline">
    Z
   </math>
   is a local martingale given by
  </p>
  <p block-type="Equation">
   <math display="block">
    Z_{t} = F(0, X_{0})
   </math>
   <br/>
   +
   <math display="block">
    \int_{0}^{t} [F(s, X_{s^{-}} + \varphi_{s}) - F(s, X_{s^{-}})] dM_{s} \quad (14)
   </math>
  </p>
  <p block-type="Text">
   and
   <math display="inline">
    A
   </math>
   a bounded variation process
  </p>
  <p block-type="Equation">
   <math display="block">
    A_{t} = \int_{0}^{t} \left( \partial_{t} F(s, X_{s}) + b_{s} \partial_{x} F(s, X_{s}) \right.
   </math>
   <br/>
   <math display="block">
    + \lambda_{s} \left[ F(s, X_{s} - \varphi_{s}) - F(s, X_{s}) - \varphi_{s} \partial_{x} F(s, X_{s}) \right] \right) \mathrm{d}s \tag{15}
   </math>
  </p>
  <h4>
   Exponential Martingales
  </h4>
  <p block-type="TextInlineMath">
   <b>
    Proposition 3
   </b>
   Let
   <math display="inline">
    N
   </math>
   be an inhomogeneous Poisson process with stochastic intensity
   <math display="inline">
    (\lambda_t, t \ge 0)
   </math>
   , and
   <math display="inline">
    (\mu_t, t \ge 0)
   </math>
   a predictable process such that
   <math display="inline">
    \int_0^t |\mu_s| \lambda_s \, ds &lt; \infty
   </math>
   . Then, the process L defined by
  </p>
  <p block-type="Equation">
   <math display="block">
    L_{t} = \begin{cases} \exp\left(-\int_{0}^{t} \mu_{s} \lambda_{s} \, \mathrm{d}s\right) &amp; \text{if } t &lt; T_{1} \\ \prod_{n, T_{n} \leq t} (1 + \mu_{T_{n}}) \\ \times \exp\left(-\int_{0}^{t} \mu_{s} \lambda_{s} \, \mathrm{d}s\right) &amp; \text{if } t \geq T_{1} \end{cases} \tag{16}
   </math>
  </p>
  <p block-type="Text">
   is a local martingale solution of
  </p>
  <p block-type="Equation">
   <math display="block">
    L_t = L_{t-} \mu_t \, \mathrm{d}M_t, \quad L_0 = 1 \tag{17}
   </math>
  </p>
  <p block-type="TextInlineMath">
   <i>
    Moreover, if
   </i>
   <math display="inline">
    \mu
   </math>
   <i>
    is such that
   </i>
   <math display="inline">
    \forall s, \mu_s &gt; -1
   </math>
   <i>
    ,
   </i>
  </p>
  <p block-type="Equation">
   <math display="block">
    L_{t} = \exp\left[-\int_{0}^{t} \mu_{s} \lambda_{s} \, \mathrm{d}s + \int_{0}^{t} \ln(1+\mu_{s}) \, \mathrm{d}N_{s}\right]
   </math>
   <math display="block">
    = \exp\left[-\int_{0}^{t} (\mu_{s} - \ln(1+\mu_{s}))\lambda_{s} \, \mathrm{d}s + \int_{0}^{t} \ln(1+\mu_{s}) \, \mathrm{d}M_{s}\right]
   </math>
   (18)
  </p>
  <p block-type="TextInlineMath">
   The local martingale L is denoted by
   <math display="inline">
    \mathcal{E}(\mu \star M)
   </math>
   and named the
   <i>
    Doléans-Dade exponential
   </i>
   (alternatively, the
   <i>
    stochastic exponential
   </i>
   ) of the process
   <math display="inline">
    \mu \star M
   </math>
   . If
   <math display="inline">
    \mu &gt; -1
   </math>
   , the process L is nonnegative and is a martingale if
   <math display="inline">
    \forall t
   </math>
   ,
   <math display="inline">
    \mathbb{E}(L_t) = 1
   </math>
   (this is the case if
   <math display="inline">
    \mu
   </math>
   satisfies
   <math display="inline">
    -1 + \delta &lt; \mu_s &lt; C
   </math>
   where C and
   <math display="inline">
    \delta &gt; 0
   </math>
   are two constants).
  </p>
  <p block-type="Text">
   If
   <math display="inline">
    \mu
   </math>
   is not greater than
   <math display="inline">
    -1
   </math>
   , then the process L defined in equation
   <math display="inline">
    (16)
   </math>
   may take negative values.
  </p>
  <h4>
   Change of Probability Measure
  </h4>
  <p block-type="TextInlineMath">
   Let
   <math display="inline">
    \mu
   </math>
   be a predictable process such that
   <math display="inline">
    \mu &gt; -1
   </math>
   , and
   <math display="inline">
    \int_0^t \lambda_s |\mu_s| ds &lt; \infty
   </math>
   , and let L be the positive exponential local martingale solution of
  </p>
  <p block-type="Equation">
   <math display="block">
    dL_t = L_{t-} \mu_t dM_t, \quad L_0 = 1 \tag{19}
   </math>
  </p>
  <p block-type="TextInlineMath">
   Assume that L is a martingale, and let
   <math display="inline">
    \mathbb{Q}
   </math>
   be the probability measure equivalent to
   <math display="inline">
    \mathbb{P}
   </math>
   defined on
   <math display="inline">
    \mathcal{F}_t
   </math>
   by
   <math display="inline">
    \mathbb{Q}|_{\mathcal{F}_t} = L_t \mathbb{P}|_{\mathcal{F}_t}
   </math>
   . Under
   <math display="inline">
    \mathbb{Q}
   </math>
   , the process
  </p>
  <p block-type="Equation">
   <math display="block">
    M_t^{\mu} := M_t - \int_0^t \mu_s \lambda_s \, \mathrm{d}s
   </math>
   <br/>
   =
   <math>
    N_t - \int_0^t (\mu_s + 1) \lambda_s \, \mathrm{d}s \quad t \ge 0
   </math>
   (20)
  </p>
  <p block-type="TextInlineMath">
   is a local martingale, hence
   <i>
    N
   </i>
   is a
   <math display="inline">
    \mathbb{Q}
   </math>
   -inhomogeneous Poisson process, with intensity
   <math display="inline">
    \lambda(1+\mu)
   </math>
   .
  </p>
  <h4>
   <b>
    Compound Poisson Processes
   </b>
  </h4>
  <h4>
   Definition and Properties
  </h4>
  <p block-type="TextInlineMath">
   Let
   <math display="inline">
    \lambda
   </math>
   be a positive number, and
   <math display="inline">
    F(\mathrm{d}y)
   </math>
   be a probability law on
   <math display="inline">
    \mathbb{R}
   </math>
   . A
   <math display="inline">
    (\lambda, F)
   </math>
   -compound Poisson process is a process
   <math display="inline">
    X = (X_t, t \ge 0)
   </math>
   of the form
  </p>
  <p block-type="Equation">
   <math display="block">
    X_{t} = \sum_{n=1}^{N_{t}} Y_{n} = \sum_{n&gt;0, T_{n} \leq t} Y_{n}
   </math>
   (21)
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    N
   </math>
   is a standard Poisson process with intensity
   <math display="inline">
    \lambda &gt; 0
   </math>
   , and the
   <math display="inline">
    (Y_n, n \ge 1)
   </math>
   are i.i.d. square-integrable random variables with law
   <math display="inline">
    F(dy) = \mathbb{P}(Y_1 \in dy)
   </math>
   , independent of
   <math display="inline">
    N
   </math>
   .
  </p>
  <p block-type="Text" class="has-continuation">
   <b>
    Proposition 4
   </b>
   A compound Poisson process has
   <math display="inline">
    stationary
   </math>
   and
   <math display="inline">
    independent
   </math>
   <math display="inline">
    increments
   </math>
   ; for fixed
   <math display="inline">
    t
   </math>
   , the
  </p>
  <p block-type="Text">
   <i>
    cumulative distribution function of
   </i>
   <math display="inline">
    X_t
   </math>
   <i>
    is
   </i>
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{P}(X_t \le x) = e^{-\lambda t} \sum_{n=0}^{\infty} \frac{(\lambda t)^n}{n!} F^{*n}(x) \qquad (22)
   </math>
  </p>
  <p block-type="Text">
   where the star indicates a convolution.
  </p>
  <p block-type="TextInlineMath">
   If
   <math display="inline">
    \mathbb{E}(|Y_1|) &lt; \infty
   </math>
   , the process
   <math display="inline">
    (Z_t = X_t - t\lambda \mathbb{E}(Y_1),
   </math>
   <math display="inline">
    t \geq 0
   </math>
   ) is a martingale and
   <math display="inline">
    \mathbb{E}(X_t) = \lambda t \mathbb{E}(Y_1)
   </math>
   . If
   <math display="inline">
    \mathbb{E}(Y_1^2) &lt; \infty
   </math>
   , the process
   <math display="inline">
    (Z_t^2 - t\lambda \mathbb{E}(Y_1^2))
   </math>
   ,
   <math display="inline">
    t \ge 0
   </math>
   ) is a martingale and Var
   <math display="inline">
    (X_t) = \lambda t \mathbb{E}(Y_t^2)
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   Introducing the random measure
   <math display="inline">
    \mu = \sum_{n=1}^{\infty} \delta_{T_n, Y_n}
   </math>
   on
   <math display="inline">
    \mathbb{R}^+ \times \mathbb{R}
   </math>
   , that is,
  </p>
  <p block-type="Equation">
   <math display="block">
    \mu(\omega, ]0, t], A) = \sum_{n&gt;0, T_n(\omega) \le t} \mathbb{1}_{Y_n(\omega) \in A} \tag{23}
   </math>
  </p>
  <p block-type="TextInlineMath">
   and denoting by
   <math display="inline">
    (f * \mu)_t
   </math>
   , the integral
  </p>
  <p block-type="Equation">
   <math display="block">
    \int_0^t \int_{\mathbb{R}} f(x) \mu(\omega, \, \mathrm{d}s, \, \mathrm{d}x) = \sum_{n&gt;0, T_n \le t} f(Y_n(\omega))
   </math>
   <math display="block">
    = \sum_{n=1}^{N_t} f(Y_n(\omega)) \tag{24}
   </math>
  </p>
  <p block-type="Text">
   we obtain that
  </p>
  <p block-type="Equation">
   <math display="block">
    M_t^f = (f * \mu)_t - t\lambda \mathbb{E}(f(Y_1))
   </math>
   <br/>
   =
   <math display="block">
    \int_0^t \int_{\mathbb{R}} f(x)(\mu(\omega, ds, dx) - \lambda F(dx) ds) \tag{25}
   </math>
  </p>
  <p block-type="Text">
   is a martingale.
  </p>
  <h4>
   Martingales
  </h4>
  <p block-type="TextInlineMath">
   <b>
    Proposition 5
   </b>
   If X is a
   <math display="inline">
    (\lambda, F)
   </math>
   -compound Poisson process, for any
   <math display="inline">
    \alpha
   </math>
   such that
   <math display="inline">
    \int_{-\infty}^{\infty} e^{\alpha x} F(dx) &lt; \infty
   </math>
   , the
   <math display="inline">
    process
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    Z_{t} = \exp\left(\alpha X_{t} - \lambda t \int_{-\infty}^{\infty} (e^{\alpha x} - 1) F(dx)\right) \quad (26)
   </math>
  </p>
  <p block-type="Text">
   is a martingale and
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}(\mathrm{e}^{\alpha X_{t}}) = \exp\left(\lambda t \int_{-\infty}^{\infty} (\mathrm{e}^{\alpha x} - 1) F(\mathrm{d}x)\right)
   </math>
   <math display="block">
    = \exp\left(\lambda t (\mathbb{E}(\mathrm{e}^{\alpha Y_{1}} - 1))\right) \tag{27}
   </math>
  </p>
  <p block-type="TextInlineMath">
   In other words, for any
   <math display="inline">
    \alpha
   </math>
   such that
   <math display="inline">
    \mathbb{E}(e^{\alpha X_t}) &lt;
   </math>
   <math display="inline">
    \infty
   </math>
   (or equivalently
   <math display="inline">
    \mathbb{E}(e^{\alpha Y_1}) &lt; \infty
   </math>
   ), the process
   <math display="inline">
    (e^{\alpha X_t}/\mathbb{E}(e^{\alpha \bar{X}_t}), t \ge 0)
   </math>
   is a martingale. More generally, let
   <math display="inline">
    f
   </math>
   be a bounded Borel function. Then, the process
  </p>
  <p block-type="Equation">
   <math display="block">
    \exp\left(\sum_{n=1}^{N_t} f(Y_n) - \lambda t \int_{-\infty}^{\infty} (e^{f(x)} - 1) F(dx)\right) \tag{28}
   </math>
  </p>
  <p block-type="Text">
   is a martingale. In particular,
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\left(\exp\left(\sum_{n=1}^{N_t} f(Y_n)\right)\right)
   </math>
   <math display="block">
    =\exp\left(\lambda t \int_{-\infty}^{\infty} (e^{f(x)} - 1) F(dx)\right) \qquad (29)
   </math>
  </p>
  <h4>
   Change of Measure
  </h4>
  <p block-type="TextInlineMath">
   Let X be a
   <math display="inline">
    (\lambda, F)
   </math>
   -compound Poisson process,
   <math display="inline">
    \tilde{\lambda} &gt; 0
   </math>
   , and
   <math display="inline">
    \tilde{F}
   </math>
   a probability measure on
   <math display="inline">
    \mathbb{R}
   </math>
   , absolutely continuous with respect to
   <math display="inline">
    F
   </math>
   , with Radon-Nikodym density
   <math display="inline">
    \varphi
   </math>
   , that is,
   <math display="inline">
    F(\mathrm{d}x) = \varphi(x)F(\mathrm{d}x)
   </math>
   . The process
  </p>
  <p block-type="Equation">
   <math display="block">
    L_{t} = \exp\left(t(\lambda - \widetilde{\lambda}) + \sum_{s \leq t} \ln\left(\frac{\widetilde{\lambda}}{\lambda} \varphi(\Delta X_{s})\right)\right) \tag{30}
   </math>
  </p>
  <p block-type="TextInlineMath">
   is a positive martingale (take
   <math display="inline">
    f(x) = \ln((\tilde{\lambda}/\lambda) \varphi(x))
   </math>
   in equation (28)) with expectation 1. Set
   <math display="inline">
    d\mathbb{Q}|_{\mathcal{F}}
   </math>
   =
   <math display="inline">
    L_t d\mathbb{P}|_{\mathcal{F}_t}
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Proposition 6
   </b>
   Under
   <math display="inline">
    \mathbb{Q}
   </math>
   , the process X is a
   <math display="inline">
    (\widetilde{\lambda}, \widetilde{F})
   </math>
   compound Poisson process.
  </p>
  <p block-type="TextInlineMath">
   Let
   <math display="inline">
    \alpha
   </math>
   be such that
   <math display="inline">
    \mathbb{E}(e^{\alpha Y_1}) &lt; \infty
   </math>
   . The particular case with
   <math display="inline">
    \varphi(x) = (e^{\alpha x}/\mathbb{E}(e^{\alpha Y_1}))
   </math>
   and
   <math display="inline">
    \widetilde{\lambda} = \lambda \mathbb{E}(e^{\alpha Y_1})
   </math>
   corresponds to the Esscher transform for which
  </p>
  <p block-type="Equation">
   <math display="block">
    d\mathbb{Q}|_{\mathcal{F}_t} = \frac{e^{\alpha X_t}}{\mathbb{E}(e^{\alpha X_t})} d\mathbb{P}|_{\mathcal{F}_t}
   </math>
   (31)
  </p>
  <p block-type="Text">
   We emphasize that there exist changes of probability that do not preserve the compound Poisson process property. For the predictable representation theorem, see Point Processes.
  </p>
  <h3>
   <i>
    An Example: Double Exponential Model
   </i>
  </h3>
  <h1>
   <b>
    References
   </b>
  </h1>
  <p block-type="Text">
   The compound Poisson process is said to be a double exponential process if the law of the random variable
   <i>
    Y
   </i>
   <sup>
    1
   </sup>
   is
  </p>
  <p block-type="Equation">
   <math display="block">
    F(\mathrm{d}x) = \left(p\theta_1 \mathrm{e}^{-\theta_1 x} \mathbbm{1}_{\{x&gt;0\}} + (1-p)\theta_2 \mathrm{e}^{\theta_2 x} \mathbbm{1}_{\{x&lt;0\}}\right) \mathrm{d}x
   </math>
   (32)
  </p>
  <p block-type="TextInlineMath">
   where
   <i>
    p
   </i>
   ∈]0
   <i>
    ,
   </i>
   1[ and
   <i>
    θi, i
   </i>
   = 1
   <i>
    ,
   </i>
   2 are positive numbers. Under an Esscher transform, this model is still a double exponential model. This particular dynamic allows one to compute the Laplace transform of the first hitting times of a given level.
  </p>
  <h1>
   <b>
    End Notes
   </b>
  </h1>
  <p block-type="Text">
   a
   <i>
    .
   </i>
   We recall that adapted continuous-on-left processes are predictable. The process
   <i>
    N
   </i>
   is not predictable.
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     [1] Bremaud, P. (1981). ´
     <i>
      Point Processes and Queues: Martingale Dynamics
     </i>
     , Springer-Verlag, Berlin.
    </li>
    <li block-type="ListItem">
     [2] ¸Cinlar, E. (1975).
     <i>
      Introduction to Stochastic Processes
     </i>
     , Prentice Hall.
    </li>
    <li block-type="ListItem">
     [3] Cont, R. &amp; Tankov, P. (2004).
     <i>
      Financial Modeling with Jump Processes
     </i>
     , Chapman &amp; Hall/CRC.
    </li>
    <li block-type="ListItem">
     [4] Jeanblanc, M., Yor, M. &amp; Chesney, M. (2009).
     <i>
      Mathematical Models for Financial Markets
     </i>
     , Springer, Berlin.
    </li>
    <li block-type="ListItem">
     [5] Karlin, S. &amp; Taylor, H. (1975).
     <i>
      A First Course in Stochastic Processes
     </i>
     , Academic Press, San Diego.
    </li>
    <li block-type="ListItem">
     [6] Protter, P.E. (2005).
     <i>
      Stochastic Integration and Differential Equations
     </i>
     , 2nd Edition, Springer, Berlin.
    </li>
   </ul>
  </p>
  <h1>
   <b>
    Related Articles
   </b>
  </h1>
  <p block-type="Text">
   <b>
    Levy Processes ´
   </b>
   ;
   <b>
    Martingales
   </b>
   ;
   <b>
    Martingale Representation Theorem
   </b>
   .
  </p>
  <p block-type="Text">
   MONIQUE JEANBLANC
  </p>
 </body>
</html>
