<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
 </head>
 <body>
  <h1>
   <b>
    Risk Management: Historical Perspectives
   </b>
  </h1>
  <p block-type="Text">
   Financial risk management refers to the design and implementation of procedures for identifying, measuring, and managing financial risks. At the heart of any activity in financial markets lies a trade-off between expected profit and risk. Naturally, deciding on a course of action should be based on the best possible evaluation of risk. After all, ignoring risk is a sure recipe for financial disaster.
  </p>
  <p block-type="Text">
   Financial risk management evolved as a distinct discipline in the early 1990s. This was made possible by advances in risk methodologies that, coupled with vast increases in computer processing capabilities, could be applied at the top level of financial institutions. This led to a new type of function, the financial risk manager, which is distinct from the usual business lines. By now, most financial institutions have a "Chief Risk Officer" reporting directly to the top management.
  </p>
  <h2>
   <b>
    The 1970s and Earlier: Foundations of Risk Management
   </b>
  </h2>
  <p block-type="Text">
   Modern risk management builds on a century of advances in analytical risk-management tools, as described in Table 1. To simplify, start with a position in a single financial instrument. Conceptually, risk measurement can be separated into two drivers. The first is exposure or change in the value of the position in response to changes in the risk factor(s). The second is the range of possible movements in the risk factors, which can be described by a probability distribution function. Risk measurement brings together these two drivers by describing the range of possible losses on the position.
  </p>
  <p block-type="Text" class="has-continuation">
   As an example, consider the most basic financial instrument: a bond, which represents a promise of future cash flows. The value of the bond depends on the yield to maturity, which is the main risk factor. The linear part of this exposure is called
   <i>
    duration
   </i>
   . Duration is a measure of the sensitivity of bond prices to small movements in yields (
   <i>
    see
   </i>
   <b>
    Bond
   </b>
   ). This concept was first developed by Macaulay [7] in 1938 and has become the cornerstone of fixedincome portfolio management. Similar concepts were
  </p>
  <p block-type="Text">
   developed later for other instruments. For example, "delta" measures the linear exposure of an option relative to the underlying risk factor. For a long time, risk was evaluated by instrument or for separate business lines.
  </p>
  <p block-type="Text">
   In 1952, Markowitz [8] developed the mean– variance framework (
   <i>
    see
   </i>
   <b>
    Risk–Return Analysis
   </b>
   ), which emphasizes the importance of measuring risk in a total portfolio context. This view was the foundation for modern risk management and led to the award of the 1990 Nobel Prize in Economics.
  </p>
  <p block-type="Text">
   By its nature, centralized risk measurement is a large-scale aggregation problem, which involves a large number of parameters. Consider, for example, the problem of allocating assets among the thousands of stocks available for investment. Generally, the joint movements in the stock prices can be described by a covariance matrix that lists all pairwise correlations. The problem, however, is that the number of coefficients in this matrix rises with the square of the number of stocks. Too many coefficients create several problems, ranging from numerical instability in the covariance matrix to loss of intuitive understanding of the economic drivers of risk. As a result, simplifications are useful.
  </p>
  <p block-type="Text">
   In 1963, Sharpe [10] simplified the covariance structure of stocks with a one-factor model (
   <i>
    see
   </i>
   <b>
    Capital Asset Pricing Model
   </b>
   ). This reduced the dimensionality of the covariance matrix to a number of coefficients that increased linearly with the number of stocks. Such simplification is at the heart of mapping methods in modern risk measurement. In addition, this decomposition leads to a neat decomposition of risk into a systematic factor and an idiosyncratic effect. The first component is common to all the stocks and cannot be diversified away. In contrast, idiosyncratic effects become less important in a large portfolio because they tend to cancel out each other. Sharpe then showed that the only risk that should be priced in equilibrium is systematic risk. This theory of asset pricing, known as the
   <i>
    capital asset pricing model
   </i>
   (
   <i>
    CAPM
   </i>
   ), led to the award of the 1990 Nobel Prize in Economics. In 1966, following Sharpe's single-factor model, multiple-factor models were developed. These provide a more realistic description of common movements among risk factors that it still parsimonious.
  </p>
  <p block-type="Text">
   In parallel, the financial industry was creating new financial instruments to manage, hedge, or take, financial risks. Derivatives are private contracts
  </p>
  <table>
   <tbody>
    <tr>
     <th>
     </th>
     <th>
     </th>
    </tr>
    <tr>
     <th>
      1938
     </th>
     <th>
      Macaulay's bond duration
     </th>
    </tr>
    <tr>
     <td>
      1952
     </td>
     <td>
      Markowitz mean–variance framework
     </td>
    </tr>
    <tr>
     <td>
      1963
     </td>
     <td>
      Sharpe's single-factor beta model
     </td>
    </tr>
    <tr>
     <td>
      1966
     </td>
     <td>
      Multiple factor models
     </td>
    </tr>
    <tr>
     <td>
      1973
     </td>
     <td>
      Black–Scholes option pricing model and "Greeks"
     </td>
    </tr>
    <tr>
     <td>
      1982
     </td>
     <td>
      ARCH models
     </td>
    </tr>
    <tr>
     <td>
      1993
     </td>
     <td>
      Value at Risk (VAR)
     </td>
    </tr>
    <tr>
     <td>
      1994
     </td>
     <td>
      RiskMetrics
     </td>
    </tr>
    <tr>
     <td>
      1997
     </td>
     <td>
      CreditMetrics
     </td>
    </tr>
    <tr>
     <td>
      2000
     </td>
     <td>
      Enterprisewide risk management
     </td>
    </tr>
    <tr>
     <td>
     </td>
     <td>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <b>
    Table 1
   </b>
   The evolution of analytical risk-management tools
  </p>
  <p block-type="Text">
   whose value derives from some underlying price. Early instruments such as forwards or futures had linear exposures to risk factors. For instance, a farmer could hedge the price risk of a wheat harvest by shorting wheat futures. Because a forward or futures contract implies an obligation to buy or sell, the payoff is a linear function of movements in the underlying risk factor, which is the price of wheat in this case. A drop in this price would cause a loss in the value of the harvest, but this should be largely hedged by a gain on the futures position. Commodity contracts exist since 1874; foreign currency futures were introduced in 1972 and interest rate futures in 1975. Over time, the industry started to offer more flexible contracts such as options, which involve the right, as opposed to the obligation, to buy or sell. This right creates a payoff function that is nonlinear in the underlying asset. Such instruments are more complicated to price and hedge.
  </p>
  <p block-type="Text">
   In 1973, Black and Scholes [3] developed a breakthrough option pricing model (
   <i>
    see
   </i>
   <b>
    Black–Scholes Formula
   </b>
   ), which led to the award of the 1997 Nobel Prize in Economics, along with Merton. The model provides a particularly elegant formula for the pricing of options, based on a remarkably small set of inputs. It also generates measures of exposure, or sensitivity, which are called the
   <i>
    Greeks
   </i>
   . The timing of this discovery was fortuitous, as equity options started trading in 1973.
  </p>
  <h2>
   <b>
    The 1980s: Start of Expansion of Derivatives Markets
   </b>
  </h2>
  <p block-type="Text">
   The need for efficient risk-management tools led to rapid growth in the market for derivatives. These markets can be described in terms of their notional
  </p>
  <p>
   <b>
    Table 2
   </b>
   Global markets for derivatives: outstanding contracts ($ billion)
  </p>
  <table>
   <tbody>
    <tr>
     <th>
      Instruments, by location and type
     </th>
     <th>
      1986
     </th>
     <th>
      2007
     </th>
    </tr>
    <tr>
     <td>
      Exchange-traded instruments
     </td>
     <td>
      583
     </td>
     <td>
      80 624
     </td>
    </tr>
    <tr>
     <td>
      Interest rate
     </td>
     <td>
      516
     </td>
     <td>
      71 095
     </td>
    </tr>
    <tr>
     <td>
      Currency
     </td>
     <td>
      18
     </td>
     <td>
      9237
     </td>
    </tr>
    <tr>
     <td>
      Stock index
     </td>
     <td>
      49
     </td>
     <td>
      292
     </td>
    </tr>
    <tr>
     <td>
      OTC instruments
     </td>
     <td>
      500
     </td>
     <td>
      596 004
     </td>
    </tr>
    <tr>
     <td>
      Interest rate swaps
     </td>
     <td>
      400
     </td>
     <td>
      393 138
     </td>
    </tr>
    <tr>
     <td>
      Currency swaps
     </td>
     <td>
      100
     </td>
     <td>
      56 238
     </td>
    </tr>
    <tr>
     <td>
      Credit default swaps
     </td>
     <td>
      0
     </td>
     <td>
      57 894
     </td>
    </tr>
    <tr>
     <td>
      Equity, commodity
     </td>
     <td>
      0
     </td>
     <td>
      17 509
     </td>
    </tr>
    <tr>
     <td>
      Total
     </td>
     <td>
      1083
     </td>
     <td>
      676 628
     </td>
    </tr>
   </tbody>
  </table>
  <p block-type="Text">
   <i>
    Source
   </i>
   : ISDA and Bank for International Settlements
  </p>
  <p block-type="Text">
   outstanding amounts, because the face value represents the amount of exposure exchanged. The year 1986 was the first one for which we started having reliable market statistics. Before that, markets were smaller or even nonexistent. Table 2 shows that the derivatives markets have grown from $1 trillion to $677 trillion in 21 years from 1986 to 2007.
  </p>
  <p block-type="Text">
   The 1980s witnessed the introduction of major new instruments: currency swaps (1981), interest rate swaps (1982), Eurodollar futures (1981), equity index futures (1982), and swaptions (1985), just to name a few.
  </p>
  <p block-type="Text">
   As a result of the expansion of these markets, risk-management methods started to take hold in the financial industry. As exposures grew, financial institutions started to impose position limits for fixedincome exposures by duration buckets. Later, positions were imposed on options using the "Greeks". Banks also began to evaluate performance in terms of risk-adjusted profits. Economic capital, which is essentially a Value at Risk (VAR) measure, was assigned to business lines (
   <i>
    see
   </i>
   <b>
    Economic Capital
   </b>
   ). This led to risk-adjusted return on capital (RAROC) measures, which deflate expected profits by economic capital, thus providing a consistent view of riskadjusted profitability across businesses (
   <i>
    see
   </i>
   <b>
    Riskadjusted Return on Capital (RAROC)
   </b>
   ).
  </p>
  <p block-type="Text" class="has-continuation">
   The expansion of these markets was followed by a number of spectacular losses in the early 1990s, however. Headline cases such as Orange County (1994), Metallgesellschaft (1994), and Barings (1995) threatened to create a backlash against derivatives whose risks were apparently not fully appreciated by
  </p>
  <p block-type="Text">
   their users. In response, the industry devised more comprehensive measures of risk.
  </p>
  <h4>
   <b>
    The 1990s: Modern Risk Management
   </b>
  </h4>
  <p block-type="Text">
   Prodded by regulators, the Group of Thirty [5] endorsed VAR in 1993 as part of "best practices" for dealing with derivatives. VAR had been developed at Morgan, in response to the request of its chairman, "At the close of each business day, tell me what the market risks are across all businesses and locations." VAR summarizes the worst loss over a target horizon that will not be exceeded with a given level of confidence. For instance, at that time, Morgan's daily VAR was approximately $15 million at the 95% level of confidence. In other words, the bank should not expect to lose more than $15 million in 95 days out of 100. This single number describes the risk of the entire trading portfolio of the bank and therefore involves a large-scale aggregation of positions (
   <i>
    see
   </i>
   Jorion [6] and Figure 1 in
   <b>
    Market Risk
   </b>
   ).
  </p>
  <p block-type="Text">
   Morgan [9] then unveiled its "RiskMetrics" system in October 1994. RiskMetrics, available free on the Internet, provided a datafeed for computing VAR, as well as a detailed technical manual. The widespread availability of data immediately engaged the industry and spurred academic and practitioner research into risk management. The methodology was partly based on new models of time-variation in risk, such as the autoregressive conditional heteroskedasticity (ARCH) model, developed by Engle [4] in 1982 and for which he received the 2003 Nobel Prize in Economics.
  </p>
  <p block-type="Text">
   The basic idea behind VAR is not new, however. It can be traced back to the mean–variance framework developed by Markowitz in 1952. What is new is the integration of all market risks into a centralized common "metric", combined with the use of current positions. Consider again the two conceptual drivers of risk, exposure, and range of possible movements in the risk factors. This information should be combined into a distribution of dollar gains and losses, which can be summarized by one number, the quantile at some confidence level, or VAR. An alternative measure of risk is the conditional VAR (CVAR), which is the average of losses beyond VAR (
   <i>
    see
   </i>
   <b>
    Expected Shortfall
   </b>
   ). The same analysis can be performed for a portfolio of financial instruments exposed to multiple sources of risk.
  </p>
  <p block-type="Text">
   The new aspect of modern risk management is that risk measures are now position based. Traditionally, risk was measured from historical return information. Nowadays, however, proprietary trading portfolios turn over very quickly. As a result, returns-based risk measures give incomplete information. This is because today's risk profile may be very different from the average risk profile over a recent history.
  </p>
  <p block-type="Text">
   Position-based risk measures, however, are rather complex to build. They involve large-scale structural bottom-up models that aggregate risks from individual position data. The choice of the model reflects a trade-off between speed and accuracy. A portfolio may contain millions of positions, which cannot be modeled individually. Instead, the manager has to choose a set of risk factors that spans the risk space effectively. The risk measurement system then has to "map" all the positions on these risk factors, replacing the value of all positions by exposures. Next, these exposures are aggregated across the entire portfolio. The last step then combines the exposures with the statistical distribution of risk factors, which gives a distribution of profits and losses at the top level.
  </p>
  <p block-type="Text">
   This modern risk architecture has many more uses than for reporting a single VAR number, however. Once this system is in place, the risk manager can easily examine the effect of extreme or unusual situations. In fact, stress testing is an important complement to VAR because VAR only provides an estimate of losses under normal market conditions, that is, at a prespecified confidence level. Once a risk-management system is in place, however, stress scenarios are just hypothetical realizations of the risk factors (
   <i>
    see
   </i>
   <b>
    Stress Testing
   </b>
   ). More generally, risk manager should be keenly aware of weaknesses in their risk models.
  </p>
  <p block-type="Text">
   By now, VAR is the most widely used measure of market risk. Its use has been widely sanctioned by regulators. In 1996, for example, the Basel Committee on Banking Supervision [1] passed a new rule allowing commercial banks to compute their capital charge for market risk based on their own internal VAR measures. This methodology has spread to most financial institutions. Risk systems are also increasingly used to control risk. Position limits are now routinely based on VAR numbers and stress-test results.
  </p>
  <h4>
   <b>
    The 2000s: Extensions to Other Risks
   </b>
  </h4>
  <p block-type="Text">
   VAR methods were initially applied to market risk, which is the risk of losses due to movements in the level or volatility of market prices. Later, modern risk-management techniques were extended to credit risk and operational risk. This led to another round of fundamental developments.
  </p>
  <p block-type="Text">
   Credit risk is the risk of losses due to the fact that counterparties may be unwilling or unable to fulfill their contractual obligations. This is a major source of risk for the economy and has proved much more damaging than episodic losses due to market risk. Time and again, countries have experienced crises in their banking sector due to credit losses that required expensive recapitalizations.
  </p>
  <p block-type="Text">
   Toward the end of the 1990s, several portfolio credit risk models were developed. Examples are KMV and CreditMetrics. These models integrate the various components of credit risk, which include probability of default, exposures, and loss given default, as well as all their correlations, in large-scale models.
  </p>
  <p block-type="Text">
   The banking industry dutifully started to measure their credit risk and soon realized that they needed new financial instruments to manage their credit exposures. This led to the rapid expansion of credit default swaps (
   <i>
    see
   </i>
   <b>
    Credit Default Swaps
   </b>
   ), which were created in 1994. These instruments created a new market for the exchange of pure credit risk. The market expanded quickly because of its low transaction costs and also because it allowed short positions in credit, which was not feasible before. Buying a credit default swap creates a profit if the credit event happens. This is akin to shorting a corporate bond but much more practical. By 2007, the outstanding notional amount for credit default swaps was close to $60 trillion, several times the size of the corporate bond markets.
  </p>
  <p block-type="Text">
   Credit risk models led to fundamental changes in the banking industry. The industry soon realized that holding loans on their books immobilized large amounts of capital and was not very profitable. In response, banks moved to a model where they could reap fees from the origination of loans, which were then repackaged and distributed to other investors. This led to the creation of the structured credit industry, where pools of debt are put together and sold as securities with various levels of priority on the collateral.
  </p>
  <p block-type="Text">
   Structured credit had its roots in the collateralized mortgage obligation (CMO) market developed in the early 1980s. Mortgage loans were placed in pools and sold to investors in the form of tranches with different priority claims. The same principle applies to collateralized debt obligations (CDOs,
   <i>
    see
   </i>
   <b>
    Collateralized Debt Obligations (CDO)
   </b>
   ). By 2001, the methodology of credit risk portfolio measurement was applied to CDOs, allowing rapid pricing of the various tranches. This spurred an exponential growth of this market, until 2007.
  </p>
  <p block-type="Text">
   This growth revealed flaws, however. On the one hand, these new instruments dispersed risk to investors and financial institutions across the globe, which is a positive development. In the case of the subprime crisis of 2007, the subprime losses were considerable, amounting to several hundred billion dollars. In the past, such losses could have bankrupted the US financial system. This has not happened, fortunately. On the other hand, this securitization process led to laxer credit standards that aggravated the scale of losses. Lenders were more interested in generating fee income than about the ultimate creditworthiness of borrowers because losses would be borne by somebody else, after all.
  </p>
  <p block-type="Text">
   In addition to credit risk, risk measurement techniques are now being applied to operational risk, which is the risk of losses resulting from inadequate or failed internal processes, people, and systems or from external events (
   <i>
    see
   </i>
   <b>
    Operational Risk
   </b>
   ). Operational risk has caused large losses to financial institutions. In 1995, a single rogue trader caused a loss of $1.3 billion at Barings, which led to the failure of the bank. As a result, the Basel Committee on Banking Supervision [2] mandated a new capital charge against operational risk, which can be based on a VAR measure. Admittedly, however, operational risk measures are much less precise than those covering market and credit risk. Data on operational risk losses are scarcer than for other types of risk. In addition, losses may not be applicable to banks with different control environments.
  </p>
  <p block-type="Text">
   In the 2000s, many institutions started to develop an integrated approach to enterprisewide risk management (ERM). This is an extension of the VAR concept, whose essence is centralization, to firmwide risks. ERM consists of identification, assessment, and measurement of all relevant risks, including market, credit, operational, and business risk. In the past, risks were considered separately from each other and
  </p>
  <h3>
   <b>
    Conclusions
   </b>
  </h3>
  <p block-type="Text">
   It is fair to conclude by stating that modern riskmanagement techniques have truly revolutionized the financial industry. Institutions are now busily trying to measure and manage their aggregate risks.
  </p>
  <p block-type="Text">
   The elegance of these risk models should not create a sense of false security, however. VAR risk measures are not designed to provide worstloss estimates. We should expect losses to exceed VAR numbers with some regularity. In addition, these risk models can be sensitive to the underlying assumptions. This is why stress tests should be used on a regular basis, including scenario analyses and model tests. A good risk manager should understand the weak spots of the models, combined with an economic intuition of the fundamental driver of the risk factors. The subprime crisis that started in 2007, for example, illustrated severe shortcomings in risk models, as institutions suffered losses that were much worse than anticipated, both in terms of frequency and size. A widespread reaction was for these institutions to strengthen their risk-management structures.
  </p>
  <p block-type="Text" class="has-continuation">
   More fundamentally, quantitative risk measurement tools do not apply well to some important sources of risk, such as liquidity risk. This is the risk of loss due to the inability to meet payments obligations, which may force early liquidation of assets at fire-sale prices. Creditors may refuse to roll over their funding, creating "bank runs" such as those that befell Northern Rock and Bear Stearns. At an even broader level, no model can fully account for systemic risk, which arises when by default one institution has a cascading effect on other firms, thus posing a threat to
  </p>
  <p block-type="Text">
   the viability of the entire financial system. Systemic risk should be handled by the central bank, which is effectively becoming the risk manager of last resort.
  </p>
  <h4>
   <b>
    References
   </b>
  </h4>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     [1] Basel Committee on Banking Supervision. (1996).
     <i>
      Amendment to the Basel Capital Accord to Incorporate Market Risk
     </i>
     , BIS, Basel.
    </li>
    <li block-type="ListItem">
     [2] Basel Committee on Banking Supervision. (2005).
     <i>
      International Convergence of Capital Measurement and Capital Standards: A Revised Framework
     </i>
     , BIS, Basel.
    </li>
    <li block-type="ListItem">
     [3] Black, F. &amp; Scholes, M. (1973). The pricing of options and corporate liabilities,
     <i>
      Journal of Political Economy
     </i>
     <b>
      81
     </b>
     , 637–659.
    </li>
    <li block-type="ListItem">
     [4] Engle, R. (1982). Autoregressive conditional heteroskedasticity with estimates of the variance of United Kingdom inflation,
     <i>
      Econometrica
     </i>
     <b>
      50
     </b>
     , 987–1007.
    </li>
    <li block-type="ListItem">
     [5] Group of Thirty. (1993).
     <i>
      Derivatives: Practices and Principles
     </i>
     , Group of Thirty, New York.
    </li>
    <li block-type="ListItem">
     [6] Jorion, P. (2005).
     <i>
      Value at Risk: The New Benchmark to Manage Financial Risk
     </i>
     , McGraw-Hill, New York.
    </li>
    <li block-type="ListItem">
     [7] Macaulay, F. (1938).
     <i>
      The Movements of Interest Rates. Bond Yields and Stock Prices in the United States since 1856
     </i>
     , National Bureau of Economic Research, New York.
    </li>
    <li block-type="ListItem">
     [8] Markowitz, H. (1952). Portfolio selection,
     <i>
      Journal of Finance
     </i>
     <b>
      7
     </b>
     , 77–91.
    </li>
    <li block-type="ListItem">
     [9] Morgan, J.P. (1995).
     <i>
      RiskMetrics Technical Manual
     </i>
     , J.P. Morgan, New York.
    </li>
    <li block-type="ListItem">
     [10] Sharpe, W. (1964). Capital asset prices: a theory of market equilibrium under conditions of risk,
     <i>
      Journal of Finance
     </i>
     <b>
      19
     </b>
     , 425–442.
    </li>
   </ul>
  </p>
  <h4>
   <b>
    Related Articles
   </b>
  </h4>
  <p block-type="Text">
   <b>
    Bond
   </b>
   ;
   <b>
    Capital Asset Pricing Model
   </b>
   ;
   <b>
    Collateralized Debt Obligations (CDO)
   </b>
   ;
   <b>
    Credit Default Swaps
   </b>
   ;
   <b>
    Markowitz, Harry
   </b>
   ;
   <b>
    Operational Risk
   </b>
   ;
   <b>
    Regulatory Capital
   </b>
   ;
   <b>
    Securitization
   </b>
   ;
   <b>
    Sharpe, William F.
   </b>
   ;
   <b>
    Sharpe Ratio
   </b>
   ;
   <b>
    Spectral Measures of Risk
   </b>
   ;
   <b>
    Valueat-Risk
   </b>
   .
  </p>
  <p block-type="Text">
   PHILIPPE JORION
  </p>
 </body>
</html>
