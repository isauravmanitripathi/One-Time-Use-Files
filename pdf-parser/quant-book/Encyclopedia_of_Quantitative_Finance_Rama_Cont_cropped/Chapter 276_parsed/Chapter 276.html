<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
 </head>
 <body>
  <h1>
   <b>
    Early Exercise Options: Upper Bounds
   </b>
  </h1>
  <h4>
   <b>
    Setup and Basic Results
   </b>
  </h4>
  <p block-type="TextInlineMath">
   We work, as usual, on a filtered probability space and consider a contingent claim with
   <i>
    early exercise
   </i>
   rights, that is, the right to accelerate payment on the claim at will. Let the claim in question be characterized by an adapted, nonnegative payout process
   <math display="inline">
    U(t)
   </math>
   , payable to the option holder at a stopping time (or
   <i>
    exercise policy
   </i>
   )
   <math display="inline">
    \tau &lt; T
   </math>
   , chosen by the holder. If early exercise can take place at any time in some interval, we say that the derivative security is an American option; if exercise can only take place on a discrete set of dates, we say that it is a
   <i>
    Bermudan option
   </i>
   .
  </p>
  <p block-type="TextInlineMath">
   Let the allowed set of exercise dates larger than or equal to t be denoted
   <math display="inline">
    \mathcal{D}(t)
   </math>
   , and suppose that we are given at time 0 a particular exercise policy
   <math display="inline">
    \tau
   </math>
   taking values in
   <math display="inline">
    \mathcal{D}(0)
   </math>
   , as well as a pricing numeraire N inducing a unique martingale measure
   <math display="inline">
    Q^N
   </math>
   . Let
   <math display="inline">
    C^{\tau}(0)
   </math>
   be the time
   <math display="inline">
    0
   </math>
   value of a derivative security that pays
   <math display="inline">
    U(\tau)
   </math>
   . Under technical conditions on
   <math display="inline">
    U(t)
   </math>
   , we can write the value of the derivative security as
  </p>
  <p block-type="Equation">
   <math display="block">
    C^{\tau}(0) = \mathbf{E}^{N} \left( \frac{U(\tau)}{N(\tau)} \right) \tag{1}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    E^{N}(\cdot)
   </math>
   denotes expectation in measure
   <math display="inline">
    Q^{N}
   </math>
   and where we have assumed, with no loss of generality, that
   <math display="inline">
    N(0) = 1
   </math>
   . Let
   <math display="inline">
    T(t)
   </math>
   be the time t set of (future) stopping times taking value in
   <math display="inline">
    \mathcal{D}(t)
   </math>
   . In the absence of arbitrage, the time 0 value
   <math display="inline">
    C(0)
   </math>
   of a security with early exercise into
   <math display="inline">
    U
   </math>
   is then given by the
   <i>
    optimal
   </i>
   stopping problem
  </p>
  <p block-type="Equation">
   <math display="block">
    C(0) = \sup_{\tau \in \mathcal{T}(0)} C^{\tau}(0) = \sup_{\tau \in \mathcal{T}(0)} \mathcal{E}^{N}\left(\frac{U(\tau)}{N(\tau)}\right) \tag{2}
   </math>
  </p>
  <p block-type="Text">
   reflecting the fact that a rational investor would choose an exercise policy to optimize the value of his/her claim.
  </p>
  <p block-type="TextInlineMath">
   With
   <math display="inline">
    E_t^N(\cdot)
   </math>
   denoting expectation conditional on the information (i.e., the filtration) at time
   <math display="inline">
    t
   </math>
   , we can extend equation
   <math display="inline">
    (2)
   </math>
   to future times t
  </p>
  <p block-type="Equation">
   <math display="block">
    C(t) = N(t) \sup_{\tau \in \mathcal{I}(t)} \mathcal{E}_t^N \left(\frac{U(\tau)}{N(\tau)}\right) \tag{3}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    \sup_{\tau} \mathbf{E}_{t}^{N} \left(U(\tau)/N(\tau)\right)
   </math>
   is known as the
   <i>
    Snell
   </i>
   envelope of
   <math display="inline">
    U/N
   </math>
   under
   <math display="inline">
    O^N
   </math>
   . Here
   <math display="inline">
    C(t)
   </math>
   must be interpreted as the value of the option with early exercise,
   <i>
    conditional
   </i>
   on exercise not having taken place before time
   <i>
    t
   </i>
   . To make this explicit, let
   <math display="inline">
    \tau^*
   </math>
   ∈
   <math display="inline">
    T(0)
   </math>
   be the optimal exercise policy, as seen from time 0. We can then write, for
   <math display="inline">
    0 &lt; t \leq T
   </math>
   ,
  </p>
  <p block-type="Equation">
   <math display="block">
    C(0) = \mathbf{E}^{N} \left( \mathbf{1}_{\{\tau^* \ge t\}} C(t) / N(t) \right)
   </math>
   <br/>
   +
   <math display="block">
    \mathbf{E}^{N} \left( \mathbf{1}_{\{\tau^* &lt; t\}} U(\tau^*) / N(\tau^*) \right) \tag{4}
   </math>
  </p>
  <p block-type="Text">
   where we break the time 0 value into two components: one from the time
   <math display="inline">
    t
   </math>
   value of the option, should it not have been exercised before time
   <math display="inline">
    t
   </math>
   , and other from the right to exercise on
   <math display="inline">
    [0, t]
   </math>
   . As we can always elect —possibly suboptimally —to never exercise on
   <math display="inline">
    [0, t]
   </math>
   , from equation (4) we see that
  </p>
  <p block-type="Equation">
   <math display="block">
    C(0) \ge \mathcal{E}^N \left( C(t) / N(t) \right) \tag{5}
   </math>
  </p>
  <p block-type="TextInlineMath">
   which establishes that
   <math display="inline">
    C(t)/N(t)
   </math>
   is a
   <i>
    supermartingale
   </i>
   under
   <math display="inline">
    O^N
   </math>
   . This result also follows directly from known properties of the Snell envelope; see [13].
  </p>
  <p block-type="TextInlineMath">
   In numerical implementations, it is most relevant to consider the discrete-time (i.e., Bermudan) case and assume that
   <math display="inline">
    \mathcal{D}(0) = \{T_1, T_2, \ldots, T_B\},\
   </math>
   where
   <math display="inline">
    T_1 &gt; 0
   </math>
   and
   <math display="inline">
    T_B = T
   </math>
   . For
   <math display="inline">
    t \in (T_i, T_{i+1})
   </math>
   , define
   <math display="inline">
    H_i
   </math>
   as the time t value of the Bermudan option when exercise is restricted to the dates
   <math display="inline">
    \mathcal{D}(T_{i+1}) =
   </math>
   <math display="inline">
    \{T_{i+1}, T_{i+2}, \ldots, T_B\}
   </math>
   ; that is,
  </p>
  <p block-type="Equation">
   <math display="block">
    H_i(t) = N(t) \mathcal{E}_t^N \left( C(T_{i+1}) / N(T_{i+1}) \right),
   </math>
   <br/>
   <math display="block">
    i = 1, \dots, B - 1
   </math>
   (6)
  </p>
  <p block-type="TextInlineMath">
   At time
   <math display="inline">
    T_i
   </math>
   ,
   <math display="inline">
    H_i(T_i)
   </math>
   can be interpreted as the
   <i>
    holding
   </i>
   value of the Bermudan option, that is, the value of the Bermudan option if not exercised at time
   <math display="inline">
    T_i
   </math>
   . If an optimal exercise policy is followed, clearly we must have at time
   <math display="inline">
    T_i
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    C(T_i) = \max (U(T_i), H_i(T_i)), \quad i = 1, \dots, B
   </math>
   (7)
  </p>
  <p block-type="Text">
   such that
  </p>
  <p block-type="Equation">
   <math display="block">
    H_i(t) = N(t) \mathbf{E}_t^N \left( \max \left( U(T_{i+1}), H_{i+1}(T_{i+1}) \right) \right),
   </math>
   <br/>
   <math display="block">
    i = 1, \dots, B - 1 \tag{8}
   </math>
  </p>
  <p block-type="TextInlineMath">
   Starting with the terminal condition
   <math display="inline">
    H_B(T) = 0
   </math>
   , equation (8) defines an backward iteration in time for the value
   <math display="inline">
    C(0) = H_0(0)
   </math>
   .
  </p>
  <h2>
   <b>
    Option Pricing Bounds
   </b>
  </h2>
  <p block-type="Text">
   In a setting where
   <math display="inline">
    U(t)
   </math>
   is a function of a lowdimensional diffusion process, the iteration (8) can often be solved numerically by partial differential equations (PDE) or lattice methods, for example, the finite difference method (see Finite Difference Methods for Early Exercise Options). In many cases of practical interest, however, these methods either do not apply or are computationally infeasible. In such situations, we may be interested in at least bounding the value of an option with early exercise rights. Providing a
   <i>
    lower bound
   </i>
   is straightforward: postulate an exercise policy
   <math display="inline">
    \tau
   </math>
   and compute the price
   <math display="inline">
    C^{\tau}(0)
   </math>
   by direct methods, for example, the Monte Carlo method. From equation (2), this clearly provides a lower bound
  </p>
  <p block-type="Equation">
   <math display="block">
    C^{\tau}(0) \le C(0) \tag{9}
   </math>
  </p>
  <p block-type="Text">
   The closer the postulated exercise policy
   <math display="inline">
    \tau
   </math>
   is to the optimal exercise policy
   <math display="inline">
    \tau^*
   </math>
   , the tighter this bound will be. Two common strategies for approximation of
   <math display="inline">
    \tau^*
   </math>
   in a Monte Carlo setting are discussed in Bermudan Options and Exercise Boundary Optimization
   <b>
    Methods
   </b>
   , the first based on regression estimates of holding values
   <math display="inline">
    H
   </math>
   in equation (8) and the second on optimization of parametric rules for the exercise strategy.
  </p>
  <p block-type="TextInlineMath">
   To produce an
   <i>
    upper bound
   </i>
   , we can rely on duality results established in [9, 14]. To present these results here, let
   <math display="inline">
    \mathcal{K}
   </math>
   denote the space of adapted martingales
   <math display="inline">
    \pi
   </math>
   for which
   <math display="inline">
    \sup_{\tau \in [0,T]} \mathbb{E}^N |\pi(\tau)| &lt; \infty
   </math>
   . For a martingale
   <math display="inline">
    \pi \in \mathcal{K}
   </math>
   , we then write
  </p>
  <p block-type="Equation">
   <math display="block">
    C(0) = \sup_{\tau \in \mathcal{T}(0)} \mathcal{E}^{N} \left( \frac{U(\tau)}{N(\tau)} \right)
   </math>
   <br/>
   <math display="block">
    = \sup_{\tau \in \mathcal{T}(0)} \mathcal{E}^{N} \left( \frac{U(\tau)}{N(\tau)} + \pi(\tau) - \pi(\tau) \right)
   </math>
   <br/>
   <math display="block">
    = \pi(0) + \sup_{\tau \in \mathcal{T}(0)} \mathcal{E}^{N} \left( \frac{U(\tau)}{N(\tau)} - \pi(\tau) \right) \tag{10}
   </math>
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   In the second equality, we have relied on the
   <i>
    optional
   </i>
   sampling theorem to tell us that the martingale property is satisfied up to a bounded random stopping time, that is, that
   <math display="inline">
    E^N(\pi(\tau)) = \pi(0)
   </math>
   . See [12] for details. We now turn the above result into an upper
  </p>
  <p block-type="Text">
   bound by forming a pathwise maximum at all possible future exercise dates
   <math display="inline">
    \mathcal{D}(0)
   </math>
   :
  </p>
  <p block-type="Equation">
   <math display="block">
    C(0) = \pi(0) + \sup_{\tau \in \mathcal{T}(0)} \mathbf{E}^{N} \left( \frac{U(\tau)}{N(\tau)} - \pi(\tau) \right)
   </math>
   <br/>
   <math display="block">
    \leq \pi(0) + \mathbf{E}^{N} \left( \max_{t \in \mathcal{D}(0)} \left( \frac{U(t)}{N(t)} - \pi(t) \right) \right) \tag{11}
   </math>
  </p>
  <p block-type="TextInlineMath">
   With equations
   <math display="inline">
    (9)
   </math>
   and
   <math display="inline">
    (11)
   </math>
   we have, as desired, established upper and lower bounds for values of options with early exercise rights. Let us consider how to make these bounds tight. As mentioned earlier, to tighten the lower bound we need to pick exercise strategies close to the optimal one. Tightening the upper bound is a bit more involved and requires usage of the Doob-Meyer decomposition (see
   <b>
    Doob–Meyer Decomposition
   </b>
   ), which can be used here to show that
  </p>
  <p block-type="Equation">
   <math display="block">
    C(t)/N(t) = M(t) - A(t) \tag{12}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    M(t)
   </math>
   is a martingale and
   <math display="inline">
    A(0)
   </math>
   an increasing, predictable process with
   <math display="inline">
    A(0) = 0
   </math>
   (such that
   <math display="inline">
    C(0) =
   </math>
   <math display="inline">
    M(0)
   </math>
   ). Given equation (12), consider taking
   <math display="inline">
    \pi(t)
   </math>
   =
   <math display="inline">
    M(t)
   </math>
   in equation (11), to get
  </p>
  <p block-type="Equation">
   <math display="block">
    C(0) \leq C(0) + \mathcal{E}^{N} \left( \max_{t \in \mathcal{D}(0)} \frac{U(t)}{N(t)} - M(t) \right)
   </math>
   <br/>
   =
   <math>
    C(0) + \mathcal{E}^{N} \left( \max_{t \in \mathcal{D}(0)} \frac{U(t)}{N(t)} - \frac{C(t)}{N(t)} - A(t) \right)
   </math>
   <br/>
   $\leq C(0). \qquad (13)$
  </p>
  <p block-type="TextInlineMath">
   The last inequality follows from the fact that
   <math display="inline">
    C(t)
   </math>
   &gt;
   <math display="inline">
    U(t)
   </math>
   and
   <math display="inline">
    A(t) &gt; 0
   </math>
   . As
   <math display="inline">
    M(0) = C(0)
   </math>
   , it follows that the quantity
  </p>
  <p block-type="Equation">
   <math display="block">
    M(0) + \mathbf{E}^N \left( \max_{t \in \mathcal{D}(0)} \frac{U(t)}{N(t)} - M(t) \right),
   </math>
   <br/>
   <math display="block">
    M(t) = \frac{C(t)}{N(t)} + A(t) \tag{14}
   </math>
  </p>
  <p block-type="TextInlineMath">
   is bounded by
   <math display="inline">
    C(0)
   </math>
   from both above and below, that is, it must equal
   <math display="inline">
    C(0)
   </math>
   . We have thereby arrived at a
   <i>
    dual
   </i>
   formulation of the option price
  </p>
  <p block-type="Equation">
   <math display="block">
    C(0) = \inf_{\pi \in \mathcal{K}} \left( \pi(0) + \mathbf{E}^N \left( \max_{t \in \mathcal{D}(0)} \frac{U(t)}{N(t)} - \pi(t) \right) \right)
   </math>
   (15)
  </p>
  <p block-type="TextInlineMath">
   and have demonstrated that the infimum is attained when the martingale
   <math display="inline">
    \pi
   </math>
   is set equal to the martingale component
   <math display="inline">
    M
   </math>
   of the deflated price process
   <math display="inline">
    C(t)/N(t)
   </math>
   .
  </p>
  <h2>
   <b>
    Monte Carlo Upper Bound Methods
   </b>
  </h2>
  <p block-type="Text">
   Let us consider how we can use the upper bound results
   <math display="inline">
    (11)
   </math>
   and
   <math display="inline">
    (15)
   </math>
   in an actual Monte Carlo application. According to equation (11), to generate an upper bound for the true option price, it evidently suffices to simply pick
   <i>
    any
   </i>
   martingale process adapted to the filtration we work in, and then compute the expectation (11) by Monte Carlo methods. For instance, if the filtration is generated by a vectorvalued Brownian motion
   <math display="inline">
    W(t)
   </math>
   , we can always set
  </p>
  <p block-type="Equation">
   <math display="block">
    \pi(t) = \int_0^t \sigma(t)^\top \, \mathrm{d}W(t) \tag{16}
   </math>
  </p>
  <p block-type="TextInlineMath">
   for some adapted vector-process
   <math display="inline">
    \sigma(t)
   </math>
   satisfying the usual conditions required for the stochastic integral to be a proper martingale. Clearly, however, if
   <math display="inline">
    \sigma(t)
   </math>
   is chosen arbitrarily, the resulting upper bound is likely to be very loose, and probably not very useful. While equation (15) is of little immediate practical use (since we do not know the process
   <math display="inline">
    C(t)/N(t)
   </math>
   ), it does suggest that for a chosen martingale
   <math display="inline">
    \pi(t)
   </math>
   in equation
   <math display="inline">
    (11)
   </math>
   to produce a tight upper bound, it needs to be "close" to
   <math display="inline">
    M(t)
   </math>
   .
  </p>
  <p block-type="Text">
   Several strategies have been proposed for constructing a good martingale
   <math display="inline">
    \pi(t)
   </math>
   . When working on a simple model set up on simple payouts, sometimes one can make inspired guesses for what
   <math display="inline">
    \pi(t)
   </math>
   should be. For instance, in a one-dimensional Black-Scholes model, Rogers [14] shows that using the numerairedeflated European put option price (which is analytically known) as a guess for
   <math display="inline">
    \pi(t)
   </math>
   generates good bounds for a Bermudan put option price. This approach, however, does not easily generalize to settings with more complicated dynamics and/or more complicated exercise payouts.
  </p>
  <h4>
   The Andersen-Broadie Algorithm
  </h4>
  <p block-type="Text" class="has-continuation">
   A general strategy for generating upper bounds is proposed in [1], which can start from any approximation to the optimal exercise strategy, perhaps
  </p>
  <p block-type="Text">
   generated from either of the methods in Bermudan Options or Exercise Boundary Optimization Methods. Using a straightforward "simulationwithin-a-simulation" approach, the authors construct an estimate to the value process
   <math display="inline">
    C^{\tau}(t)
   </math>
   and use its estimated martingale component as
   <math display="inline">
    \pi(t)
   </math>
   in equation (11). Specifically, working on a discrete timeline, they set
  </p>
  <p block-type="Equation">
   <math display="block">
    \pi(T_{i+1}) - \pi(T_i) = \frac{C^{\tau}(T_{i+1})}{N(T_{i+1})} - \mathcal{E}_{T_i}^N \left(\frac{C^{\tau}(T_{i+1})}{N(T_{i+1})}\right)
   </math>
   <math display="block">
    = \mathcal{E}_{T_{i+1}}^N \left(\frac{U(\tau)}{N(\tau)}\right) - \mathcal{E}_{T_i}^N \left(\frac{U(\tau)}{N(\tau)} | \tau \ge T_{i+1}\right) \tag{17}
   </math>
  </p>
  <p block-type="Text">
   where nested simulations are used to estimate both expectations on the right-hand side of the equation.&lt;sup&gt;a&lt;/sup&gt; The resulting Monte Carlo estimate of the upper bound is shown to be biased high always, with the bias being a decreasing function in the number of inner simulation trials. As suggested by equation
   <math display="inline">
    (15)
   </math>
   , the upper bound produced by the algorithm in
   <math display="inline">
    [1]
   </math>
   strongly depends on the quality of the exercise strategy: the better the strategy, the tighter the bound.
  </p>
  <p block-type="Text">
   The need for nested simulations makes the algorithm in [1] expensive: if
   <math display="inline">
    M
   </math>
   is the number of outer simulations and
   <math display="inline">
    K
   </math>
   the number of inner simulations. an option with
   <math display="inline">
    B
   </math>
   exercise opportunities will involve a worst case workload proportional to
  </p>
  <p block-type="Equation">
   <math display="block">
    M \cdot K \cdot B^2 \tag{18}
   </math>
  </p>
  <p block-type="Text">
   For comparison, a lower bound simulation has a workload proportional to
   <math display="inline">
    M \cdot B
   </math>
   , plus whatever work is required to estimate the exercise rule in a presimulation. In many cases the inner simulations can be stopped quickly (due to early exercise); thus, in practice the dependence on
   <math display="inline">
    B
   </math>
   in equation (18) is often less than quadratic and sometimes close to linear. In addition, in [3] it is shown—along with other ideas for efficiency improvements—that inner simulations are not needed on dates where it is suboptimal to exercise the option, which can lead to considerable time savings, especially for out-of-the-money options. Finally,
   <math display="inline">
    K
   </math>
   can often be set to a number much smaller than
   <math display="inline">
    M
   </math>
   without significantly affecting the quality of the upper bound, and even very small values of
   <math display="inline">
    K
   </math>
   (e.g.,
   <math display="inline">
    50-100
   </math>
   or less) may yield informative results. With the computational improvements suggested in [3], upper bound computations on a range of different option payouts take on the order of
   <math display="inline">
    1-10
   </math>
   CPU minutes compared with
   <math display="inline">
    0.1-2
   </math>
   CPU minutes for the lower
  </p>
  <p block-type="Text">
   bound. Of course, the CPU times depend on the speed of the processor, but it is safe to say that relatively tight confidence intervals for most option types can be obtained in times measured in minutes, not in hours as is commonly believed.
  </p>
  <p block-type="Text">
   The strategy in
   <math display="inline">
    [1]
   </math>
   is generic, in that it can handle virtually any type of multidimensional process dynamics and security payouts. Despite the computational drawbacks, the use of nested simulation guarantees that the choice of
   <math display="inline">
    \pi
   </math>
   induces an upper bound estimate that is biased high. Importantly, this key property is
   <i>
    not
   </i>
   shared by many alternative estimators, such as regression, of the expectations in equation
   <math display="inline">
    (17)
   </math>
   . One exception is discussed in [8] where a special martingale-preserving regression approach is introduced. This algorithm, however, requires strong conditions on regression basis functions that may be hard to check in practice.
  </p>
  <h4>
   The Belomestny–Bender–Schoenmakers Algorithm
  </h4>
  <p block-type="TextInlineMath" class="has-continuation">
   In the special case where dynamics are driven only by Brownian motions, the usual martingale representation theorems show that the optimal strategy
   <math display="inline">
    \pi^*(t)
   </math>
   must be an Ito integral, that is, of the form in equation (16). Starting again from a postulated exercise strategy, Belomestny
   <i>
    et al.
   </i>
   <math display="inline">
    [2]
   </math>
   use this observation to construct a regression on a set of basis functions to uncover an estimate for the function
   <math display="inline">
    \sigma(t)
   </math>
   . By applying regression techniques this way—rather than to directly compute expectations of
   <math display="inline">
    U(\tau)/N(\tau)
   </math>
   —the authors are able to construct a true martingale process
   <math display="inline">
    \pi(t)
   </math>
   , which can be turned into a valid upper bound through equation (11). The resulting nonnested simulation algorithm requires careful implementation to yield stable results, in part, because the optimal integrand
   <math display="inline">
    \sigma(t)
   </math>
   can be expected to be considerably less regular than
   <math display="inline">
    \pi^*(t)
   </math>
   itself; this, in turn, requires additional thought in the selection of appropriate basis functions for the regression. One possibility advocated in [2] is to include, whenever available, exact or approximate expressions for the diffusion term in dynamics of several still-alive European options underlying the Bermudan option. This strategy is akin to that of
   <math display="inline">
    [14]
   </math>
   , and its feasibility depends on the pricing problem at hand. In cases where it does apply, the authors of [2] demonstrate that their method gives good results, with the upper bound often being nearly as tight as that of the nested algorithm in [1]. They
  </p>
  <p block-type="Text">
   also show how to use their technique to develop a variance-reduced version of the algorithm in [1].
  </p>
  <h4>
   <b>
    Confidence Intervals and Practical Usage
   </b>
  </h4>
  <p block-type="TextInlineMath">
   Assume that we have estimated an exercise strategy using either of the approaches in Bermudan Options or Exercise Boundary Optimization Methods. Suppose that the Monte Carlo estimate for the lower bound price is
   <math display="inline">
    \hat{C}_{lo}(0)
   </math>
   with a sample standard deviation of
   <math display="inline">
    \hat{s}_{lo}
   </math>
   based on
   <math display="inline">
    M_{lo}
   </math>
   Monte Carlo trials. Using, say, the algorithm in [1], we also estimate an upper bound
   <math display="inline">
    \hat{C}_{hi}(0)
   </math>
   with a sample standard deviation
   <math display="inline">
    \hat{s}_{hi}
   </math>
   computed from
   <math display="inline">
    M_{hi}
   </math>
   (outer) simulation trials. With
   <math display="inline">
    z_x
   </math>
   denoting the xth percentile of a standard Gaussian distribution, asymptotically a
   <math display="inline">
    100(1 - \alpha)\%
   </math>
   confidence interval for the true price
   <math display="inline">
    C(0)
   </math>
   must be
   <math display="inline">
    \text{tighter}^{\text{b}}
   </math>
   than
  </p>
  <p block-type="Equation">
   <math display="block">
    \left[\hat{C}_{lo}(0) - z_{1-\alpha/2} \frac{\hat{s}_{lo}}{\sqrt{M_{lo}}}; \hat{C}_{hi}(0) - z_{1-\alpha/2} \frac{\hat{s}_{hi}}{\sqrt{M_{hi}}}\right] \tag{19}
   </math>
  </p>
  <p block-type="TextInlineMath">
   Most often, upper bound simulation algorithms can be expected to be both more involved and/or more expensive than lower bound simulation methods. In many cases, the role of the upper bound simulation algorithm will therefore be to test whether postulated lower bound exercise strategies are tight or not. Specifically, starting from some guess for the exercise strategy, we can produce confidence intervals using equation (19) to test whether the lower bound estimate is of good quality, in which case the confidence interval can be made tight by using large values of
   <math display="inline">
    M_{lo}
   </math>
   and
   <math display="inline">
    M_{hi}
   </math>
   (as well as the number of inner simulation trials). In case the lower bound estimator is deemed unsatisfactory, we can iteratively refine it, by altering the choice of basis functions, say, until the confidence interval is tight. Importantly, such tests can often be done at a high level, covering entire classes of payouts and/or models. Once an exercise strategy has been validated for a particular product or model, day-to-day pricing of Bermudan securities can be done by the lower bound method, with only occasional runs of the upper bound method needed (e.g., if market conditions change markedly). If upper bound methods are predominantly used in this manner, the fact that they may sometimes be computationally intensive&lt;sup&gt;c&lt;/sup&gt; becomes less punitive.
  </p>
  <h4>
   <b>
    Extensions and Related Work
   </b>
  </h4>
  <p block-type="Text">
   The results
   <math display="inline">
    (11)
   </math>
   and
   <math display="inline">
    (15)
   </math>
   are sometimes known as additive duality results. Jamshidian [10] has introduced alternative
   <i>
    multiplicative
   </i>
   results. A comparative study of additive and multiplicative duality was undertaken in [7], with the authors concluding that the additive duality results are preferable in applications.
  </p>
  <p block-type="Text">
   Earlier methods for producing lower and upper bounds were proposed in [5, 6]. Both methods [5, 6] have the significant feature of producing automatically convergent bounds. However, [5] is only practical when the number of exercise dates is a small finite number (e.g., less than five). The method proposed in [6] does not suffer this drawback, but is more challenging to implement and is substantially slower than most lower bounds methods.
  </p>
  <p block-type="Text">
   Finally, let us note that computation of upper bounds by Monte Carlo simulation theoretically extends to option sensitivities (Greeks), as demonstrated in [11] where duality is applied to the likelihood ratio method (see [4]). As the proposed algorithm is very computationally intensive, the practical value of this result remains to be seen.
  </p>
  <h4>
   <b>
    End Notes
   </b>
  </h4>
  <p block-type="Text">
   &lt;sup&gt;a&lt;/sup&gt; In cases where
   <math display="inline">
    U(t)
   </math>
   is not known in closed form as may be the case for complicated callable securities (see Bermudan Swaptions and Callable Libor Exotics)nested simulation can also be used to establish estimates for
   <math display="inline">
    U(t)
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   &lt;sup&gt;b&lt;/sup&gt;. The confidence interval is conservative because of the low bias in
   <math display="inline">
    \hat{C}_{l_0}(0)
   </math>
   (i.e.,
   <math display="inline">
    E^N(\hat{C}_{l_0}) \leq C(0)
   </math>
   ) and the high bias in
   <math display="inline">
    \hat{C}_{hi}(0)
   </math>
   which originates in part from the nature of the upper bound, and in part from the earlier mentioned additional high bias introduced by the inner simulations.
  </p>
  <p block-type="Text">
   &lt;sup&gt;c&lt;/sup&gt;.Note, though, that in testing the viability of a class of exercise rules through an upper bound simulation, it is often acceptable to work with a reduced set of exercise opportunities—for example change a quarterly exercise schedule to an annual one—in order to save computation time (see equation
   <math display="inline">
    (18)
   </math>
   ).
  </p>
  <h2>
   References
  </h2>
  <p block-type="Text">
   [1] Andersen, L. &amp; Broadie, M. (2004). A primal-dual simulation algorithm for pricing multi-dimensional American options,
   <i>
    Management Science
   </i>
   <b>
    50
   </b>
   , 1222–1234.
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     Belomestny, D., Bender, C. &amp; Schoenmakers, J. (2009). [2] True upper bounds for Bermudan products via nonnested Monte Carlo, Mathematical Finance, 19(1), 53-71.
    </li>
    <li block-type="ListItem">
     [3] Broadie, M. &amp; Cao, M. (2008). Improved lower and upper bound algorithms for pricing American options by simulation,
     <i>
      Quantitative Finance
     </i>
     <b>
      8
     </b>
     , 845-861.
    </li>
    <li block-type="ListItem">
     [4] Broadie, M. &amp; Glasserman, P. (1996). Estimating security price derivatives using simulation, Management Science 42, 269-285.
    </li>
    <li block-type="ListItem">
     [5] Broadie, M. &amp; Glasserman, P. (1997). Pricing American-style securities using simulation, Journal of Economic Dynamics and Control 21, 1323-1352.
    </li>
    <li block-type="ListItem">
     [6] Broadie, M. &amp; Glasserman, P. (2004). A stochastic mesh method for pricing high-dimensional American options,
     <i>
      Journal of Computational Finance
     </i>
     <b>
      7
     </b>
     , 35–72.
    </li>
    <li block-type="ListItem">
     [7] Chen, N. &amp; Glasserman, P. (2007). Additive and multiplicative duals for American option pricing, Finance and Stochastics 11, 153-179.
    </li>
    <li block-type="ListItem">
     [8] Glasserman, P. &amp; Yu, B. (2005). Pricing American options by simulation: regression now or regression later? in Monte Carlo and Quasi-Monte Carlo Methods, H. Niederreiter, ed, Springer Verlag.
    </li>
    <li block-type="ListItem">
     Haugh, M. &amp; Kogan, L. (2004). Pricing American [9] options: a duality approach, Operations Research 52,
     <math display="inline">
      258 - 270.
     </math>
    </li>
    <li block-type="ListItem">
     [10] Jamshidian, F. (2006). The duality of optimal exercise and domineering claims: a Doob-Meyer decomposition approach to the Snell envelope, Stochastics: an International Journal of Probability and Stochastics Processes 79. 27-60.
    </li>
    <li block-type="ListItem">
     [11] Kaniel, R., Tompaidis, S. &amp; Zemlianov, A. (2008). Efficient computation of hedging parameters for discretely exercisable options, Operations Research 56, 811-826.
    </li>
    <li block-type="ListItem">
     [12] Karatzas, I. &amp; Shreve, S. (1991). Brownian Motion and Stochastic Calculus, 2nd Edition, Springer Verlag.
    </li>
    <li block-type="ListItem">
     [13] Lamberton, D. &amp; Lapeyre, B. (2007). Introduction to Stochastic Calculus Applied to Finance, 2nd Edition, CRC Press.
    </li>
    <li block-type="ListItem">
     <math display="inline">
      [14]
     </math>
     Rogers, L.C.G. (2001). Monte Carlo valuation of American options,
     <i>
      Mathematical Finance
     </i>
     <b>
      12
     </b>
     , 271–286.
    </li>
   </ul>
  </p>
  <h1>
   <b>
    Related Articles
   </b>
  </h1>
  <p block-type="Text">
   American Options; Bermudan Options; Bermudan Swaptions and Callable Libor Exotics; Doob-Meyer Decomposition; Exercise Boundary
   <b>
    Optimization Methods; Finite Difference Methods
   </b>
   for Early Exercise Options.
  </p>
  <p block-type="Text">
   LEIF B.G. ANDERSEN &amp; MARK BROADIE
  </p>
 </body>
</html>
