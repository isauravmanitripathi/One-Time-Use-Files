<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
 </head>
 <body>
  <h1>
   <b>
    Multigrid Methods
   </b>
  </h1>
  <h2>
   <b>
    Multigrid Basics
   </b>
  </h2>
  <p block-type="Text">
   The multigrid iterative solution method has the unique potential of solving partial differential equations (PDEs) discretized with
   <math display="inline">
    N^d
   </math>
   unknowns in
   <math display="inline">
    \mathcal{O}(N^d)
   </math>
   work. This property forms the basis for efficiently solving very large computational problems. Initiated by Brandt [2], the development of multigrid has been particularly stimulated by the work done in computational fluid dynamics toward the end of the twentieth century. Introductions to multigrid can be found in [4, 15].
  </p>
  <p block-type="Text">
   The insights and algorithms developed can be directly transferred to finance, that is, for solving the higher dimensional versions of convection-diffusionreaction type PDE operators efficiently. These higher dimensional PDEs arise, for example, when dealing with stochastic volatility or with multiasset options under Black-Scholes dynamics. The aim is to solve these discrete PDE problems in just a few multigrid iterations within a split second.
  </p>
  <h3>
   Linear Multigrid
  </h3>
  <p block-type="Text">
   We would like to solve iteratively the discrete problem resulting from a PDE,
  </p>
  <p block-type="Equation">
   <math display="block">
    A_h u_h = f_h, \text{ on grid } G_h \tag{1}
   </math>
  </p>
  <p block-type="TextInlineMath">
   for unknown
   <math display="inline">
    u_h
   </math>
   . For any approximation
   <math display="inline">
    u_h^m
   </math>
   , after iteration
   <math display="inline">
    m
   </math>
   , of the solution
   <math display="inline">
    u_h
   </math>
   , we denote the error by
   <math display="inline">
    e_h^m := u_h - u_h^m
   </math>
   , and the defect (or residual) by
   <math display="inline">
    d_h^m := f_h - A_h u_h^m
   </math>
   . Multigrid methods are motivated by the fact that many iterative methods, such as the well-known pointwise Gauss-Seidel iteration (PGS), have a smoothing effect on
   <math display="inline">
    e_h^m
   </math>
   . A smooth error can be well represented on a coarser grid, containing substantially fewer points, where its approximation is much cheaper. The defect equation,
  </p>
  <p block-type="Equation">
   <math display="block">
    A_h e_h^m = d_h^m \tag{2}
   </math>
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   represents the error; it is equivalent to the original equation, since
   <math display="inline">
    u_h = u_h^m + e_h^m
   </math>
   . Departing from the insight of a smooth error,
   <math display="inline">
    e_h^m
   </math>
   , the idea is to use an
  </p>
  <p block-type="Text">
   appropriate approximation,
   <math display="inline">
    A_H
   </math>
   , of
   <math display="inline">
    A_h
   </math>
   on a coarser
   <i>
    grid
   </i>
   ,
   <math display="inline">
    G_H
   </math>
   (for instance, a grid with double the mesh size in each direction). The defect equation is then replaced by
  </p>
  <p block-type="Equation">
   <math display="block">
    A_H \widehat{e}_H^m = d_H^m \tag{3}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    A_H: G_H \to G_H
   </math>
   , dim
   <math display="inline">
    G_H &lt; \dim G_h
   </math>
   and
   <math display="inline">
    A_H
   </math>
   is invertible. As
   <math display="inline">
    d_H^m
   </math>
   and
   <math display="inline">
    \widehat{e}_H^m
   </math>
   are grid functions on the coarser grid,
   <math display="inline">
    G_H
   </math>
   , we need two transfer operators between the fine and coarse grid.
   <math display="inline">
    I_h^H
   </math>
   is used to restrict
   <math display="inline">
    d_h^m
   </math>
   to
   <math display="inline">
    G_H
   </math>
   , and
   <math display="inline">
    I_H^h
   </math>
   is used to interpolate (or prolongate) the correction,
   <math display="inline">
    \widehat{e}_{H}^{m}
   </math>
   , back to
   <math display="inline">
    G_{h}
   </math>
   :
  </p>
  <p block-type="Equation">
   <math display="block">
    d_H^m := I_h^H d_h^m, \ \widehat{e}_h^m := I_H^h \widehat{e}_H^m \tag{4}
   </math>
  </p>
  <p block-type="Text">
   This defines an iterative two-grid solution method, the two-grid correction scheme:
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     1.
     <math display="inline">
      v_1
     </math>
     smoothing steps on the fine grid:
     <math display="inline">
      \widehat{u}_h \Longleftarrow S^{\nu_1}(u_h^0, f_h);
     </math>
    </li>
    <li block-type="ListItem">
     2. computation of fine-grid residuals:
     <math display="inline">
      d_h := f_h - A_h \widehat{u}_h;
     </math>
    </li>
    <li block-type="ListItem">
     3. restriction of residuals from fine to coarse:
     <math display="inline">
      d_H := I_h^H d_h;
     </math>
    </li>
    <li block-type="ListItem">
     4. solution of coarse-grid problem:
     <math display="inline">
      A_H \widehat{e}_H = d_H
     </math>
     ;
    </li>
    <li block-type="ListItem">
     5. prolongation of corrections from coarse to fine:
     <math display="inline">
      \widehat{e}_h := I^h_H \widehat{e}_H;
     </math>
    </li>
    <li block-type="ListItem">
     6. add correction to fine-grid approximation:
     <math display="inline">
      \widehat{u}_h \Longleftarrow \widehat{u}_h + e_h;
     </math>
    </li>
    <li block-type="ListItem">
     7.
     <math display="inline">
      \nu_2
     </math>
     smoothing steps on the fine grid:&lt;br&gt;
     <math display="inline">
      u_h^1 \longleftarrow S^{\nu_2}(\widehat{u}_h, f_h).
     </math>
    </li>
   </ul>
  </p>
  <p block-type="TextInlineMath">
   Steps
   <math display="inline">
    (1)
   </math>
   and
   <math display="inline">
    (7)
   </math>
   are pre and postsmoothing steps, consisting of a few Gauss-Seidel iterations. Steps
   <math display="inline">
    (2)-(6)
   </math>
   form the "coarse-grid correction cycle". In a well-converging two-grid method, it is not necessary to solve this coarse-grid defect equation exactly. Instead, one can replace
   <math display="inline">
    \widehat{e}_{H}^{m}
   </math>
   by a suitable approximation. A natural way is to apply the two-grid idea again to the coarse-grid equation, now employing an even coarser grid than
   <math display="inline">
    G_H
   </math>
   . This can be done recursively; on each grid
   <math display="inline">
    \gamma
   </math>
   two-grid iteration steps are applied. With
   <math display="inline">
    \gamma = 1
   </math>
   , the multigrid V-cycle is obtained.
  </p>
  <p block-type="Text" class="has-continuation">
   The smoothness of the error after Gauss-Seidel iterations depends on the discrete PDE under consideration. For nicely elliptic operators such as the Laplacian, errors will become smooth in all grid directions and grid coarsening can take place along every direction. For the convection-diffusion type equations, we obtain similar smooth errors if we
  </p>
  <p block-type="Text">
   process the grid points according to the directions governed by the convective term [15]. The choice of coarse grid highly depends on the smoothness of the error in the approximation. We coarsen in those directions in which this error is smooth. Coarsening is simple for structured Cartesian grids, where one can remove every second grid point to obtain the coarse grid. For irregular grids, the resulting matrix
   <math display="inline">
    A_h
   </math>
   assists in determining the smoothness of the error. The matrix can accordingly be reduced algebraically (algebraic multigrid, AMG, see, e.g., [15]). In geometric multigrid, coarse grids are defined on the basis of a given fine grid, and coarse-grid corrections are computed from the PDE discretized on the coarse grids.
  </p>
  <p block-type="TextInlineMath">
   If
   <math display="inline">
    N^d
   </math>
   is the number of unknowns on
   <math display="inline">
    G_h
   </math>
   and
   <math display="inline">
    N^d/\beta
   </math>
   is the number of nodes on the coarse grid, then the multigrid algorithm requires
   <math display="inline">
    \mathcal{O}(N^d)
   </math>
   storage and, for accuracy commensurable with discretization accuracy,
   <math display="inline">
    \mathcal{O}(N^d \log N^d)
   </math>
   work, if
   <math display="inline">
    \gamma &lt; \beta
   </math>
   . To get
   <math display="inline">
    \mathcal{O}(N^d)
   </math>
   work, the multigrid cycles must be preceded by nested iteration, also called full multigrid [4, 15].
  </p>
  <h1>
   <b>
    Multiasset Options; Dealing with Grid
   </b>
   Anisotropies in Multigrid
  </h1>
  <p block-type="Text">
   In this section, we discuss the numerical treatment with multigrid for the multiasset Black-Scholes operator. Because this operator can be transformed to the multidimensional heat equation [11], we focus the discussion on the Laplacian operator for simplicity.
  </p>
  <p block-type="Text">
   The major hindrance in the numerical solution of multidimensional PDEs is the so-called
   <i>
    curse of
   </i>
   dimensionality, which implies that with growth in the number of dimensions, we have an exponential growth in the number of grid points on tensor-product grids. Although we do not address this issue, in particular, we would like to stress that a way to handle dimensionality is the sparse-grid method [5, 14, 18]. One of the characteristics of these sparse grids is that they are essentially
   <i>
    nonequidistant
   </i>
   and, therefore, efficient multigrid solution methods for this type of grid are quite important.
  </p>
  <p block-type="TextInlineMath">
   We therefore consider here the discrete 2D Laplacian, discretized by finite differences on a grid with
   <math display="inline">
    h_{y} \gg h_{x}
   </math>
   , meaning that the matrix elements related to the x-derivative,
   <math display="inline">
    O(h_x^{-2})
   </math>
   , are significantly larger than those for the y-derivative,
   <math display="inline">
    O(h_{\nu}^{-2})
   </math>
   . If we apply
  </p>
  <p block-type="Text">
   a PGS to this discrete operator, we find that its smoothing effect is very poor in the y-direction. The reason is that PGS has a smoothing effect only with respect to the "strong coupling" in the operator, in this case the
   <math display="inline">
    x
   </math>
   -direction. A multigrid method based on pointwise smoothing and grid coarsening in all directions will not converge well, as we coarsen along directions in which the error is nonsmooth.
  </p>
  <p block-type="Text">
   An algorithmic improvement is to keep the pointwise relaxation for smoothing, but to
   <i>
    change the grid coarsening
   </i>
   according to the one-dimensional smoothness of errors: the coarse grid defined by doubling the mesh size only in that direction in which the errors are smooth will result in an efficient multigrid method. Figure 1 shows an example of semicoarsening along the
   <math display="inline">
    x
   </math>
   -axis.
  </p>
  <p block-type="Text">
   A second successful approach is to keep the grid coarsening in all directions, but to change the smoothing procedure from a pointwise to linewise iteration. Line relaxations are block iterations in which each block of unknowns corresponds to a line. This smoother generates smooth error in all grid directions in the case of grid anisotropies.
  </p>
  <p block-type="Text">
   These two strategies for excellent convergence, that is, to maintain standard coarsening and change the smoother, or to keep the pointwise smoothing procedure but adapt the coarsening, remain valid for higher dimensional problems. In a 3D problem, this implies that
   <i>
    planewise relaxation
   </i>
   should be employed (in combination with standard coarsening), in which all unknowns lying in the plane of strongly coupled unknowns are relaxed simultaneously. In contrast to line relaxation, which leads to tridiagonal matrices, in plane relaxation we need to solve a discrete 2D problem. A multigrid treatment of high-dimensional PDEs in finance based on hyperplane relaxation has been proposed in [13], while the use of pointwise
  </p>
  <p>
   <img src="_page_1_Figure_11.jpeg"/>
  </p>
  <p>
   <b>
    Figure 1
   </b>
   An example of
   <math display="inline">
    x
   </math>
   -semicoarsening using three grids
  </p>
  <p block-type="Text">
   smoothing and coarsening the grid simultaneously along all dimensions where the errors are strongly coupled by
   <i>
    simultaneous partial grid coarsening
   </i>
   has been employed in [18, 19], until the coarse-grid problem is isotropic to the point where full coarsening is feasible. The resulting multigrid methods are highly efficient.
  </p>
  <h1>
   American Options; Multigrid Treatment of
   <b>
    Nonlinear Problems
   </b>
  </h1>
  <p block-type="Text">
   Next, we discuss multigrid methods for the computation of the value of an American-style option. In [17], it was shown that for American-style options the theory related to free boundary problems, as it was developed in the
   <math display="inline">
    1970s
   </math>
   [1, 8], applies. It is possible to rewrite the arising free boundary problem as a linear complementarity problem (LCP), of the form
  </p>
  <p block-type="Equation">
   <math display="block">
    Au \le f_1 \quad \mathbf{x} \in \Omega \tag{5}
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    u \ge f_2 \quad \mathbf{x} \in \Omega \tag{6}
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    (u - f_2)(Au - f_1) = 0 \quad \mathbf{x} \in \Omega \tag{7}
   </math>
  </p>
  <p block-type="Text">
   The LCP formulation is beneficial for iterative solution, since the unknown boundary does not appear explicitly and can be obtained in a postprocessing step. The LCP problem is, however, nonlinear, which implies that we have to generalize the linear multigrid algorithm to the nonlinear situation. We can distinguish in solutions of LCPs a so-called active region from an inactive region. In the active region, constraint (6) holds with equality sign, whereas in the inactive region, constraint (5) is valid with equality sign.
  </p>
  <h4>
   Nonlinear Multigrid
  </h4>
  <p block-type="Text">
   The fundamental idea of multigrid for nonlinear
   <math display="inline">
    PDEs
   </math>
   of the form
  </p>
  <p block-type="Equation">
   <math display="block">
    N_h u_h = f_h \tag{8}
   </math>
  </p>
  <p block-type="Text">
   is the same as that for linear equations. First, the errors in the solution have to be smoothed so that they can be approximated on a coarser grid. In the nonlinear case, the fine-grid defect equation is given by
  </p>
  <p block-type="Equation">
   <math display="block">
    N_h \Big(\overline{u}_h^m + e_h^m\Big) - N_h \overline{u}_h^m = d_h^m \tag{9}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    \overline{u}_h^m
   </math>
   is the approximation of the solution after relaxation in the
   <i>
    i
   </i>
   th multigrid cycle,
   <math display="inline">
    e_h^m
   </math>
   is the error and
   <math display="inline">
    d_h^m
   </math>
   is the corresponding defect. This equation is approximated on a coarse grid by
  </p>
  <p block-type="Equation">
   <math display="block">
    N_H \Big(\overline{u}_H^m + \widehat{e}_H^m\Big) - N_H \overline{u}_H^m = d_H^m \qquad (10)
   </math>
  </p>
  <p block-type="TextInlineMath">
   Not only is the defect,
   <math display="inline">
    d_h^m
   </math>
   , transferred to the coarse grid by some restriction operator
   <math display="inline">
    I_h^H
   </math>
   but also the relaxed approximation
   <math display="inline">
    \overline{u}_h^m
   </math>
   itself by a restriction operator
   <math display="inline">
    \widehat{I}_{h}^{H}
   </math>
   .
  </p>
  <p block-type="Text">
   However, as in the linear case, only the coarsegrid corrections,
   <math display="inline">
    \widehat{e}_H
   </math>
   , are interpolated back to the fine grid, where the fine-grid errors are smoothed again. This forms the basis of the well-known full approximation scheme (FAS) [2]. The nonlinearity of the problems enters in the smoothing operators. If
   <math display="inline">
    N_h
   </math>
   and
   <math display="inline">
    N_H
   </math>
   are linear operators, the FAS method is equivalent to the linear multigrid scheme. For many problems, however, the nonlinearity can also be handled globally, resulting in a sequence of linear problems that can be solved efficiently with linear multigrid.
  </p>
  <h2>
   Multigrid for Linear Complementarity Problems
  </h2>
  <p block-type="Text">
   In 1983, Brandt and Cryer [3] proposed a multigrid method for LCPs arising from free boundary problems. The algorithm is based on the projected successive over-relaxation (SOR) method [7] and is called the
   <i>
    projected full approximation scheme (PFAS)
   </i>
   in [3]. PFAS has been successfully used in the financial community for American options with stochastic volatility in
   <math display="inline">
    [6, 12]
   </math>
   .
  </p>
  <p block-type="Text">
   For the smoothing method in PFAS, one employs a projected version of the PGS, consisting of two partial steps per unknown: In a first step, a Gauss-Seidel iteration is applied to equation (5) at
   <math display="inline">
    (x_i, y_i)
   </math>
   with equality sign. In the second partial step, the solution at
   <math display="inline">
    (x_i, y_i)
   </math>
   is projected, so that constraint (6) is satisfied,
  </p>
  <p block-type="Equation">
   <math display="block">
    \overline{u}^{m}(x_{i}, y_{j}) = \max\{f_{2}(x_{i}, y_{j}), \widehat{u}(x_{i}, y_{j})\}
   </math>
   <math display="block">
    \forall (x_{i}, y_{i}) \in G_{h} \tag{11}
   </math>
  </p>
  <p block-type="Text">
   where
   <math display="inline">
    \overline{u}^m
   </math>
   denotes the unknown at
   <math display="inline">
    (x_i, y_i)
   </math>
   after PGS and
   <math display="inline">
    \hat{u}
   </math>
   the unknown after the Gauss–Seidel iteration. A linewise variant of PGS has been applied in [6].
  </p>
  <p block-type="TextInlineMath">
   The following LCP holds for
   <math display="inline">
    e_h^m := u_h - \overline{u}_h^m
   </math>
   :
  </p>
  <p block-type="Equation">
   <math display="block">
    A_{h}e_{h}^{m} \leq d_{h}^{m} \quad \mathbf{x} \in \Omega
   </math>
   <math display="block">
    e_{h}^{m} + \overline{u}_{h}^{m} \geq f_{2,h} \quad \mathbf{x} \in \Omega
   </math>
   <math display="block">
    (e_{h}^{m} + \overline{u}_{h}^{m} - f_{2,h})(A_{h}e_{h}^{m} - d_{h}^{m}) = 0 \quad \mathbf{x} \in \Omega \quad (12)
   </math>
  </p>
  <p block-type="TextInlineMath">
   with defect:
   <math display="inline">
    d_h^m = f_{1,h} - A_h \overline{u}_h^m
   </math>
   . A smooth error,
   <math display="inline">
    e_h^m
   </math>
   , can be approximated on a coarse grid without any essential loss of information. The LCP coarse-grid equation for the coarse-grid approximation of the error
   <math display="inline">
    \widehat{e}_{H}^{m}
   </math>
   is therefore defined in PFAS by:
  </p>
  <p block-type="Equation">
   <math display="block">
    A_{H}\widehat{e}_{H}^{m} \leq I_{h}^{H}d_{h}^{m}
   </math>
   <math display="block">
    \widehat{e}_{H}^{m} + \widehat{I}_{h}^{H}\overline{u}_{h}^{m} \geq f_{2,H}
   </math>
   <math display="block">
    (\widehat{e}_{H}^{m} + \widehat{I}_{h}^{H}\overline{u}_{h}^{m} - f_{2,H})(A_{H}\widehat{e}_{H}^{m} - I_{h}^{H}d_{h}^{m}) = 0 \quad (13)
   </math>
  </p>
  <p block-type="TextInlineMath">
   For LCPs, we need to choose "constraint preserving" restriction operators that do not mix information from active and inactive regions on coarse grids. Further, the bilinear interpolation operator
   <math display="inline">
    I_H^h
   </math>
   is applied only to unknowns on the "active" points [3].
  </p>
  <p block-type="Text">
   We finally mention that in
   <math display="inline">
    [10]
   </math>
   , another multigrid variant for LCPs, the so-called monotone multigrid method, has been presented, used in finance in [9].
  </p>
  <h4>
   Multigrid as a Preconditioner
  </h4>
  <p block-type="Text">
   Multigrid as a preconditioner is particularly interesting for robustness. An argument for combining multigrid with an acceleration technique is that problems become more and more complex if we treat real-life applications. The fundamental idea of multigrid, to reduce the high-frequency error components by smoothing and to take care of the low frequency error by coarse-grid correction, does not always work optimally if straightforward multigrid approaches are used. In such situations, the combination with Krylov subspace methods, such as conjugate gradient, generalized minimal residual (GMRES), or BiCGSTAB, have the potential to give a substantial convergence acceleration. Often, sophisticated multigrid components may also lead to very satisfactory convergence factors, but they can be difficult to realize and implement.
  </p>
  <p block-type="TextInlineMath">
   From the multigrid point of view, multigrid as a preconditioner can also be interpreted as an acceleration of multigrid by iterant recombination. This interpretation easily allows generalizations, for example, to nonlinear problems and to LCPs. Let
   <math display="inline">
    u_h^0
   </math>
   be an initial approximation for solving
   <math display="inline">
    A_h u_h = f_h
   </math>
   , and
   <math display="inline">
    d_h^0 = f_h - \hat{A}_h u_h^0
   </math>
   its defect. The
   <i>
    Krylov subspace
   </i>
   ,
   <math display="inline">
    K_h^m
   </math>
   , is defined by
   <math display="inline">
    K_h^m := \text{span}[d_h^0, A_h d_h^0, \dots, A_h^{m-1} d_h^0].
   </math>
   This subspace can also be represented by span
   <math display="inline">
    [u_h^0]
   </math>
   <math display="inline">
    u_h^m, u_h^1 - u_h^m, \ldots, u_h^{m-1} - u_h^m
   </math>
   , where the
   <math display="inline">
    u_h^m
   </math>
   are previous approximations to the solution. To find an improved approximation
   <math display="inline">
    u_{h,\text{acc}}^m
   </math>
   , we now consider a linear combination of the
   <math display="inline">
    \tilde{m}+1
   </math>
   latest approximations:
  </p>
  <p block-type="Equation">
   <math display="block">
    u_{h,\text{acc}}^{m} = u_h^{m} + \sum_{i=1}^{\widetilde{m}} \overline{\alpha}_i (u_h^{m-i} - u_h^{m}) \qquad (14)
   </math>
  </p>
  <p block-type="TextInlineMath">
   In order to obtain an improved approximation
   <math display="inline">
    u_{h,\text{acc}}^m
   </math>
   , the parameters
   <math display="inline">
    \overline{\alpha}_i
   </math>
   are determined in such a way that the defect
   <math display="inline">
    d_{h,\text{acc}}^m
   </math>
   is minimized, for example, with respect to the
   <math display="inline">
    l_2
   </math>
   -norm
   <math display="inline">
    ||\cdot||_2
   </math>
   . This is a classical defect minimization problem [16]. This technique was generalized to LCPs in [12], where PFAS was used as the method whose iterants were recombined.
  </p>
  <h4>
   Acknowledgments
  </h4>
  <p block-type="Text">
   This research has been partially supported by the Dutch government through the national program BSIK: knowledge and research capacity, in the ICT project BRICKS (http://www.bsik-bricks.nl), theme MSV1.
  </p>
  <h4>
   References
  </h4>
  <p block-type="ListGroup" class="has-continuation">
   <ul>
    <li block-type="ListItem">
     Bensoussan, A. &amp; Lions, J.L. (1982). Applications des [1] in Équations Variationelles en Contrôle Stochastique, North-Holland, Dunot, Amsterdam, English Translation 1978.
    </li>
    <li block-type="ListItem">
     Brandt, A. (1977). Multi-level adaptive solutions to [2] boundary-value problems, Mathematics of Computation 31, 333-390.
    </li>
    <li block-type="ListItem">
     Brandt, A. &amp; Cryer, C.W. (1983). Multigrid algorithms [3] for the solution of linear complementarity problems arising from free boundary problems, SIAM Journal on Scientific Computing 4, 655–684.
    </li>
    <li block-type="ListItem">
     [4] Briggs, W.L., Emden Henson, V. &amp; McCormick, S.F. (2000). A Multigrid Tutorial, 2nd Edition, SIAM, Philadelphia, PA.
    </li>
    <li block-type="ListItem">
     Bungartz, H.J. &amp; Griebel, M. (2004). Sparse grids, Acta [5] Numerica 13, 147-269.
    </li>
   </ul>
  </p>
  <p block-type="ListGroup" class="has-continuation">
   <ul>
    <li block-type="ListItem">
     [6] Clarke, N. &amp; Parrot, K. (1999). Multigrid for American option pricing with stochastic volatility,
     <i>
      Applied Mathematics and Finance
     </i>
     <b>
      6
     </b>
     , 177–197.
    </li>
    <li block-type="ListItem">
     [7] Cryer, C.W. (1971). The solution of a quadratic programming problem using systematic overrelaxation,
     <i>
      SIAM Journal on Control
     </i>
     <b>
      9
     </b>
     , 385–392.
    </li>
    <li block-type="ListItem">
     [8] Friedman, A. (1982).
     <i>
      Variational Principles and Free Boundary Problems
     </i>
     , Wiley, New York.
    </li>
    <li block-type="ListItem">
     [9] Holtz, M. &amp; Kunoth, A. (2007). B-spline based monotone multigrid methods.
     <i>
      SIAM Journal on Numerical Analysis
     </i>
     <b>
      45
     </b>
     , 1175–1199.
    </li>
    <li block-type="ListItem">
     [10] Kornhuber, R. (1994). Monotone multigrid methods for elliptic variational inequalities I,
     <i>
      Applied Numerical Mathematics
     </i>
     <b>
      69
     </b>
     , 167–184.
    </li>
    <li block-type="ListItem">
     [11] Kwok, Y.K. (1998).
     <i>
      Mathematical Models of Financial Derivatives
     </i>
     , 2nd Edition, Springer, Singapore.
    </li>
    <li block-type="ListItem">
     [12] Oosterlee, C.W. (2003). On multigrid for linear complementarity problems with application to American-style options.
     <i>
      Electronic Transactions on Numerical Analysis
     </i>
     ,
     <b>
      15
     </b>
     , 165–185.
    </li>
    <li block-type="ListItem">
     [13] Reisinger, C. &amp; Wittum, G. (2004). On multigrid for anisotropic equations and variational inequalities,
     <i>
      Computers and Visual Science
     </i>
     ,
     <b>
      7
     </b>
     , 189–197.
    </li>
   </ul>
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     [14] Reisinger, C. &amp; Wittum, G. (2007). Efficient hierarchical approximation of high-dimensional option pricing problems,
     <i>
      SIAM Journal On Scientific Computing
     </i>
     <b>
      29
     </b>
     , 440–458.
    </li>
    <li block-type="ListItem">
     [15] Trottenberg, U., Oosterlee, C.W. &amp; Schuller, A. (2000). ¨
     <i>
      Multigrid
     </i>
     , Academic Press, London.
    </li>
    <li block-type="ListItem">
     [16] Washio, T. &amp; Oosterlee, C.W. (1997). Krylov subspace acceleration for nonlinear multigrid schemes.
     <i>
      Electronic Transactions on Numerical Analysis
     </i>
     <b>
      6
     </b>
     , 271–290.
    </li>
    <li block-type="ListItem">
     [17] Wilmott, P., Dewynne, J. &amp; Howison, S. (1993).
     <i>
      Option Pricing
     </i>
     , Oxford Financial Press.
    </li>
    <li block-type="ListItem">
     [18] bin Zubair, H., Leentvaar, C.C.W. &amp; Oosterlee, C.W. (2007). Efficient
     <i>
      d
     </i>
     -multigrid preconditioners for sparse-grid solution of high dimensional partial differential equations,
     <i>
      International Journal Of Computer Mathematics
     </i>
     <b>
      84
     </b>
     , 1129–1146.
    </li>
    <li block-type="ListItem">
     [19] bin Zubair, H., Oosterlee, C.W. &amp; Wienands, R. (2007). Multigrid for high dimensional elliptic partial differential equations on non-equidistant grids,
     <i>
      SIAM Journal On Scientific Computing
     </i>
     <b>
      29
     </b>
     , 1613–1636.
    </li>
   </ul>
  </p>
  <p block-type="Text">
   CORNELIS W. OOSTERLEE
  </p>
 </body>
</html>
