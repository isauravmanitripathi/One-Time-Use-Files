<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
 </head>
 <body>
  <h2>
   <b>
    Bermudan Options
   </b>
  </h2>
  <p block-type="Text">
   A Bermudan option allows its holder to exercise the contract before maturity, and this feature makes its pricing significantly more difficult in comparison with the corresponding European option. Even for simple put options, currently there are no explicit formulae for their prices and therefore numerical methods must be employed. Although there are several such methods available for pricing Bermudan and American (see American Options) options depending on a single asset (see Finite Difference Methods for Early
   <b>
    Exercise Options
   </b>
   ), these methods become typically ineffective for options on multiple assets. In such cases, we have to usually resort to methods based on Monte Carlo simulations. In this context, approaches that combine simulations with regression techniques have proven to be particularly effective. An attractive feature of these methods is that, in principle, they can be applied to any situation where trajectories of the underlying process can be simulated, since no other information about the process is required (unlike, e.g., the stochastic mesh method) (see Stochastic Mesh Method). In particular, they can be applied to pathdependent options. Since their introduction by several authors, especially Carri√®re [2], Thitsiklis and Van Roy [7], and Longstaff and Schwartz [4], the area of their applications has been extended beyond the pricing of Bermudan options, and currently it also includes the optimal dynamic asset allocation problem [1] and hedging [6].
  </p>
  <p block-type="TextInlineMath">
   Regression methods use the dynamic programming representation to determine the price of the option and also the optimal exercise strategy. To simplify the presentation of these methods, suppose that our objective is to price a Bermudan style option whose payoff depends only on the current value of the underlying security. The option can be exercised at
   <math display="inline">
    M + 1
   </math>
   time points (including the initial time), which we shall denote by
   <math display="inline">
    t_0, t_1, \ldots, t_M = T
   </math>
   . At the time of exercise,
   <math display="inline">
    \tau
   </math>
   , the value of the option is equal to
   <math display="inline">
    G(\tau, S_{\tau})
   </math>
   , where G is a payoff function. The dynamic of the price of the underlying security is described by a process
   <math display="inline">
    \{S_{t_i}\}_{i=0,1,\dots,M}
   </math>
   , which we assume to be a Markov chain with values in
   <math display="inline">
    \mathcal{R}^b
   </math>
   . This process may be obtained, for example, as a result of sampling a continuous process
   <math display="inline">
    \{S_t\}_{\{0 \le t \le T\}}
   </math>
   that solves a stochastic differential equation.
  </p>
  <p block-type="Text">
   From the general theory of arbitrage-free pricing (see Risk-neutral Pricing), it follows that an arbitrage-free price of the option can be represented as the optimal expected discounted payoff:
  </p>
  <p block-type="Equation">
   <math display="block">
    P(t_0, S_0) := \max E[B(t_0, \tau)G(\tau, S_\tau)] \qquad (1)
   </math>
  </p>
  <p block-type="TextInlineMath">
   where the expectation is taken with respect to a given risk-neutral measure O, and
   <math display="inline">
    B(s, t)
   </math>
   denotes the discount factor for the period
   <math display="inline">
    (s, t)
   </math>
   . The maximum in equation (1) is taken over all stopping times taking values in the set
   <math display="inline">
    \{t_0, t_1, \ldots, t_M\}
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   Since we do not know the optimal exercise strategy, a direct calculation of the price from equation (1) is not feasible. However, the price of the option can also be obtained by using the dynamic programming representation. For this, we use the following backward recursion to find functions
   <math display="inline">
    P(t_i, \cdot)
   </math>
   ,
   <math display="inline">
    i =
   </math>
   <math display="inline">
    1, \ldots, M
   </math>
   ,
  </p>
  <p block-type="Equation">
   <math display="block">
    P(T, x) = G(T, x)
   </math>
   (2)
   <br/>
   <math display="block">
    P(t_i, x) = \max\{G(t_i, x), C(t_i, x)\},
   </math>
   <br/>
   <math display="block">
    i = M - 1, \dots, 0
   </math>
   (3)
  </p>
  <p block-type="Text">
   where the continuation value,
   <math display="inline">
    C(t_i, x)
   </math>
   , is defined as
  </p>
  <p block-type="Equation">
   <math display="block">
    C(t_i, x) := B_i E[P(t_{i+1}, S_{t_{i+1}})|S_{t_i} = x] \qquad (4)
   </math>
  </p>
  <p block-type="TextInlineMath">
   Then the price of the option at
   <math display="inline">
    t_0
   </math>
   is given by
   <math display="inline">
    P(t_0, S_0)
   </math>
   . In the last equation, we assume that the discount factor
   <math display="inline">
    B_i \equiv B(t_i, t_{i+1})
   </math>
   is deterministic. Equation (3) lends itself to a very intuitive explanation. At the
   <math display="inline">
    i
   </math>
   th exercise opportunity, the owner of the option makes the decision about early exercise by comparing the immediate exercise value with the present value of continuing. The larger of these two determines the present value of the option and the optimal action.
  </p>
  <p block-type="Text">
   To use this method, in practice, we must be able to calculate efficiently the conditional expectations
  </p>
  <p block-type="Equation">
   <math display="block">
    E[P(t_{i+1}, S_{t_{i+1}})|S_{t_i} = x]
   </math>
   (5)
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   for
   <math display="inline">
    i = 0, \ldots, M - 1
   </math>
   and some selected set of points
   <math display="inline">
    x \in \mathbb{R}^b
   </math>
   from the state space. Regression-based methods accomplish this through the regression of option values at the next time step on a set of regressors that depend on the current state. The main assumption behind these methods is that the conditional expectation (5) as a function of the state variable
   <math display="inline">
    x
   </math>
  </p>
  <p block-type="Text">
   can be represented in the form of an infinite series expansion, meaning that we have
  </p>
  <p block-type="Equation">
   <math display="block">
    C(t_i, x) = \sum_{j=1}^{\infty} a_{ij} \beta_j(x) \tag{6}
   </math>
  </p>
  <p block-type="TextInlineMath">
   for some basis functions
   <math display="inline">
    \beta_i : \mathcal{R}^b \to \mathcal{R}
   </math>
   and constants
   <math display="inline">
    \{a_{ij}\}\
   </math>
   . Then an approximation to the continuation value can be obtained by using only a finite number of basis functions, say
   <math display="inline">
    L
   </math>
   . This can be accomplished, for example, by projecting
   <math display="inline">
    C(t_i, \cdot)
   </math>
   onto the span of the basis functions
   <math display="inline">
    \beta_j
   </math>
   ,
   <math display="inline">
    j = 1, \ldots, L
   </math>
   . If the projection space is equipped with a measure that corresponds to the distribution of
   <math display="inline">
    S_{t_i}
   </math>
   , then the coefficients in this approximation,
   <math display="inline">
    a_{i1}^*, \ldots, a_{iL}^*
   </math>
   , solve the following optimization problem
  </p>
  <p block-type="Equation">
   <math display="block">
    E\left[ (C(t_i, S_{t_i}) - \sum_{j=1}^{L} a_{ij}^* \beta_j (S_{t_i}))^2 \right]
   </math>
   <br/>
   =
   <math display="block">
    \min_{\{a_{i1}, \dots, a_{iL}\}} E\left[ (C(t_i, S_{t_i}) - \sum_{j=1}^{L} a_{ij} \beta_j (S_{t_i}))^2 \right]
   </math>
   <br/>
   (7)
  </p>
  <p block-type="TextInlineMath">
   Thus, here the continuation value is approximated by a member of a parametric family of functions. This method, however, cannot be implemented directly since the continuation value
   <math display="inline">
    C(t_i, \cdot)
   </math>
   is unknown. From the definition of
   <math display="inline">
    C(t_i, \cdot)
   </math>
   , it follows that for a single realization
   <math display="inline">
    (s_{i1}, s_{(i+1)1})
   </math>
   of the vector
   <math display="inline">
    (S_{t_i}, S_{t_{i+1}})
   </math>
   the continuation value
   <math display="inline">
    C(t_i, s_{i1})
   </math>
   can be approximated by
   <math display="inline">
    B_{t_i} P(t_{i+1}, s_{(i+1)1})
   </math>
   . This observation leads to the selection of the coefficients
   <math display="inline">
    a_{i1}^*, \ldots, a_{iL}^*
   </math>
   that minimize the following criterion (see
   <math display="inline">
    [8]
   </math>
   ):
  </p>
  <p block-type="Equation">
   <math display="block">
    E\left[ (B_i P(t_{i+1}, S_{t_{i+1}}) - \sum_{j=1}^{L} a_{ij} \beta_j (S_{t_i}))^2 \right] \quad (8)
   </math>
  </p>
  <p block-type="TextInlineMath">
   where the expectation is taken with respect to the joint distribution of
   <math display="inline">
    (S_{t_i}, S_{t_{i+1}})
   </math>
   .
  </p>
  <p block-type="Text" class="has-continuation">
   The argument that motivates the use of equation
   <math display="inline">
    (8)
   </math>
   as a method of approximation may suggest that the method will not be accurate, since we are approximating the continuation value at a given state by using only one successor. We should observe, however, that in this method we are not approximating continuation values individually at each state but
  </p>
  <p block-type="TextInlineMath">
   rather we approximate the continuation value
   <math display="inline">
    C(t_i, \cdot)
   </math>
   treated as a function. Because of this and the assumed smoothness of this function, the resulting estimate of the continuation value at any state "borrows" also information about continuation values from points in a neighborhood of this state.
  </p>
  <p block-type="Text">
   A factor that indeed determines the effectiveness of this approach is the selection of the basis functions. The assumption that guarantees the existence of the infinite series expansion (6) is rather a weak one, as any sufficiently smooth function can be approximated, for example, by polynomials. In practice, however, we have to truncate this expansion to a finite sum and hence we have to decide which terms we need to keep. The choice of a finite number of basis functions determines the success of the method and often must be crafted to the problem at hand. It becomes especially difficult for options on multiple assets, since then the number of required basis functions grows quickly with the dimension of the underlying price process.
  </p>
  <p block-type="TextInlineMath">
   On the basis of this method of approximation of continuation values, we can define an implementable procedure for pricing Bermudan options. For this, in equation
   <math display="inline">
    (8)
   </math>
   we have to substitute for
   <math display="inline">
    P(t_{i+1}, \cdot)
   </math>
   its approximation,
   <math display="inline">
    \hat{P}(t_{i+1}, \cdot)
   </math>
   , determined from the backward induction
   <math display="inline">
    (2)-(4)
   </math>
   . In addition, to find the coefficients
   <math display="inline">
    a_{i1}^*, \ldots, a_{iM}^*
   </math>
   that minimize equation
   <math display="inline">
    (8)
   </math>
   , typically we have to approximate the expectation by using a sample mean. The resulting algorithm can be summarized in the following way. In the first phase, we simulate
   <math display="inline">
    N
   </math>
   independent trajectories
   <math display="inline">
    \{s_{1j}, \ldots, s_{Mj}\}, j = 1, \ldots, N
   </math>
   , of the Markov chain
   <math display="inline">
    \{S_{t_i}\}_{\{0 \le i \le M\}}
   </math>
   . At maturity of the contract, we set
   <math display="inline">
    \hat{P}_{Mj} = G(T, s_{Mj})
   </math>
   and then start the backward induction. Given the estimated values
   <math display="inline">
    \hat{P}_{(i+1)j}
   </math>
   ,
   <math display="inline">
    j =
   </math>
   1,...,
   <i>
    N
   </i>
   , we approximate the continuation value&lt;br&gt;at
   <math display="inline">
    s_{ij}
   </math>
   by
   <math display="inline">
    \hat{C}_{ij} = \sum_{k=1}^{M} a_{ik}^* \beta_k(s_{ij})
   </math>
   , where
   <math display="inline">
    a_{i1}^*, \ldots, a_{iM}^*
   </math>
   minimize
  </p>
  <p block-type="Equation">
   <math display="block">
    \sum_{j=1}^{N} \left[ B_i \hat{P}_{(i+1)j} - \sum_{k=1}^{M} a_{ik} \beta_k(s_{ij}) \right]^2 \tag{9}
   </math>
  </p>
  <p block-type="TextInlineMath">
   Then, we set
   <math display="inline">
    \hat{P}_{ij} = \max\{G(t_i, s_{ij}), \hat{C}_{ij}\}
   </math>
   . Finally, the price of the option is calculated as
   <math display="inline">
    \max\{B_o(\hat{P}_{11} +
   </math>
   <math display="inline">
    \cdots + \hat{P}_{1N})/N, G(t_0, s_0)
   </math>
   .
  </p>
  <p block-type="Text" class="has-continuation">
   Carri√®re [2] has proposed a similar approach, but instead of approximating the continuation value by a member of a parametric family he suggests using
  </p>
  <p block-type="Text">
   nonparametric regression techniques based on splines and a local polynomial smoother. The approach proposed by Longstaff and Schwartz [4] is similar to the one presented here except that the authors use a different formula for calculating
   <math display="inline">
    \hat{P}_{ij}
   </math>
   . They also recommend using the least-squares method (9) only for options in the money.
  </p>
  <p block-type="Text">
   Convergence properties of regression-based methods have been studied in [3, 5, 7, 8]. In particular, Cl√©ment et al. [3] prove convergence of the method proposed by Longstaff and Schwartz as the number of simulated trajectories,
   <math display="inline">
    N
   </math>
   , tends to infinity. Stentoft [5] presents a detailed numerical analysis of the Longstaff and Schwartz approach. By considering alternative families of polynomials and different numbers of basis functions, the author provides a guidance into the problem of proper selection of basis functions. He also finds that in problems with high number of assets the least-squares approach is superior to the binomial model method in terms of the trade-off between computational time and precision.
  </p>
  <h2>
   References
  </h2>
  <p block-type="Text">
   [1] Brandt, M.W., Goyal, A., Santa-Clara, P. &amp; Stroud, J.R.
   <math display="inline">
    (2005)
   </math>
   . A simulation approach to dynamic portfolio choice with an application to learning about return predictability,
   <i>
    Review of Financial Studies
   </i>
   <b>
    18
   </b>
   , 831‚Äì873.
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     [2] Carri√®re, J. (1996). Valuation of early-exercise price of options using simulations and non-parametric regression, Insurance: Mathematics and Economics 19, 19-30.
    </li>
    <li block-type="ListItem">
     [3] Cl√©ment, E., Lamberton, D. &amp; Protter, P. (2002). An analysis of a least squares regression algorithm for American option pricing, Finance and Stochastics 6, 449-471.
    </li>
    <li block-type="ListItem">
     [4] Longstaff, F.A. &amp; Schwartz, E.S. (2001). Valuing American options by simulation: a simple least-squares approach, Review of Financial Studies 14, 113‚Äì147.
    </li>
    <li block-type="ListItem">
     [5] Stentoft, L. (2004). Assessing the least-squares Monte-Carlo approach to American option valuation,
     <i>
      Review of
     </i>
     Derivatives Research 7, 129‚Äì168.
    </li>
    <li block-type="ListItem">
     [6] Tebaldi, C. (2005). Hedging using simulation: a least squares approach, Journal of Economic Dynamics and Control 29, 1287-1312.
    </li>
    <li block-type="ListItem">
     [7] Thitsiklis, J. &amp; Van Roy, B. (1999). Optimal stopping of Markov processes: Hilbert space theory, approximation algorithms, and an application to pricing highdimensional financial derivatives, IEEE Transactions on Automatic Control 44, 1840-1851.
    </li>
    <li block-type="ListItem">
     [8] Thitsiklis, J. &amp; Van Roy, B. (2001). Regression methods for pricing complex American-style options, IEEE Transactions on Neural Networks 12, 694-703.
    </li>
   </ul>
  </p>
  <h2>
   <b>
    Related Articles
   </b>
  </h2>
  <p block-type="Text">
   American Options; Finite Difference Methods for Early Exercise Options; Integral Equation Methods for Free Boundaries; Monte Carlo Simulation for Stochastic Differential Equations.
  </p>
  <p block-type="Text">
   ADAM KOLKIEWICZ
  </p>
 </body>
</html>
