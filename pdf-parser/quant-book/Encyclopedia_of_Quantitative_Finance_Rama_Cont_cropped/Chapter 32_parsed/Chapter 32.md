# **Point Processes**

This article gives a brief overview of general point processes. We refer to the books  $[1-5]$ , for proofs and advanced results.

# **Marked Point Processes**

## Definition

An increasing sequence of random times is called a univariate point process. A simple example is the Poisson process.

Given a univariate point process, we associate to every time  $T_n$  a mark  $Z_n$ . More precisely, let  $(\Omega, \mathcal{F}, \mathbb{P})$  be a probability space,  $(Z_n, n \ge 1)$  a sequence of random variables taking values in a measurable space  $(E, \mathcal{E})$ , and  $(T_n, n \ge 1)$  an increasing sequence of nonnegative random variables. We assume that  $\lim T_n = \infty$ , so that there is only a finite number of *n* such that, for a given *t*, one has  $T_n \le t$ . We define the process  $N$  as follows. For each set,  $A \in \mathcal{E}, N_t(A) = \sum_n \mathbb{1}_{\{T_n \le t\}} \mathbb{1}_{\{Z_n \in A\}}$  is the number of "marks" in the set  $A$  before time  $t$ . The natural filtration of  $N$  is

$$\mathcal{F}_t^{\mathbf{N}} = \sigma(N_s(A), s \le t, A \in \mathcal{E}) \tag{1}$$

The predictable  $\sigma$ -algebra  $\mathcal{P}$  is the  $\sigma$ -algebra defined on  $\Omega \times \mathbb{R}^+$  that is generated by the sets

$$A \times \{0\}, \ A \in \mathcal{F}_0^{\mathbf{N}}; \quad A \times ]s, t], \ A \in \mathcal{F}_s^{\mathbf{N}}, \ s \le t$$

$$(2)$$

The associated random counting measure  $\mu(\omega)$ , ds, dz) is defined as follows: let  $\Phi$  be a map

$$(t,\omega,z) \in (\mathbb{R}^+, \Omega, E) \to \Phi(t,\omega,z) \in \mathbb{R} \tag{3}$$

We set

$$\int_{]0,t]} \int_{E} \Phi(s,z) \mu(\mathrm{d}s,\mathrm{d}z) = \sum_{n=1}^{\infty} \Phi(T_n,Z_n) \mathbb{1}_{\{T_n \le t\}}$$
$$= \sum_{n=1}^{N_t(E)} \Phi(T_n,Z_n) \qquad (4)$$

The process  $N$  is called a *marked point process*. This is a generalization of the compound Poisson process: we have introduced, in particular, a spatial dimension for the size of jumps, which are no more i.i.d. random variables.

A map  $\Phi$  is predictable if it is  $\mathcal{P} \otimes \mathcal{E}$  measurable. The *compensator* of the marked point process  $N$  is the unique predictable random measure  $\nu$  on ( $\mathbb{R}^+ \times$  $E, \mathcal{G} \otimes \mathcal{E}$ ) such that, for every bounded predictable process  $\Phi$ 

$$\mathbb{E}\left(\int_{0}^{t} \int_{E} \Phi(s, z; \omega) \mu(\omega; \mathrm{d}s, \mathrm{d}z)\right)$$
$$= \mathbb{E}\left(\int_{0}^{t} \int_{E} \Phi(s, z; \omega) \nu(\omega; \mathrm{d}s, \mathrm{d}z)\right) \quad (5)$$

In the case of a marked point process on  $\mathbb{R} \times \mathbb{R}^d$ , the compensator admits an explicit representation: let  $G_n(\mathrm{d}t,\mathrm{d}z)$  be a regular version of the conditional distribution of  $(T_{n+1}, Z_{n+1})$  with respect to  $\mathcal{F}_{T_n}^N =$  $\sigma\{(T_1, Z_1), \ldots (T_n, Z_n)\}$ . Then,

$$\nu(\mathrm{d}t,\mathrm{d}z) = \sum_{n} \mathbbm{1}_{\{T_n < t \le T_{n+1}\}} \frac{G_n(\mathrm{d}t,\mathrm{d}z)}{G_n([t,\infty[\times\mathbb{R}^d])} \quad (6)$$

# Intensity Process

In what follows, we assume that, for any  $A \in \mathcal{E}$ , the process  $(N_t(A), t \ge 0)$  admits the **F**-predictable intensity  $(\lambda_t(A), t \ge 0)$ , that is, there exists a nonnegative process  $(\lambda_t(A), t > 0)$  such that

$$N_t(A) - \int_0^t \lambda_s(A) \mathrm{d}s \tag{7}$$

is an **F**- martingale. Then, if  $X_t = \sum_{n=1}^{N_t(E)} \Phi(T_n, Z_n)$  where  $\Phi$  is an **F**-predictable process that satisfies

$$\mathbb{E}\left(\int_{]0,t]}\int_{E}|\Phi(s,z)|\lambda_{s}(\mathrm{d}z)\mathrm{d}s\right)<\infty\qquad(8)$$

the process

$$X_{t} - \int_{0}^{t} \int_{E} \Phi(s, z) \lambda_{s}(\mathrm{d}z) \mathrm{d}s$$
  
= 
$$\int_{]0, t]} \int_{E} \Phi(s, z) \left[ \mu(\mathrm{d}s, \mathrm{d}z) - \lambda_{s}(\mathrm{d}z) \mathrm{d}s \right] \qquad (9)$$

is a martingale and, in particular,

$$\mathbb{E}\left(\int_{]0,t]} \int_{E} \Phi(s,z)\mu(\mathrm{d}s,\mathrm{d}z)\right)$$
$$=\mathbb{E}\left(\int_{]0,t]} \int_{E} \Phi(s,z)\lambda_{s}(\mathrm{d}z)\mathrm{d}s\right) \qquad (10)$$

The random measure  $\mu(ds, dz) - \lambda_s(dz)ds$  is the compensated measure of  $\mu$ .

**Example** Compound Poisson Process. Let  $X_t =$  $\sum_{n=1}^{N_t} Y_n$  be a  $(\lambda, F)$ -compound Poisson process. We can consider the  $Y_n$ s as marks and introduce the marked point process  $N_t(A) = \sum_{n=1}^{N_t} 1_{Y_n \in A}$ . For any A, the process  $(N_t(A), t \ge 0)$  is a compound Poisson process, and  $(N_t(A) - \lambda t P(Y_1 \in A), t \ge 0)$ is a martingale. The intensity of the marked point process N is  $\lambda_t(\mathrm{d}z) = \lambda F(\mathrm{d}z)$ . Moreover, if  $A_i$  are disjoint sets, the processes  $N(A_i)$  are independent. The counting random measure  $\mu$  satisfies

$$\int_0^t \int_{\mathbb{R}} f(x) \mu(\omega; \mathrm{d}s, \mathrm{d}x) = \sum_{k=1}^{N_t} f(Y_k) \tag{11}$$

and we obtain, in particular, that, as in the article on Poisson processes (see Poisson Process)

$$M_t^f = \int_0^t \int_{\mathbb{R}} f(x) (\mu(\omega; \mathrm{d}s, \mathrm{d}x) - \mathrm{d}s \,\lambda F(\mathrm{d}x)) \tag{12}$$

is a martingale.

# Predictable Representation Property

Let  $\mathbf{F}^{\mathbf{N}}$  be the filtration generated by the marked point process with intensity  $\lambda_s(dz)$ . Then, any  $(\mathbb{P}, \mathbf{F}^N)$ martingale  $M$  admits the representation

$$M_t = M_0 + \int_0^t \int_E \Phi(s, x) (\mu(\mathrm{d}s, \mathrm{d}x) - \lambda_s(\mathrm{d}x) \mathrm{d}s) \tag{13}$$

where  $\Phi$  is a  $\mathbf{F}^{\mathbf{N}}$ -predictable process such that

$$\mathbb{E}\left(\int_{0}^{t} \int_{E} |\Phi(s,x)| \lambda_{s}(\mathrm{d}x) \mathrm{d}s\right) < \infty \tag{14}$$

## Change of Probability Measure

Let  $\mu$  be the random measure of a marked point process with intensity  $\lambda_t(A) = \alpha_t m_t(A)$ , where m is a probability measure. We shall say that the marked point process admits  $(\alpha_t, m_t(\text{d}z))$  as P-local characteristics. Let  $(\psi_t, h_t(z))$  be two predictable positive processes such that

$$\int_0^t \psi_s \alpha_s \mathrm{d}s < \infty, \ \int_E h_t(z) m_t(\mathrm{d}z) = 1 \qquad (15)$$

Let  $L$  be the solution of

$$dL_{t} = L_{t^{-}} \int_{E} (\psi_{t} h_{t}(z) - 1)(\mu(\mathrm{d}t, \mathrm{d}z)$$
$$- \alpha_{t} m_{t}(\mathrm{d}z) \mathrm{d}t), \ L_{0} = 1 \tag{16}$$

If  $\mathbb{E}(L_t) = 1$  (so that L is a martingale), setting  $\mathbb{Q}|_{\mathcal{F}_t} = L_t \mathbb{P}|_{\mathcal{F}_t}$ , the marked point process has the  $\mathbb{Q}$ local characteristics  $(\psi_t \alpha_t, h_t(z) m_t(dz)).$ 

Example Compound Poisson Process. The change of measure for compound Poisson processes can be written in terms of random measures. Let

$$L_{t} = \exp\left(\int_{\mathbb{R}} f(x)N_{t}(\mathrm{d}x) - t\lambda \int_{-\infty}^{\infty} (e^{f(x)} - 1)F(\mathrm{d}x)\right)$$
$$= \exp\left(\int_{0}^{t} \int_{\mathbb{R}} f(x)\mu(\mathrm{d}s, \mathrm{d}x) - t \int_{-\infty}^{\infty} (e^{f(x)} - 1)\lambda F(\mathrm{d}x)\right) \qquad (17)$$

be a martingale. Define  $d\mathbb{Q}|_{\mathcal{F}_t} = L_t d\mathbb{P}|_{\mathcal{F}_t}$ . Then,

$$\int_0^t \int_{\mathbb{R}} (\mu(\mathrm{d}s, \mathrm{d}x) - \mathrm{d}s \, e^{f(x)} \lambda F(\mathrm{d}x)) \tag{18}$$

is a  $\mathbb{Q}$ -martingale as obtained in the article on Poisson processes (see Poisson Process).

# **Poisson Point Processes**

#### Poisson Measures

Let  $(E, \mathcal{E})$  be a measurable space. A random measure  $\mu$  on  $(E, \mathcal{E})$  is a Poisson measure with intensity  $\nu$ , where  $\nu$  is a  $\sigma$ -finite measure on  $(E, \mathcal{E})$ , if

- 1. for every set  $B \in \mathcal{E}$  with  $\nu(B) < \infty$ ,  $\mu(B)$ follows a Poisson distribution with parameter  $\nu(B)$ :
- 2. for disjoint sets  $B_i$ ,  $i \le n$ , the variables  $\mu(B_i)$ ,  $i \leq n$  are independent.

## Point Processes

Let  $(E, \mathcal{E})$  be a measurable space and  $\delta$  an additional point. We set  $E_{\delta} = E \cup \delta$ ,  $\mathcal{E}_{\delta} = \sigma(\mathcal{E}, \{\delta\})$ .

**Definition 1** Let **e** be a stochastic process defined on a probability space  $(\Omega, \mathcal{F}, P)$ , taking values in  $(E_{\delta}, \mathcal{E}_{\delta})$ . The process **e** is a point process if

- 1. the map  $(t,\omega) \to \mathbf{e}_t(\omega)$  is  $\mathcal{B}([0,\infty[) \otimes \mathcal{F}$ measurable:
- 2. *the set*  $D_{\omega} = \{t : \mathbf{e}_t(\omega) \neq \delta\}$  *is a.s. countable.*

For every measurable set B of  $]0, \infty[ \times E]$ , we set

$$N^{B}(\omega) := \sum_{s \ge 0} \mathbb{1}_{B}(s, \mathbf{e}_{s}(\omega)) \tag{19}$$

In particular, if  $B = [0, t] \times \Gamma$ , we write

$$N_t^{\Gamma} = N^B = \text{Card}\{s \le t : \mathbf{e}(s) \in \Gamma\}$$
(20)

# Poisson Point Processes

**Definition 2** An  $\mathbf{F}$ -Poisson point process  $\mathbf{e}$  is a point process such that

- 1.  $N_t^E < \infty$  a.s. for every t
- 2. for any  $\Gamma \in \mathcal{E}$ , the process  $N^{\Gamma}$  is **F**-adapted
- 3. for any s and t and any  $\Gamma \in \mathcal{E}$ ,  $N_{s+t}^{\Gamma} N_t^{\Gamma}$  is independent from  $\mathcal{F}_t$  and distributed as  $N_s^{\Gamma}$ .

In particular, for any disjoint family  $(\Gamma_i,$  $i = 1, \ldots, d$ ), the *d*-dimensional process  $(N_t^{\Gamma_i}, i =$  $1, \dots, d$ ) is a Poisson process.

**Definition 3** *The*  $\sigma$ *-finite measure on*  $\mathcal{E}$  *defined by* 

$$\mathbf{n}(\Gamma) = \frac{1}{t} \mathbb{E}(N_t^{\Gamma}) \tag{21}$$

is called the characteristic measure of  $\mathbf{e}$ .

If  $\mathbf{n}(\Gamma) < \infty$ , the process  $N_t^{\Gamma} - t\mathbf{n}(\Gamma)$  is an F-martingale.

## **Proposition 1** (*Compensation Formula*).

Let  $H$  be a measurable positive process vanishing at  $\delta$ . Then

$$\mathbb{E}\left[\sum_{s\geq 0} H(s,\omega,\mathbf{e}_s(\omega))\right]$$
$$= \mathbb{E}\left[\int_0^\infty \mathrm{d}s \int H(s,\omega,u)\mathbf{n}(\mathrm{d}u)\right] \quad (22)$$

If, for any t,  $\mathbb{E}\left[\int_0^t \mathrm{d}s \int H(s,\omega,u)\mathbf{n}(\mathrm{d}u)\right] < \infty$ , the process

$$\sum_{s \le t} H(s, \omega, \mathbf{e}_s(\omega)) - \int_0^t \mathrm{d}s \int H(s, \omega, u) \mathbf{n}(\mathrm{d}u) \tag{23}$$

is a martingale.

## **Proposition 2** (*Exponential Formula*).

If  $f$  is a measurable function such that  $\int_0^t ds \int |f(s, u)| \mathbf{n}(\mathrm{d}u) < \infty$  for every t, then,

$$\mathbb{E}\left[\exp\left(i\sum_{0< s\leq t}f(s,\mathbf{e}_s)\right)\right]$$
$$=\exp\left(\int_0^t\mathrm{d}s\int(\mathrm{e}^{if(s,u)}-1)\mathbf{n}(\mathrm{d}u)\right) \quad (24)$$

*Moreover, if*  $f \ge 0$ ,

$$\mathbb{E}\left[\exp\left(-\sum_{0 < s \le t} f(s, \mathbf{e}_s)\right)\right]$$
$$= \exp\left(-\int_0^t \mathrm{d}s \int (1 - \mathrm{e}^{-f(s,u)}) \mathbf{n}(\mathrm{d}u)\right) \tag{25}$$

### References

- [1] Cont, R. & Tankov, P. (2004). Financial Modeling with Jump Processes, Chapman & Hall/CRC.
- [2] Dellacherie, C. & Meyer, P.-A. (1980). Probabilités et Potentiel, chapitres, Hermann, Paris, Chapter V-VIII. English translation (1982), Probabilities and Potentiel Chapters V-VIII, North-Holland.

- [3] Jacod, J. & Shiryaev, A.N. (2003). *Limit Theorems for Stochastic Processes*, 2nd Edition, Springer Verlag.
- [4] Last, G. & Brandt, A. (1995). *Marked Point Processes on the Real Line. The Dynamic Approach*, Springer, Berlin.
- [5] Protter, P.E. (2005). *Stochastic Integration and Differential Equations*, 2nd Edition, Springer, Berlin.

**Related Articles**

**Levy Processes ´** ; **Martingales**; **Martingale Representation Theorem**.

MONIQUE JEANBLANC