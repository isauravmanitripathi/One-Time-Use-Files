<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
 </head>
 <body>
  <h1>
   <b>
    Point Processes
   </b>
  </h1>
  <p block-type="Text">
   This article gives a brief overview of general point processes. We refer to the books
   <math display="inline">
    [1-5]
   </math>
   , for proofs and advanced results.
  </p>
  <h1>
   <b>
    Marked Point Processes
   </b>
  </h1>
  <h2>
   Definition
  </h2>
  <p block-type="Text">
   An increasing sequence of random times is called a univariate point process. A simple example is the Poisson process.
  </p>
  <p block-type="TextInlineMath">
   Given a univariate point process, we associate to every time
   <math display="inline">
    T_n
   </math>
   a mark
   <math display="inline">
    Z_n
   </math>
   . More precisely, let
   <math display="inline">
    (\Omega, \mathcal{F}, \mathbb{P})
   </math>
   be a probability space,
   <math display="inline">
    (Z_n, n \ge 1)
   </math>
   a sequence of random variables taking values in a measurable space
   <math display="inline">
    (E, \mathcal{E})
   </math>
   , and
   <math display="inline">
    (T_n, n \ge 1)
   </math>
   an increasing sequence of nonnegative random variables. We assume that
   <math display="inline">
    \lim T_n = \infty
   </math>
   , so that there is only a finite number of
   <i>
    n
   </i>
   such that, for a given
   <i>
    t
   </i>
   , one has
   <math display="inline">
    T_n \le t
   </math>
   . We define the process
   <math display="inline">
    N
   </math>
   as follows. For each set,
   <math display="inline">
    A \in \mathcal{E}, N_t(A) = \sum_n \mathbb{1}_{\{T_n \le t\}} \mathbb{1}_{\{Z_n \in A\}}
   </math>
   is the number of "marks" in the set
   <math display="inline">
    A
   </math>
   before time
   <math display="inline">
    t
   </math>
   . The natural filtration of
   <math display="inline">
    N
   </math>
   is
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathcal{F}_t^{\mathbf{N}} = \sigma(N_s(A), s \le t, A \in \mathcal{E}) \tag{1}
   </math>
  </p>
  <p block-type="Text">
   The predictable
   <math display="inline">
    \sigma
   </math>
   -algebra
   <math display="inline">
    \mathcal{P}
   </math>
   is the
   <math display="inline">
    \sigma
   </math>
   -algebra defined on
   <math display="inline">
    \Omega \times \mathbb{R}^+
   </math>
   that is generated by the sets
  </p>
  <p block-type="Equation">
   <math display="block">
    A \times \{0\}, \ A \in \mathcal{F}_0^{\mathbf{N}}; \quad A \times ]s, t], \ A \in \mathcal{F}_s^{\mathbf{N}}, \ s \le t
   </math>
   <math display="block">
    (2)
   </math>
  </p>
  <p block-type="Text">
   The associated random counting measure
   <math display="inline">
    \mu(\omega)
   </math>
   , ds, dz) is defined as follows: let
   <math display="inline">
    \Phi
   </math>
   be a map
  </p>
  <p block-type="Equation">
   <math display="block">
    (t,\omega,z) \in (\mathbb{R}^+, \Omega, E) \to \Phi(t,\omega,z) \in \mathbb{R} \tag{3}
   </math>
  </p>
  <p block-type="Text">
   We set
  </p>
  <p block-type="Equation">
   <math display="block">
    \int_{]0,t]} \int_{E} \Phi(s,z) \mu(\mathrm{d}s,\mathrm{d}z) = \sum_{n=1}^{\infty} \Phi(T_n,Z_n) \mathbb{1}_{\{T_n \le t\}}
   </math>
   <math display="block">
    = \sum_{n=1}^{N_t(E)} \Phi(T_n,Z_n) \qquad (4)
   </math>
  </p>
  <p block-type="Text">
   The process
   <math display="inline">
    N
   </math>
   is called a
   <i>
    marked point process
   </i>
   . This is a generalization of the compound Poisson process: we have introduced, in particular, a spatial dimension for the size of jumps, which are no more i.i.d. random variables.
  </p>
  <p block-type="TextInlineMath">
   A map
   <math display="inline">
    \Phi
   </math>
   is predictable if it is
   <math display="inline">
    \mathcal{P} \otimes \mathcal{E}
   </math>
   measurable. The
   <i>
    compensator
   </i>
   of the marked point process
   <math display="inline">
    N
   </math>
   is the unique predictable random measure
   <math display="inline">
    \nu
   </math>
   on (
   <math display="inline">
    \mathbb{R}^+ \times
   </math>
   <math display="inline">
    E, \mathcal{G} \otimes \mathcal{E}
   </math>
   ) such that, for every bounded predictable process
   <math display="inline">
    \Phi
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\left(\int_{0}^{t} \int_{E} \Phi(s, z; \omega) \mu(\omega; \mathrm{d}s, \mathrm{d}z)\right)
   </math>
   <math display="block">
    = \mathbb{E}\left(\int_{0}^{t} \int_{E} \Phi(s, z; \omega) \nu(\omega; \mathrm{d}s, \mathrm{d}z)\right) \quad (5)
   </math>
  </p>
  <p block-type="TextInlineMath">
   In the case of a marked point process on
   <math display="inline">
    \mathbb{R} \times \mathbb{R}^d
   </math>
   , the compensator admits an explicit representation: let
   <math display="inline">
    G_n(\mathrm{d}t,\mathrm{d}z)
   </math>
   be a regular version of the conditional distribution of
   <math display="inline">
    (T_{n+1}, Z_{n+1})
   </math>
   with respect to
   <math display="inline">
    \mathcal{F}_{T_n}^N =
   </math>
   <math display="inline">
    \sigma\{(T_1, Z_1), \ldots (T_n, Z_n)\}
   </math>
   . Then,
  </p>
  <p block-type="Equation">
   <math display="block">
    \nu(\mathrm{d}t,\mathrm{d}z) = \sum_{n} \mathbbm{1}_{\{T_n &lt; t \le T_{n+1}\}} \frac{G_n(\mathrm{d}t,\mathrm{d}z)}{G_n([t,\infty[\times\mathbb{R}^d])} \quad (6)
   </math>
  </p>
  <h1>
   Intensity Process
  </h1>
  <p block-type="TextInlineMath">
   In what follows, we assume that, for any
   <math display="inline">
    A \in \mathcal{E}
   </math>
   , the process
   <math display="inline">
    (N_t(A), t \ge 0)
   </math>
   admits the
   <b>
    F
   </b>
   -predictable intensity
   <math display="inline">
    (\lambda_t(A), t \ge 0)
   </math>
   , that is, there exists a nonnegative process
   <math display="inline">
    (\lambda_t(A), t &gt; 0)
   </math>
   such that
  </p>
  <p block-type="Equation">
   <math display="block">
    N_t(A) - \int_0^t \lambda_s(A) \mathrm{d}s \tag{7}
   </math>
  </p>
  <p block-type="TextInlineMath">
   is an
   <b>
    F
   </b>
   - martingale. Then, if
   <math display="inline">
    X_t = \sum_{n=1}^{N_t(E)} \Phi(T_n, Z_n)
   </math>
   where
   <math display="inline">
    \Phi
   </math>
   is an
   <b>
    F
   </b>
   -predictable process that satisfies
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\left(\int_{]0,t]}\int_{E}|\Phi(s,z)|\lambda_{s}(\mathrm{d}z)\mathrm{d}s\right)&lt;\infty\qquad(8)
   </math>
  </p>
  <p block-type="Text">
   the process
  </p>
  <p block-type="Equation">
   <math display="block">
    X_{t} - \int_{0}^{t} \int_{E} \Phi(s, z) \lambda_{s}(\mathrm{d}z) \mathrm{d}s
   </math>
   <br/>
   =
   <math display="block">
    \int_{]0, t]} \int_{E} \Phi(s, z) \left[ \mu(\mathrm{d}s, \mathrm{d}z) - \lambda_{s}(\mathrm{d}z) \mathrm{d}s \right] \qquad (9)
   </math>
  </p>
  <p block-type="Text">
   is a martingale and, in particular,
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\left(\int_{]0,t]} \int_{E} \Phi(s,z)\mu(\mathrm{d}s,\mathrm{d}z)\right)
   </math>
   <math display="block">
    =\mathbb{E}\left(\int_{]0,t]} \int_{E} \Phi(s,z)\lambda_{s}(\mathrm{d}z)\mathrm{d}s\right) \qquad (10)
   </math>
  </p>
  <p block-type="TextInlineMath">
   The random measure
   <math display="inline">
    \mu(ds, dz) - \lambda_s(dz)ds
   </math>
   is the compensated measure of
   <math display="inline">
    \mu
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Example
   </b>
   Compound Poisson Process. Let
   <math display="inline">
    X_t =
   </math>
   <math display="inline">
    \sum_{n=1}^{N_t} Y_n
   </math>
   be a
   <math display="inline">
    (\lambda, F)
   </math>
   -compound Poisson process. We can consider the
   <math display="inline">
    Y_n
   </math>
   s as marks and introduce the marked point process
   <math display="inline">
    N_t(A) = \sum_{n=1}^{N_t} 1_{Y_n \in A}
   </math>
   . For any A, the process
   <math display="inline">
    (N_t(A), t \ge 0)
   </math>
   is a compound Poisson process, and
   <math display="inline">
    (N_t(A) - \lambda t P(Y_1 \in A), t \ge 0)
   </math>
   is a martingale. The intensity of the marked point process N is
   <math display="inline">
    \lambda_t(\mathrm{d}z) = \lambda F(\mathrm{d}z)
   </math>
   . Moreover, if
   <math display="inline">
    A_i
   </math>
   are disjoint sets, the processes
   <math display="inline">
    N(A_i)
   </math>
   are independent. The counting random measure
   <math display="inline">
    \mu
   </math>
   satisfies
  </p>
  <p block-type="Equation">
   <math display="block">
    \int_0^t \int_{\mathbb{R}} f(x) \mu(\omega; \mathrm{d}s, \mathrm{d}x) = \sum_{k=1}^{N_t} f(Y_k) \tag{11}
   </math>
  </p>
  <p block-type="Text">
   and we obtain, in particular, that, as in the article on Poisson processes (see Poisson Process)
  </p>
  <p block-type="Equation">
   <math display="block">
    M_t^f = \int_0^t \int_{\mathbb{R}} f(x) (\mu(\omega; \mathrm{d}s, \mathrm{d}x) - \mathrm{d}s \,\lambda F(\mathrm{d}x)) \tag{12}
   </math>
  </p>
  <p block-type="Text">
   is a martingale.
  </p>
  <h1>
   Predictable Representation Property
  </h1>
  <p block-type="TextInlineMath">
   Let
   <math display="inline">
    \mathbf{F}^{\mathbf{N}}
   </math>
   be the filtration generated by the marked point process with intensity
   <math display="inline">
    \lambda_s(dz)
   </math>
   . Then, any
   <math display="inline">
    (\mathbb{P}, \mathbf{F}^N)
   </math>
   martingale
   <math display="inline">
    M
   </math>
   admits the representation
  </p>
  <p block-type="Equation">
   <math display="block">
    M_t = M_0 + \int_0^t \int_E \Phi(s, x) (\mu(\mathrm{d}s, \mathrm{d}x) - \lambda_s(\mathrm{d}x) \mathrm{d}s) \tag{13}
   </math>
  </p>
  <p block-type="Text">
   where
   <math display="inline">
    \Phi
   </math>
   is a
   <math display="inline">
    \mathbf{F}^{\mathbf{N}}
   </math>
   -predictable process such that
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\left(\int_{0}^{t} \int_{E} |\Phi(s,x)| \lambda_{s}(\mathrm{d}x) \mathrm{d}s\right) &lt; \infty \tag{14}
   </math>
  </p>
  <h2>
   Change of Probability Measure
  </h2>
  <p block-type="TextInlineMath">
   Let
   <math display="inline">
    \mu
   </math>
   be the random measure of a marked point process with intensity
   <math display="inline">
    \lambda_t(A) = \alpha_t m_t(A)
   </math>
   , where m is a probability measure. We shall say that the marked point process admits
   <math display="inline">
    (\alpha_t, m_t(\text{d}z))
   </math>
   as P-local characteristics. Let
   <math display="inline">
    (\psi_t, h_t(z))
   </math>
   be two predictable positive processes such that
  </p>
  <p block-type="Equation">
   <math display="block">
    \int_0^t \psi_s \alpha_s \mathrm{d}s &lt; \infty, \ \int_E h_t(z) m_t(\mathrm{d}z) = 1 \qquad (15)
   </math>
  </p>
  <p block-type="Text">
   Let
   <math display="inline">
    L
   </math>
   be the solution of
  </p>
  <p block-type="Equation">
   <math display="block">
    dL_{t} = L_{t^{-}} \int_{E} (\psi_{t} h_{t}(z) - 1)(\mu(\mathrm{d}t, \mathrm{d}z)
   </math>
   <math display="block">
    - \alpha_{t} m_{t}(\mathrm{d}z) \mathrm{d}t), \ L_{0} = 1 \tag{16}
   </math>
  </p>
  <p block-type="TextInlineMath">
   If
   <math display="inline">
    \mathbb{E}(L_t) = 1
   </math>
   (so that L is a martingale), setting
   <math display="inline">
    \mathbb{Q}|_{\mathcal{F}_t} = L_t \mathbb{P}|_{\mathcal{F}_t}
   </math>
   , the marked point process has the
   <math display="inline">
    \mathbb{Q}
   </math>
   local characteristics
   <math display="inline">
    (\psi_t \alpha_t, h_t(z) m_t(dz)).
   </math>
  </p>
  <p block-type="Text">
   Example Compound Poisson Process. The change of measure for compound Poisson processes can be written in terms of random measures. Let
  </p>
  <p block-type="Equation">
   <math display="block">
    L_{t} = \exp\left(\int_{\mathbb{R}} f(x)N_{t}(\mathrm{d}x) - t\lambda \int_{-\infty}^{\infty} (e^{f(x)} - 1)F(\mathrm{d}x)\right)
   </math>
   <math display="block">
    = \exp\left(\int_{0}^{t} \int_{\mathbb{R}} f(x)\mu(\mathrm{d}s, \mathrm{d}x) - t \int_{-\infty}^{\infty} (e^{f(x)} - 1)\lambda F(\mathrm{d}x)\right) \qquad (17)
   </math>
  </p>
  <p block-type="TextInlineMath">
   be a martingale. Define
   <math display="inline">
    d\mathbb{Q}|_{\mathcal{F}_t} = L_t d\mathbb{P}|_{\mathcal{F}_t}
   </math>
   . Then,
  </p>
  <p block-type="Equation">
   <math display="block">
    \int_0^t \int_{\mathbb{R}} (\mu(\mathrm{d}s, \mathrm{d}x) - \mathrm{d}s \, e^{f(x)} \lambda F(\mathrm{d}x)) \tag{18}
   </math>
  </p>
  <p block-type="Text">
   is a
   <math display="inline">
    \mathbb{Q}
   </math>
   -martingale as obtained in the article on Poisson processes (see Poisson Process).
  </p>
  <h1>
   <b>
    Poisson Point Processes
   </b>
  </h1>
  <h4>
   Poisson Measures
  </h4>
  <p block-type="TextInlineMath">
   Let
   <math display="inline">
    (E, \mathcal{E})
   </math>
   be a measurable space. A random measure
   <math display="inline">
    \mu
   </math>
   on
   <math display="inline">
    (E, \mathcal{E})
   </math>
   is a Poisson measure with intensity
   <math display="inline">
    \nu
   </math>
   , where
   <math display="inline">
    \nu
   </math>
   is a
   <math display="inline">
    \sigma
   </math>
   -finite measure on
   <math display="inline">
    (E, \mathcal{E})
   </math>
   , if
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     1. for every set
     <math display="inline">
      B \in \mathcal{E}
     </math>
     with
     <math display="inline">
      \nu(B) &lt; \infty
     </math>
     ,
     <math display="inline">
      \mu(B)
     </math>
     follows a Poisson distribution with parameter
     <math display="inline">
      \nu(B)
     </math>
     :
    </li>
    <li block-type="ListItem">
     2. for disjoint sets
     <math display="inline">
      B_i
     </math>
     ,
     <math display="inline">
      i \le n
     </math>
     , the variables
     <math display="inline">
      \mu(B_i)
     </math>
     ,
     <math display="inline">
      i \leq n
     </math>
     are independent.
    </li>
   </ul>
  </p>
  <h2>
   Point Processes
  </h2>
  <p block-type="TextInlineMath">
   Let
   <math display="inline">
    (E, \mathcal{E})
   </math>
   be a measurable space and
   <math display="inline">
    \delta
   </math>
   an additional point. We set
   <math display="inline">
    E_{\delta} = E \cup \delta
   </math>
   ,
   <math display="inline">
    \mathcal{E}_{\delta} = \sigma(\mathcal{E}, \{\delta\})
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   <b>
    Definition 1
   </b>
   Let
   <b>
    e
   </b>
   be a stochastic process defined on a probability space
   <math display="inline">
    (\Omega, \mathcal{F}, P)
   </math>
   , taking values in
   <math display="inline">
    (E_{\delta}, \mathcal{E}_{\delta})
   </math>
   . The process
   <b>
    e
   </b>
   is a point process if
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     1. the map
     <math display="inline">
      (t,\omega) \to \mathbf{e}_t(\omega)
     </math>
     is
     <math display="inline">
      \mathcal{B}([0,\infty[) \otimes \mathcal{F}
     </math>
     measurable:
    </li>
    <li block-type="ListItem">
     2.
     <i>
      the set
     </i>
     <math display="inline">
      D_{\omega} = \{t : \mathbf{e}_t(\omega) \neq \delta\}
     </math>
     <i>
      is a.s. countable.
     </i>
    </li>
   </ul>
  </p>
  <p block-type="TextInlineMath">
   For every measurable set B of
   <math display="inline">
    ]0, \infty[ \times E]
   </math>
   , we set
  </p>
  <p block-type="Equation">
   <math display="block">
    N^{B}(\omega) := \sum_{s \ge 0} \mathbb{1}_{B}(s, \mathbf{e}_{s}(\omega)) \tag{19}
   </math>
  </p>
  <p block-type="TextInlineMath">
   In particular, if
   <math display="inline">
    B = [0, t] \times \Gamma
   </math>
   , we write
  </p>
  <p block-type="Equation">
   <math display="block">
    N_t^{\Gamma} = N^B = \text{Card}\{s \le t : \mathbf{e}(s) \in \Gamma\}
   </math>
   (20)
  </p>
  <h1>
   Poisson Point Processes
  </h1>
  <p block-type="Text">
   <b>
    Definition 2
   </b>
   An
   <math display="inline">
    \mathbf{F}
   </math>
   -Poisson point process
   <math display="inline">
    \mathbf{e}
   </math>
   is a point process such that
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     1.
     <math display="inline">
      N_t^E &lt; \infty
     </math>
     a.s. for every t
    </li>
    <li block-type="ListItem">
     2. for any
     <math display="inline">
      \Gamma \in \mathcal{E}
     </math>
     , the process
     <math display="inline">
      N^{\Gamma}
     </math>
     is
     <b>
      F
     </b>
     -adapted
    </li>
    <li block-type="ListItem">
     3. for any s and t and any
     <math display="inline">
      \Gamma \in \mathcal{E}
     </math>
     ,
     <math display="inline">
      N_{s+t}^{\Gamma}  N_t^{\Gamma}
     </math>
     is independent from
     <math display="inline">
      \mathcal{F}_t
     </math>
     and distributed as
     <math display="inline">
      N_s^{\Gamma}
     </math>
     .
    </li>
   </ul>
  </p>
  <p block-type="TextInlineMath">
   In particular, for any disjoint family
   <math display="inline">
    (\Gamma_i,
   </math>
   <math display="inline">
    i = 1, \ldots, d
   </math>
   ), the
   <i>
    d
   </i>
   -dimensional process
   <math display="inline">
    (N_t^{\Gamma_i}, i =
   </math>
   <math display="inline">
    1, \dots, d
   </math>
   ) is a Poisson process.
  </p>
  <p block-type="Text">
   <b>
    Definition 3
   </b>
   <i>
    The
   </i>
   <math display="inline">
    \sigma
   </math>
   <i>
    -finite measure on
   </i>
   <math display="inline">
    \mathcal{E}
   </math>
   <i>
    defined by
   </i>
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbf{n}(\Gamma) = \frac{1}{t} \mathbb{E}(N_t^{\Gamma}) \tag{21}
   </math>
  </p>
  <p block-type="Text">
   is called the characteristic measure of
   <math display="inline">
    \mathbf{e}
   </math>
   .
  </p>
  <p block-type="TextInlineMath">
   If
   <math display="inline">
    \mathbf{n}(\Gamma) &lt; \infty
   </math>
   , the process
   <math display="inline">
    N_t^{\Gamma} - t\mathbf{n}(\Gamma)
   </math>
   is an F-martingale.
  </p>
  <h2>
   <b>
    Proposition 1
   </b>
   (
   <i>
    Compensation Formula
   </i>
   ).
  </h2>
  <p block-type="Text">
   Let
   <math display="inline">
    H
   </math>
   be a measurable positive process vanishing at
   <math display="inline">
    \delta
   </math>
   . Then
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\left[\sum_{s\geq 0} H(s,\omega,\mathbf{e}_s(\omega))\right]
   </math>
   <math display="block">
    = \mathbb{E}\left[\int_0^\infty \mathrm{d}s \int H(s,\omega,u)\mathbf{n}(\mathrm{d}u)\right] \quad (22)
   </math>
  </p>
  <p block-type="TextInlineMath">
   If, for any t,
   <math display="inline">
    \mathbb{E}\left[\int_0^t \mathrm{d}s \int H(s,\omega,u)\mathbf{n}(\mathrm{d}u)\right] &lt; \infty
   </math>
   , the process
  </p>
  <p block-type="Equation">
   <math display="block">
    \sum_{s \le t} H(s, \omega, \mathbf{e}_s(\omega)) - \int_0^t \mathrm{d}s \int H(s, \omega, u) \mathbf{n}(\mathrm{d}u) \tag{23}
   </math>
  </p>
  <p block-type="Text">
   is a martingale.
  </p>
  <h2>
   <b>
    Proposition 2
   </b>
   (
   <i>
    Exponential Formula
   </i>
   ).
  </h2>
  <p block-type="TextInlineMath">
   If
   <math display="inline">
    f
   </math>
   is a measurable function such that
   <math display="inline">
    \int_0^t ds \int |f(s, u)| \mathbf{n}(\mathrm{d}u) &lt; \infty
   </math>
   for every t, then,
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\left[\exp\left(i\sum_{0&lt; s\leq t}f(s,\mathbf{e}_s)\right)\right]
   </math>
   <math display="block">
    =\exp\left(\int_0^t\mathrm{d}s\int(\mathrm{e}^{if(s,u)}-1)\mathbf{n}(\mathrm{d}u)\right) \quad (24)
   </math>
  </p>
  <p block-type="TextInlineMath">
   <i>
    Moreover, if
   </i>
   <math display="inline">
    f \ge 0
   </math>
   ,
  </p>
  <p block-type="Equation">
   <math display="block">
    \mathbb{E}\left[\exp\left(-\sum_{0 &lt; s \le t} f(s, \mathbf{e}_s)\right)\right]
   </math>
   <math display="block">
    = \exp\left(-\int_0^t \mathrm{d}s \int (1 - \mathrm{e}^{-f(s,u)}) \mathbf{n}(\mathrm{d}u)\right) \tag{25}
   </math>
  </p>
  <h3>
   References
  </h3>
  <p block-type="ListGroup" class="has-continuation">
   <ul>
    <li block-type="ListItem">
     [1] Cont, R. &amp; Tankov, P. (2004). Financial Modeling with Jump Processes, Chapman &amp; Hall/CRC.
    </li>
    <li block-type="ListItem">
     [2] Dellacherie, C. &amp; Meyer, P.-A. (1980). Probabilités et Potentiel, chapitres, Hermann, Paris, Chapter V-VIII. English translation (1982), Probabilities and Potentiel Chapters V-VIII, North-Holland.
    </li>
   </ul>
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     [3] Jacod, J. &amp; Shiryaev, A.N. (2003).
     <i>
      Limit Theorems for Stochastic Processes
     </i>
     , 2nd Edition, Springer Verlag.
    </li>
    <li block-type="ListItem">
     [4] Last, G. &amp; Brandt, A. (1995).
     <i>
      Marked Point Processes on the Real Line. The Dynamic Approach
     </i>
     , Springer, Berlin.
    </li>
    <li block-type="ListItem">
     [5] Protter, P.E. (2005).
     <i>
      Stochastic Integration and Differential Equations
     </i>
     , 2nd Edition, Springer, Berlin.
    </li>
   </ul>
  </p>
  <p block-type="Text">
   <b>
    Related Articles
   </b>
  </p>
  <p block-type="Text">
   <b>
    Levy Processes ´
   </b>
   ;
   <b>
    Martingales
   </b>
   ;
   <b>
    Martingale Representation Theorem
   </b>
   .
  </p>
  <p block-type="Text">
   MONIQUE JEANBLANC
  </p>
 </body>
</html>
