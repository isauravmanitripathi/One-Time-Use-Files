<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
 </head>
 <body>
  <h1>
   <b>
    Risk Measures: Statistical Estimation
   </b>
  </h1>
  <p block-type="Text">
   The recent interest in the estimation of risk measures is explained by changes in regulations in finance and insurance industries [4]. Ten years ago, the regulation was applied to a rather limited scope of assets and firms and only consisted in fixing minimal reserve level to hedge risky investments. However, these levels were computed without clear reference to the underlying risk. The new regulations, known as
   <i>
    Basel 2
   </i>
   for the finance industry and
   <i>
    Solvency 2
   </i>
   for the insurance industry, have proposed to account for risk in computing the reserves (Pillar 1). They also insist on the need for introduction of internal models by banks or insurance companies to follow their risk (Pillar 2) and on transparency (Pillar 3). This is a coherent program, which concerns risk modeling as well as the creation or the improvement of databases, and has to account for the heterogeneous technological level in these industries. In this article, we focus on risk measures, their computation, and updating.
  </p>
  <p block-type="TextInlineMath">
   In the current implementation of Basel 2 and Solvency 2, the risk measure suggested by regulators and generally retained by firms is the Value-at-Risk (VaR). This measure has several drawbacks, but has the advantage of being easily understood by practitioners. It can be presented as follows. Let us consider a given portfolio of assets. This portfolio can concern stocks, corporate bonds, consumer loans, or life insurance contracts. In practice, it corresponds to a business line of a bank, a credit institution, or an insurance company. The value of this portfolio at date
   <i>
    t
   </i>
   is denoted by
   <i>
    Wt
   </i>
   , but at this date its future values
   <i>
    Wt
   </i>
   <sup>
    +
   </sup>
   <i>
    <sup>
     h
    </sup>
   </i>
   are unknown.a To hedge this uncertainty, some reserves
   <i>
    R
   </i>
   are introduced. With these reserves, the future portfolio value increases to
   <i>
    Wt
   </i>
   <sup>
    +
   </sup>
   <i>
    <sup>
     h
    </sup>
   </i>
   +
   <i>
    R
   </i>
   , which diminishes the potential loss. Let us fix a probability of loss
   <i>
    α
   </i>
   = 1
   <i>
    ,
   </i>
   5, or 10%, say; then, the reserve level can be chosen such that
  </p>
  <p block-type="Equation">
   <math display="block">
    P_t[W_{t+h} + R &lt; 0] = \alpha \tag{1}
   </math>
  </p>
  <p block-type="TextInlineMath" class="has-continuation">
   where
   <i>
    Pt
   </i>
   denotes the probability given the information available at time
   <i>
    t
   </i>
   . By solving equation (1), we see that the reserve level is the opposite of the
   <i>
    α
   </i>
   - quantile of the distribution of the future portfolio value. It depends on the selected loss probability
  </p>
  <p block-type="Text">
   <i>
    α
   </i>
   , investment horizon
   <i>
    h
   </i>
   , date
   <i>
    t
   </i>
   , information available at this date, and the set of selected assets. It can be denoted by
   <i>
    R(t, h
   </i>
   ;
   <i>
    α)
   </i>
   and is written in a monetary unit as the dollar or the euro. For the determination of reserves, the admissible sets of assets, the level
   <i>
    α
   </i>
   , the horizon
   <i>
    h
   </i>
   , and the date of computations are imposed by the regulators. Other values can be selected by firms for internal use, especially for fixing and reallocating the so-called economic capital.
  </p>
  <p block-type="Text">
   However, the portfolio value
   <i>
    (Wt)
   </i>
   generally features a nonstationary evolution, which can render difficulty in the determination of
   <i>
    R
   </i>
   . To circumvent this difficulty, it has been proposed to introduce the notion of VaR defined as
  </p>
  <p block-type="Equation">
   <math display="block">
    VaR(t, h; \alpha) = R(t, h; \alpha) + W_t \tag{2}
   </math>
  </p>
  <p block-type="Text">
   Thus, the VaR defined as
  </p>
  <p block-type="Equation">
   <math display="block">
    P_t[W_{t+h} - W_t &lt; -VaR(t, h; \alpha)] = \alpha \qquad (3)
   </math>
  </p>
  <p block-type="Text">
   is the opposite of the conditional
   <i>
    α
   </i>
   -quantile of the change in portfolio value
   <i>
    (Wt
   </i>
   <sup>
    +
   </sup>
   <i>
    <sup>
     h
    </sup>
   </i>
   −
   <i>
    Wt)
   </i>
   , which is a much more stationary process.b This definition highlights the importance of the (conditional) quantile function for building risk measures.
  </p>
  <p block-type="Text">
   In the following section, we discuss properties that are suitable for risk measures. This allows to define a large class of risk measures, called
   <i>
    distortion risk measure
   </i>
   s (
   <i>
    DRM
   </i>
   s), which is flexible and includes the VaR as a special case. In the section Nonparametric Estimation in the IID Framework, we consider the estimation of DRMs, when the portfolio returns are independent of the past and identically distributed (IID). Under the IID assumption, the estimated risk measures have simple expressions in terms of returns, and it is easy to estimate their accuracy. These simple computations, which involve only a ranking of returns plus some averaging, explains the success of this practice, called
   <i>
    historical simulation
   </i>
   .
  </p>
  <p block-type="Text">
   Nevertheless, the IID assumption is not realistic (
   <i>
    see
   </i>
   <b>
    Stylized Properties of Asset Returns
   </b>
   ). For instance, it would be preferable to account for volatility persistence, for cycle effects, and so on. The introduction of serial dependences when computing and analyzing conditional risk measures is not an easy task and is only in its infancy for regulation purposes. Finally, we discuss the validation of the approaches used to compute the reserves and the coherent definitions of reserves for several business lines.
  </p>
  <h1>
   <b>
    Risk Measures
   </b>
  </h1>
  <p block-type="Text">
   First, we discuss the construction and the comparison of risk measures for a given date and a given horizon. For this reason, we do not indicate indexes
   <i>
    t
   </i>
   and
   <i>
    h
   </i>
   . Two axiomatic theories have been introduced in the literature to construct risk measures.
  </p>
  <h4>
   1.
   <b>
    Coherent risk measures
   </b>
  </h4>
  <p block-type="Text">
   The first constructive approach to evaluate the capital requirement was proposed by Artzner
   <i>
    et al.
   </i>
   [2].
   <i>
    R(W )
   </i>
   denotes the required reserve amount for a portfolio
   <i>
    W
   </i>
   , that is, for the future portfolio value
   <i>
    Wt
   </i>
   +
   <i>
    h.
   </i>
  </p>
  <p block-type="Text">
   The axioms are as follows:
  </p>
  <p block-type="Text">
   Distribution dependence:
   <i>
    R(W )
   </i>
   depends only on the distribution of
   <i>
    W
   </i>
   .
  </p>
  <p block-type="TextInlineMath">
   Monotonicity: If
   <i>
    W
   </i>
   is more risky than
   <i>
    W
   </i>
   <sup>
    ∗
   </sup>
   by the stochastic dominance
   <sup>
    c
   </sup>
   of order 1, then
   <i>
    R(W )
   </i>
   ≥
   <i>
    R(W
   </i>
   <sup>
    ∗
   </sup>
   <i>
    )
   </i>
   .
  </p>
  <p block-type="TextInlineMath">
   Drift invariance:
   <i>
    R(W
   </i>
   +
   <i>
    c)
   </i>
   =
   <i>
    R(W )
   </i>
   −
   <i>
    c
   </i>
   , for any
   <i>
    W
   </i>
   and any deterministic
   <i>
    c
   </i>
   .
  </p>
  <p block-type="TextInlineMath">
   Positive homogeneity:
   <i>
    R(λW )
   </i>
   =
   <i>
    λR(W )
   </i>
   , for any
   <i>
    W
   </i>
   and any nonnegative scalar
   <i>
    λ
   </i>
   .
  </p>
  <p block-type="TextInlineMath">
   Subadditivity:
   <i>
    R(W
   </i>
   +
   <i>
    W
   </i>
   <sup>
    ∗
   </sup>
   <i>
    )
   </i>
   ≤
   <i>
    R(W )
   </i>
   +
   <i>
    R(W
   </i>
   <sup>
    ∗
   </sup>
   <i>
    )
   </i>
   , for any
   <i>
    W
   </i>
   and
   <i>
    W
   </i>
   <sup>
    ∗
   </sup>
   .
  </p>
  <p block-type="Text">
   Note that the homogeneity and subadditivity properties imply the convexity of the coherent risk measure (
   <i>
    see
   </i>
   <b>
    Convex Risk Measures
   </b>
   ).
  </p>
  <h4>
   2.
   <b>
    The Wang axioms
   </b>
  </h4>
  <p block-type="Text">
   The next set of axioms were introduced in a series of papers by Wang and Young [27], for the purpose of analyzing losses in insurance. Thus, we restrict ourselves to losses that are negative
   <i>
    W
   </i>
   . The axioms are as follows:
  </p>
  <p block-type="Text">
   Distribution dependence:
   <i>
    R(W )
   </i>
   depends on the distribution of
   <i>
    W
   </i>
   only.
  </p>
  <p block-type="TextInlineMath">
   Positivity:
   <i>
    R(W )
   </i>
   ≥ 0
   <i>
    .
   </i>
  </p>
  <p block-type="TextInlineMath">
   Deterministic loss:
   <i>
    R(c)
   </i>
   = −
   <i>
    c
   </i>
   , for any deterministic loss
   <i>
    c &lt;
   </i>
   0
   <i>
    .
   </i>
  </p>
  <p block-type="TextInlineMath">
   Positive homogeneity:
   <i>
    R(λW )
   </i>
   =
   <i>
    λR(W )
   </i>
   for any loss
   <i>
    W &lt;
   </i>
   0, and any nonnegative scalar
   <i>
    λ
   </i>
   .
  </p>
  <p block-type="TextInlineMath">
   Additivity for comonotonic risk:
   <i>
    R(W
   </i>
   +
   <i>
    W
   </i>
   <sup>
    ∗
   </sup>
   <i>
    )
   </i>
   =
   <i>
    R(W )
   </i>
   +
   <i>
    R(W
   </i>
   <sup>
    ∗
   </sup>
   <i>
    )
   </i>
   for any losses
   <i>
    W
   </i>
   and
   <i>
    W
   </i>
   <sup>
    ∗
   </sup>
   , which are increasing deterministic transformations of the same underlying risk
   <i>
    Z
   </i>
   .
  </p>
  <p block-type="Text">
   Some of the above-mentioned conditions are easily written in terms of quantile functions, by noting that
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     the quantile function of
     <i>
      λW
     </i>
     is
     <i>
      λ
     </i>
     times the quantile function of
     <i>
      W
     </i>
     and
    </li>
    <li block-type="ListItem">
     the quantile function of the sum
     <i>
      W
     </i>
     +
     <i>
      W
     </i>
     <sup>
      ∗
     </sup>
     of comonotonic risks is the sum of the quantile functions of
     <i>
      W
     </i>
     and
     <i>
      W
     </i>
     <sup>
      ∗
     </sup>
     .
    </li>
   </ul>
  </p>
  <h4>
   3.
   <b>
    Distortion risk measures
   </b>
  </h4>
  <p block-type="Text">
   A reserve level can be considered as a measure of risk. The interpretation in terms of quantile functions of the homogeneity and additivity for comonotonic risk assumptions implies that a risk measure satisfying Wang's set of axioms can be written as a linear functional of the quantile function. By applying the Riesz theorem, this leads to the introduction of the so-called distortion risk measures (DRM) defined by Wang [25, 26]:
  </p>
  <p block-type="Equation">
   <math display="block">
    \Pi(Q, H) = -\int_0^1 Q(u) \, \mathrm{d}H(u) \tag{4}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <i>
    Q
   </i>
   denotes the quantile function of the uncertain loss and
   <i>
    H
   </i>
   is a measure, called the
   <i>
    distortion measure
   </i>
   . The positivity axiom implies that
   <i>
    H
   </i>
   is a positive measure and the assumption of certain loss implies that
   <i>
    H
   </i>
   is a probability measure. Moreover, the DRM is coherent if
   <i>
    H
   </i>
   is concave. DRMs are the basis of the so-called "dual theory of choices under risk" [22, 27, 28]. Thus, a DRM is simply a weighted average of opposite quantile values. Well-known risk measures are derived by considering appropriate DRMs.
  </p>
  <p block-type="Text">
   (a) VaR
  </p>
  <p block-type="TextInlineMath">
   When
   <i>
    H (u
   </i>
   ;
   <i>
    α)
   </i>
   = 1l
   <i>
    (u
   </i>
   ≥
   <i>
    α)
   </i>
   , with
   <i>
    α
   </i>
   ∈
   <i>
    (
   </i>
   0
   <i>
    ,
   </i>
   1
   <i>
    ),
   </i>
   we get
  </p>
  <p block-type="Equation">
   <math display="block">
    \Pi(Q, H(.; \alpha)) = -Q(\alpha) = VaR(\alpha) \tag{5}
   </math>
  </p>
  <p block-type="TextInlineMath">
   (b) Tail-VaR
  </p>
  <p block-type="TextInlineMath">
   When
   <i>
    H (u, α)
   </i>
   = min
   <i>
    (u/α,
   </i>
   1
   <i>
    )
   </i>
   , with
   <i>
    α
   </i>
   ∈ [0
   <i>
    ,
   </i>
   1], we get the equally weighted average of VaR on the interval [0
   <i>
    , α
   </i>
   ]:
  </p>
  <p block-type="Equation">
   <math display="block">
    \Pi[Q, H(., \alpha)] = -\int_0^\alpha \frac{Q(u)}{\alpha} du\n
   </math>
   <math display="block">
    \n= -\frac{1}{\alpha} \int_0^\alpha u \, dF(u)\n
   </math>
   <math display="block">
    \n= E[-W|W &lt; -VaR(\alpha)] \quad (6)
   </math>
  </p>
  <p block-type="Text">
   which is the opposite of the expected portfolio value when there is a loss; this measure is called the
   <i>
    Tail-VaR
   </i>
   at level
   <i>
    α
   </i>
   . This is a coherent risk measure since
   <i>
    H
   </i>
   is a concave function.
  </p>
  <h4>
   (c) Proportional hazard DRM
  </h4>
  <p block-type="TextInlineMath">
   This risk measure is obtained for the power law transformation
   <math display="inline">
    H(u; p) = u^p
   </math>
   , where
   <math display="inline">
    p &gt; 0
   </math>
   and has been introduced for the definition of insurance premium.
  </p>
  <h1>
   Nonparametric Estimation in the IID Framework
  </h1>
  <p block-type="Text">
   In this section, we assume a sequence of IID returns concerning a given portfolio, and consider the estimation of the risk measures by their sample counterpart. Since these measures are defined from the quantile function, we first recall the asymptotic behavior of the empirical quantile. Then, we deduce the properties of estimated distortion risk measures.
  </p>
  <h4>
   The Empirical Quantile Function
  </h4>
  <p block-type="TextInlineMath">
   <math display="inline">
    y_1, \ldots, y_T
   </math>
   denotes the sequence of IID returns, with a common distribution with pdf
   <math display="inline">
    f
   </math>
   , cdf
   <math display="inline">
    F
   </math>
   , and quantile function
   <math display="inline">
    Q
   </math>
   . The empirical cdf is defined as
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{F}_T(y) = \frac{1}{T} \sum_{t=1}^T \mathbf{1}_{y_t \le y} \tag{7}
   </math>
  </p>
  <p block-type="Text">
   whereas the empirical quantile function is
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{Q}_T(u) = \inf\{y : \hat{F}_T(y) \ge u\} \tag{8}
   </math>
  </p>
  <p block-type="Text">
   When the distribution is continuous with positive pdf, the empirical cdf and quantile functions are asymptotically related by means of the Bahadur representation [19, Section 4.3]:
  </p>
  <p block-type="Equation">
   <math display="block">
    \sqrt{T}[\hat{Q}_T(u) - Q(u)]
   </math>
   <br/>
   =
   <math>
    -\frac{1}{f[Q(u)]}\sqrt{T}[\hat{F}_T[Q(u)] - u] + o_P(1)
   </math>
   (9)
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    o_P(1)
   </math>
   is negligible in probability. This asymptotic equivalence allows for deriving the asymptotic behavior of the empirical quantile from the asymptotic behavior of the empirical cdf.
  </p>
  <p block-type="Text">
   It is well known that the empirical cdf is strongly consistent with the true underlying cdf and converges weakly, that is, in distribution, to a Brownian bridge up to an appropriate standardization
   <math display="inline">
    [23]
   </math>
   :
  </p>
  <p block-type="Equation">
   <math display="block">
    \sqrt{T}[\hat{F}_T(Q(u)) - u] \Rightarrow B(u), u \in [0, 1] \qquad (10)
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    \Rightarrow
   </math>
   denotes weak convergence and
   <i>
    B
   </i>
   is a Brownian bridge, that is, a Gaussian process with zero mean and covariance: Cov
   <math display="inline">
    [B(u_1), B(u_2)] =
   </math>
   <math display="inline">
    \min(u_1, u_2) - u_1u_2
   </math>
   . By applying the Bahadur representation
   <math display="inline">
    (9)
   </math>
   , we deduce that
  </p>
  <p block-type="Equation">
   <math display="block">
    \sqrt{T}[\hat{Q}_T(u) - Q(u)] \Rightarrow -\frac{1}{f[Q(u)]}B(u) \qquad (11)
   </math>
  </p>
  <h2>
   <b>
    Empirical Distortion Risk Measures
   </b>
  </h2>
  <p block-type="Text">
   Let us now consider a given risk measure:
  </p>
  <p block-type="Equation">
   <math display="block">
    \Pi(Q, H) - \int_0^1 Q(u) \, \mathrm{d}H(u) \tag{12}
   </math>
  </p>
  <p block-type="Text">
   where
   <math display="inline">
    H
   </math>
   is the distortion measure. Its empirical counterpart is given by
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{\Pi}_T(H) = \Pi(\hat{Q}_T, H) = -\int_0^1 \hat{Q}_T(u) \, \mathrm{d}H(u) \quad (13)
   </math>
  </p>
  <p block-type="TextInlineMath">
   It is easily written in terms of observed returns. Let us consider the returns ranked in increasing order as
   <math display="inline">
    y_1^* \le y_2^* &lt; \cdots, &lt; y_T^*
   </math>
   , called the
   <i>
    order statistic
   </i>
   . We have
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{\Pi}_T(H) = -\sum_{t=1}^T \{y_t^*[H(t/T) - H((t-1)/T)]\}
   </math>
   (14)
  </p>
  <p block-type="TextInlineMath">
   This estimator is a linear combination of the order statistics
   <math display="inline">
    y_1^* &lt; \cdots &lt; y_T^*
   </math>
   , with weights depending on the sample size.&lt;sup&gt;d&lt;/sup&gt;
  </p>
  <p block-type="TextInlineMath">
   Formula (14) is especially simple for estimating a VaR, that is, the opposite of the value of the
   <math display="inline">
    \alpha
   </math>
   quantile, when the sample size is well chosen. Indeed, let us assume, for instance, a risk level
   <math display="inline">
    \alpha = 5\%
   </math>
   and
   <math display="inline">
    T = 200
   </math>
   ; the estimated VaR (5%) is simply
  </p>
  <p block-type="Equation">
   <math display="block">
    \widehat{VaR}_{T}(5\%) = -y_{10}^{*} \tag{15}
   </math>
  </p>
  <p block-type="TextInlineMath">
   (since
   <math display="inline">
    5\% \times 200 = 10
   </math>
   ).
  </p>
  <h3>
   Asymptotic Behavior of Estimated DRM
  </h3>
  <p block-type="TextInlineMath" class="has-continuation">
   The asymptotic behavior of the estimated DRM is directly deduced from the asymptotic behavior of the empirical quantile function. The estimator
   <math display="inline">
    \hat{\Pi}_T(H)
   </math>
  </p>
  <p block-type="Text">
   converges to the theoretical DRM,
   <math display="inline">
    \Pi(Q; H)
   </math>
   , and we have
  </p>
  <p block-type="Equation">
   <math display="block">
    \sqrt{T}[\hat{\Pi}_T(H) - \Pi(Q, H)]
   </math>
   <math display="block">
    \Rightarrow \int_0^1 \frac{1}{f[Q(u)]} B(u) \, \mathrm{d}H(u) \tag{16}
   </math>
  </p>
  <p block-type="Text">
   This means that the estimated DRM is asymptotically Gaussian, with zero mean and a variance given by
  </p>
  <p block-type="Equation">
   <math display="block">
    V_{\text{as}}\{\sqrt{T}(\hat{\Pi}_T(H) - \Pi(Q, H))\}
   </math>
   <br/>
   =
   <math>
    \int_0^1 \int_0^1 \frac{\min(u_1, u_2) - u_1 u_2}{f[Q(u_1)] f[Q(u_2)]} \, \mathrm{d}H(u_1) \, \mathrm{d}H(u_2)
   </math>
   (17)
  </p>
  <p block-type="Text" class="has-continuation">
   This expression of the asymptotic variance can be difficult to use in practice, since it involves the pdf, which is rather difficult to estimate. It can
  </p>
  <p block-type="Text">
   <b>
    Example 1 (Sample VaR).
   </b>
   The VaR(
   <math display="inline">
    \alpha
   </math>
   ) is obtained with the distortion measure equal to the point mass at
   <math display="inline">
    \alpha
   </math>
   . The distortion measure is not continuous and formula (19) cannot be applied. From the general result, we know that
  </p>
  <p block-type="Equation">
   <math display="block">
    \sqrt{T}[\widehat{VaR}_{T}(\alpha) - VaR(\alpha)] = -\sqrt{T}[\widehat{Q}_{T}(\alpha) - Q(\alpha)] \rightsquigarrow N\left[0, \frac{1}{f[Q(\alpha)]}\alpha(1-\alpha)\right]
   </math>
   (20)
  </p>
  <p block-type="Text">
   The accuracy of this estimator depends not only on the risk level
   <math display="inline">
    \alpha
   </math>
   but also on the tail behavior of the distribution, since the density
   <math display="inline">
    f
   </math>
   (generally) tends to zero at infinity. Thus, the estimator of the VaR is not very accurate for small probability of loss
   <math display="inline">
    \alpha
   </math>
   , and the lack of accuracy increases with increase in magnitude of the tail.
  </p>
  <p block-type="Text">
   <b>
    Example 2 (Sample Tail-VaR).
   </b>
   By applying formula (19), the asymptotic variance of the estimated Tail-VaR [15] is
  </p>
  <p block-type="Equation">
   <math display="block">
    V_{\text{as}}\{\sqrt{T}[T\widehat{Va}R(\alpha) - TVaR(\alpha)]\}
   </math>
   <br/>
   =
   <math display="block">
    \frac{V[Y|Y \leq -VaR(\alpha)] + (1-\alpha)[TVaR(\alpha) - VaR(\alpha)]^{2}}{\alpha}
   </math>
   (21)
  </p>
  <p block-type="Text">
   be simplified when the DRM is continuous with distortion density
   <math display="inline">
    h
   </math>
   . Indeed, we get
  </p>
  <p block-type="Equation">
   <math display="block">
    V_{\text{as}}\{\sqrt{T}[\hat{\Pi}_{T}(H) - \Pi(Q, H)]\}
   </math>
   <br/>
   =
   <math>
    \int_{0}^{1} \int_{0}^{1} \frac{[\min(u_{1}, u_{2}) - u_{1}u_{2}]}{f[Q(u_{1})]f[Q(u_{2})]}
   </math>
   <br/>
   <math>
    \times h(u_{1})h(u_{2}) du_{1} du_{2}
   </math>
   <br/>
   =
   <math>
    \int_{0}^{1} \int_{0}^{1} [\min(u_{1}, u_{2}) - u_{1}u_{2}]
   </math>
   <br/>
   <math>
    h(u_{1})h(u_{2}) dQ(u_{1}) dQ(u_{2})
   </math>
   (18)
  </p>
  <p block-type="Text">
   by noting that
   <math display="inline">
    1/f[Q(u)]
   </math>
   is the quantile density. Therefore, we get
  </p>
  <p block-type="Equation">
   <math display="block">
    V_{\text{as}}\{\sqrt{T}[\hat{\Pi}_{T}(H) - \Pi(Q, H)]\}
   </math>
   <br/>
   =
   <math>
    \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} [\min[F(y_{1}), F(y_{2})] - F(y_{1})F(y_{2})]
   </math>
   <br/>
   <math>
    \times h[F(y_{1})]h[F(y_{2})] \, \mathrm{d}y_{1} \, \mathrm{d}y_{2}.
   </math>
   (19)
  </p>
  <p block-type="Text">
   where TVaR denotes the Tail-VaR.
  </p>
  <p block-type="Text">
   This asymptotic variance has two components. The first one measures the variability of the loss when a loss occurs, and the second one accounts for the expected loss beyond the VaR.
  </p>
  <h4>
   Estimated Accuracy of a Sample DRM
  </h4>
  <p block-type="Text">
   It is important to distinguish the case of continuous distortion measures, which exclude the VaR.
  </p>
  <h1>
   1. Continuous distortion measure
  </h1>
  <p block-type="Text">
   When
   <math display="inline">
    H
   </math>
   is continuous with density
   <math display="inline">
    h
   </math>
   , we can directly use the sample counterpart of formula (19) to derive a consistent estimator of the variance of
   <math display="inline">
    \hat{\Pi}_T(H)
   </math>
   [15, 18]. We get
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{V}_{\text{as}}(\sqrt{T}[\hat{\Pi}_{T}(H) - \Pi(Q; H)])
   </math>
   <math display="block">
    = \sum_{i=1}^{T-1} \sum_{j=1}^{T-1} \left\{ \left( \min\left(\frac{i}{T}, \frac{j}{T}\right) - \frac{i}{T} \frac{j}{T} \right) \right\}
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    \times h\left(\frac{i}{T}\right)h\left(\frac{j}{T}\right)\left(y_{i+1}^*-y_i^*\right)\left(y_{j+1}^*-y_j^*\right) \bigg\} \tag{22}
   </math>
  </p>
  <h2>
   2. Discrete distortion measure
  </h2>
  <p block-type="Text">
   Formula (19) cannot be applied to the VaR. Since
  </p>
  <p block-type="Equation">
   <math display="block">
    V_{\rm as}\left(\sqrt{T}[\hat{Q}_T(\alpha) - Q(\alpha)]\right) = \frac{1}{f[Q(\alpha)]}\alpha(1-\alpha) \tag{23}
   </math>
  </p>
  <p block-type="Text">
   this variance can be estimated by
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{V}_{\text{as}}\left(\sqrt{T}[\hat{Q}_{T}(\alpha)-Q(\alpha)]\right) = \frac{1}{\hat{f}_{T}(\hat{Q}_{T}(\alpha)]}\alpha(1-\alpha) \tag{24}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    \hat{f}_T
   </math>
   is, for instance, a kernel estimator of the density.
  </p>
  <h1>
   <b>
    Dynamic Analysis
   </b>
  </h1>
  <p block-type="Text">
   Despite its success among practitioners, the computation and analysis of VaR and DRM in an IID framework is not realistic, and the (nonlinear) return dynamics should be taken into account. It arises in the computation of the risk measure itself, which depends on the conditional quantile function.&lt;sup&gt;e&lt;/sup&gt; In this conditional framework, a nonparametric approach is difficult to follow, since the number of conditioning variables can be rather large, including current and lagged values of several asset returns, for instance. This explains why parametric or semiparametric approaches are generally considered, with the risk of using a misspecified model, that is, of introducing an additional model risk. In the first subsection, we consider a conditionally Gaussian model and derive the corresponding estimators of the DRM. The second subsection concerns the term structure of VaR. In the third subsection, we discuss dynamic models recently introduced for the purpose of computing dynamic VaR. These models are directly written in terms of conditional quantile functions.
  </p>
  <h2>
   Parametric Dynamic Models
  </h2>
  <h4>
   1. Definition of the dynamic DRM
  </h4>
  <p block-type="Text" class="has-continuation">
   The dynamic model is generally written for the portfolio returns of interest
   <math display="inline">
    y_1, \ldots, y_T
   </math>
   . Let us assume that
  </p>
  <p block-type="Text">
   the conditional distribution of
   <math display="inline">
    y_t
   </math>
   , given observable variables
   <math display="inline">
    z_{t-1}
   </math>
   , say, is such that
  </p>
  <p block-type="Equation">
   <math display="block">
    y_t = m(z_{t-1}; \theta) + \sigma(z_{t-1}; \theta)u_t \tag{25}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    (u_t)
   </math>
   are the IID standard Gaussian variables and
   <math display="inline">
    \theta
   </math>
   is an unknown parameter.
   <math display="inline">
    m(z_{t-1}; \theta)
   </math>
   (respectively,
   <math display="inline">
    \sigma(z_{t-1};\theta)
   </math>
   ) is the conditional drift (respectively, conditional volatility). The conditional quantile function is
  </p>
  <p block-type="Equation">
   <math display="block">
    Q_t(u) = m(z_{t-1}; \theta) + \sigma(z_{t-1}; \theta)\Phi^{-1}(u) \qquad (26)
   </math>
  </p>
  <p block-type="Text">
   where
   <math display="inline">
    \Phi
   </math>
   denotes the cdf of the standard normal. We deduce that a dynamic DRM can be written as
  </p>
  <p block-type="Equation">
   <math display="block">
    \Pi(Q_t, H) = -\int_0^1 Q_t(u) \, \mathrm{d}H(u) = -m(z_{t-1}; \theta) \n- \sigma(z_{t-1}; \theta) \int_0^1 \Phi^{-1}(u) \, \mathrm{d}H(u) \quad (27)
   </math>
  </p>
  <p block-type="Text">
   The DRM depends on the information by means of the conditional mean and volatility and is a linear combination of these summary statistics.
  </p>
  <p block-type="Text">
   This type of analysis is usually applied with autoregressive conditionally heteroscedastic (ARCH) models or switching regime models [6], and is easily extended to error terms with no Gaussian distribution, such as the Student distribution.
  </p>
  <p block-type="Text">
   For instance, such an approach is followed by J.P. Morgan with an IGARCH model defined by
  </p>
  <p block-type="Equation">
   <math display="block">
    y_t = \sigma_t u_t \tag{28}
   </math>
  </p>
  <p block-type="Text">
   where
  </p>
  <p block-type="Equation">
   <math display="block">
    \sigma_t^2 = \theta \sigma_{t-1}^2 + (1 - \theta) y_{t-1}^2 = (1 - \theta) \sum_{j=1}^{\infty} \theta^{j-1} y_{t-j}^2
   </math>
   (29)
  </p>
  <p block-type="Text">
   and
   <math display="inline">
    \theta = 0.95
   </math>
   . Such an automatic dynamic, assumed valid for any portfolio return, is likely misspecified, and it is preferable to estimate the return dynamics separately for each portfolio.
  </p>
  <h2>
   2. Estimation of the dynamic DRM
  </h2>
  <p block-type="Text">
   The DRM is usually estimated in two steps. In the first step, the parameter
   <math display="inline">
    \theta
   </math>
   is estimated by (conditional) maximum likelihood (ML), that is, by maximizing
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{\theta}_T = \arg \max_{\theta} \sum_{t=1}^T \left\{ -\frac{1}{2} \log \sigma^2(z_{t-1}; \theta) - \frac{1}{2} \frac{[y_t - m(z_{t-1}; \theta)]^2}{\sigma^2(z_{t-1}; \theta)} \right\}
   </math>
   (30)
  </p>
  <p block-type="Text">
   This estimator has the standard asymptotic properties of an ML estimator. Then, in the second step, the DRM is estimated as
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{\Pi}_{t,T} = -m(z_{t-1}; \hat{\theta}_T) - \sigma(z_{t-1}; \hat{\theta}_T) \int_0^1 \Phi^{-1}(u) \, \mathrm{d}H(u) \tag{31}
   </math>
  </p>
  <p block-type="Text">
   For instance, we have
  </p>
  <p block-type="Equation">
   <math display="block">
    \widehat{VaR}_{T}(t;\alpha) = -m(z_{t-1};\hat{\theta}_{T}) - \sigma(z_{t-1};\hat{\theta}_{T})\Phi^{-1}(\alpha)
   </math>
   (32)
  </p>
  <p block-type="Text">
   The first step is valid for any type of DRM and can be applied to get a coherent set of estimated risk measures, such as VaR(1%), VaR(5%), VaR(10%), and TVaR(10%).
  </p>
  <h4>
   The Term Structure of VaR
  </h4>
  <p block-type="TextInlineMath">
   Until now, we focused on the evolution of the dynamic risk measure, that is, on its dependence with respect to time for a fixed horizon
   <math display="inline">
    h = 1
   </math>
   . It is interesting to consider how the risk measure depends on the horizon h for a fixed date t. If
   <math display="inline">
    y_{t+1}
   </math>
   denotes the opposite change of portfolio value between
   <math display="inline">
    t
   </math>
   and
   <math display="inline">
    t + 1
   </math>
   , the opposite change of portfolio value between t and
   <math display="inline">
    t + h
   </math>
   is
   <math display="inline">
    y_{t,h} = y_{t+1} + \cdots + y_{t+h}
   </math>
   . Therefore, the conditional quantile function of interest
   <math display="inline">
    Q_{t,h}
   </math>
   is now associated with the conditional distribution of
   <math display="inline">
    y_{t,h}
   </math>
   given the information at time
   <math display="inline">
    t
   </math>
   .
  </p>
  <p block-type="Text">
   The term structure of VaR is the mapping
  </p>
  <p block-type="Equation">
   <math display="block">
    h \to VaR(t, h; \alpha) = -Q_{t,h}(\alpha) \tag{33}
   </math>
  </p>
  <p block-type="Text">
   which can be defined for any date
   <math display="inline">
    t
   </math>
   and probability level
   <math display="inline">
    \alpha
   </math>
   .
  </p>
  <p block-type="Text">
   In simple cases, the term structure of VaR is derived explicitly. For instance, let us assume a Gaussian autoregressive process of order 1 for the short-term opposite portfolio change
  </p>
  <p block-type="Equation">
   <math display="block">
    y_{t} = \mu + \varphi(y_{t-1} - \mu) + \sigma u_{t} \tag{34}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    \mu, \varphi, \sigma
   </math>
   are the mean, autoregressive coefficient, and innovation variance, respectively, and
   <math display="inline">
    (u_t)
   </math>
   is a sequence of IID standard Gaussian variables. Thus, the conditional distribution of
   <math display="inline">
    y_{t,h}
   </math>
   is Gaussian, with mean
  </p>
  <p block-type="Equation">
   <math display="block">
    m(y_t, h) = \mu h + \varphi \frac{1 - \varphi^h}{1 - \varphi} (y_t - \mu) \qquad (35)
   </math>
  </p>
  <p block-type="Text">
   and variance
  </p>
  <p block-type="Equation">
   <math display="block">
    \sigma^{2}(h) = \frac{\sigma^{2}}{(1-\varphi^{2})} \left\{ h - 2\varphi(1-\varphi^{h}) + \varphi^{2} \frac{1-\varphi^{2h}}{1-\varphi^{2}} \right\}
   </math>
   (36)
  </p>
  <p block-type="Text">
   We deduce the VaR at horizon
   <math display="inline">
    h
   </math>
   as
  </p>
  <p block-type="Equation">
   <math display="block">
    VaR(t, h; \alpha) = -m(y_t, h) - \sigma(h)\Phi^{-1}(\alpha) \tag{37}
   </math>
  </p>
  <p block-type="TextInlineMath">
   The IID Gaussian framework is obtained when
   <math display="inline">
    \varphi = 0
   </math>
   . In this case, we have
   <math display="inline">
    VaR(t, h; \alpha) = -\mu h - \mu
   </math>
   <math display="inline">
    \sigma\sqrt{h}\Phi^{-1}(\alpha)
   </math>
   , and the term structure involves both a linear and square-root function of the horizon
   <math display="inline">
    h
   </math>
   . This formula is often used by practitioners with
   <math display="inline">
    \mu = 0
   </math>
   to derive automatically the VaR at horizon
   <math display="inline">
    h
   </math>
   from the VaR at horizon 1 by
   <math display="inline">
    VaR(t, h; \alpha) = \sqrt{h}VaR(t, 1; \alpha)
   </math>
   . As seen earlier, this simplified formula is valid under very restrictive assumptions and has to be systematically avoided.
  </p>
  <p block-type="TextInlineMath">
   In fact, it is necessary to carefully compute the VaR at the different horizons case by case. In general, the term structure of
   <math display="inline">
    VaR
   </math>
   has no explicit expression, but can be derived by simulation, whenever the short-term quantile function
   <math display="inline">
    Q_{t,1}
   </math>
   has an explicit expression:
   <math display="inline">
    Q_{t,1}(u) =
   </math>
   <math display="inline">
    Q(u; y_{t-1})
   </math>
   , say, if we assume for illustration, a Markov process. The simulation procedure is as follows:
  </p>
  <p block-type="Text">
   1. Consider independent drawings
   <math display="inline">
    u_{t+1}^s, \ldots, u_{t+h}^s
   </math>
   in the standard uniform distribution on
   <math display="inline">
    (0, 1)
   </math>
  </p>
  <h3>
   2. Apply the recursive formula
  </h3>
  <p block-type="Equation">
   <math display="block">
    y_{t+1}^{s} = Q(u_{t+1}^{s}, y_{t})
   </math>
   <br/>
   <math display="block">
    y_{t+2}^{s} = Q(u_{t+2}^{s}, y_{t+1}^{s})
   </math>
   <br/>
   <math display="block">
    y_{t+h}^{s} = Q(u_{t+h}^{s}, y_{t+h-1}^{s})
   </math>
   (38)
  </p>
  <p block-type="TextInlineMath">
   <math display="inline">
    (y_{t+1}^s, \ldots, y_{t+h}^s)
   </math>
   has the same conditional distribution as
   <math display="inline">
    (y_{t+1}, \ldots, y_{t+h})
   </math>
   .
  </p>
  <p block-type="Text">
   3. Replicate
   <math display="inline">
    s = 1, \ldots, S
   </math>
   , and approximate
   <math display="inline">
    Q_{t,h}(\alpha)
   </math>
   by the empirical quantile distribution of
   <math display="inline">
    y_{t h}^{s}
   </math>
   =
   <math display="inline">
    y_{t+1}^s + \cdots + y_{t+h}^s, s = 1, \ldots, S.
   </math>
  </p>
  <h3>
   Dynamic Quantile Models
  </h3>
  <p block-type="Text">
   <b>
    Specification.
   </b>
   Since the dynamic DRM is easily written in terms of the conditional quantile function, it has been recently proposed to directly specify the dynamic model for
   <math display="inline">
    (y_t)
   </math>
   in terms of function
   <math display="inline">
    Q_t
   </math>
   , instead of using more standard (nonlinear) autoregressive specifications [11, 13]. For instance, a dynamic additive quantile (DAQ) model is
  </p>
  <p block-type="Equation">
   <math display="block">
    Q_{t}(u;\theta) = \sum_{k=1}^{K} a_{k}(\underline{y_{t-1}};\alpha_{k}) Q_{k}(u;\beta_{k}) + a_{0}(\underline{y_{t-1}};\alpha_{0})
   </math>
   (39)
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    y_{t-1} = (y_{t-1}, y_{t-2}, \ldots), Q_k
   </math>
   are path-independent baseline quantile functions with identical range
   <math display="inline">
    (-\infty, +\infty)
   </math>
   and
   <math display="inline">
    a_k(y_{t-1}; \alpha_k), k = 1, \ldots, K
   </math>
   are nonnegative functions of the past.
   <math display="inline">
    \theta = (\alpha'_0, \ldots, \alpha'_K, \beta'_1, \beta'_1)
   </math>
   <math display="inline">
    \ldots, \beta'_K
   </math>
   ' is the vector of parameters. The positivity restrictions on functions
   <math display="inline">
    a_k
   </math>
   ensure that
   <math display="inline">
    Q_t(:,\theta)
   </math>
   is an increasing function and thus is compatible with the quantile interpretation.
  </p>
  <p block-type="Text">
   The DAO model encompasses simple specifications of interest. For instance, specifications of the type
  </p>
  <p block-type="Equation">
   <math display="block">
    Q_t(u) = Q_0(u) + Q_1(u) \max(y_{t-1}, 0)
   </math>
   <br/>
   +
   <math>
    Q_2(u) \max(-y_{t-1}, 0)
   </math>
   (40)
  </p>
  <p block-type="Text">
   or
  </p>
  <p block-type="Equation">
   <math display="block">
    Q_t(u) = \gamma_0(u) + \gamma_1(u)Q_{t-1}(u) + \gamma_2(u)|y_{t-1}|
   </math>
   <br/>
   =
   <math>
    \frac{\gamma_0(u)}{1 - \gamma_1(u)} + \sum_{k=1}^{\infty} \gamma_2(u)\gamma_1(u)^h|y_{t-h}|
   </math>
   (41)
  </p>
  <p block-type="Text">
   are special cases of the conditional autoregressive variance at risk (CAViaR) models introduced by Engle and Manganelli [9]. A specification such as
  </p>
  <p block-type="Equation">
   <math display="block">
    Q_{t}(u) = m_{0} + m_{1}|y_{t-1} - \mu|
   </math>
   <br/>
   +
   <math>
    (\sigma_{0,0} + \sigma_{0,1}|y_{t-1} - \mu|)^{1/2}\Phi^{-1}(u)
   </math>
   <br/>
   +
   <math>
    (\sigma_{1,0} + \sigma_{1,1}|y_{t-1} - \mu|)^{1/2}tg[\pi(u - 1/2)]
   </math>
   <br/>
   (42)
  </p>
  <p block-type="TextInlineMath">
   defines a quantile mixture of a Gaussian distribution (with baseline quantile function
   <math display="inline">
    \Phi^{-1}
   </math>
   ) and a Cauchy distribution (with baseline quantile function
   <math display="inline">
    tg[\pi(u  \frac{1}{2}
   </math>
   ), with ARCH effects in both scale parameters and a risk premium in the location parameter.
  </p>
  <p block-type="Text">
   For a DAQ model, the dynamic DRM are immediately derived as
  </p>
  <p block-type="Equation">
   <math display="block">
    \Pi(Q_t, H) = \sum_{k=1}^{K} a_k(\underline{y_{t-1}}; \alpha_k) \int Q_k(u; \beta_k) \, \mathrm{d}H(u) \\
+ a_0(\underline{y_{t-1}}; \alpha_0) \tag{43}
   </math>
  </p>
  <p block-type="TextInlineMath">
   They depend on the same set of dynamic summaries of the past
   <math display="inline">
    a_k(y_{t-1};\alpha_k), k = 0, \ldots, K
   </math>
   , with sensitivity coefficients equal to the baseline DRMs. These explicit expressions (see examples
   <math display="inline">
    (40)
   </math>
   –
   <math display="inline">
    (42)
   </math>
   ) are appropriate for easily deriving the term structure of VaR by simulation (see the section The Term Structure of VaR).
  </p>
  <p block-type="TextInlineMath">
   <b>
    Estimation.
   </b>
   When the dynamic model is directly written in terms of a quantile function with a simple expression of
   <math display="inline">
    Q_t
   </math>
   , it can be numerically cumbersome to derive the conditional pdf
   <math display="inline">
    f_t(y)
   </math>
   =
   <math display="inline">
    \left(\frac{\mathrm{d}\varrho_t}{\mathrm{d}u}[Q_t^{-1}(y)]\right)^{-1}
   </math>
   , which requires the inversion of function
   <math display="inline">
    Q_t
   </math>
   at each observation date. As a consequence, it can be difficult to derive the maximum likelihood estimate of the parameter
   <math display="inline">
    \theta
   </math>
   .
  </p>
  <p block-type="Text">
   Different estimation approaches have been proposed in the statistical literature.
  </p>
  <p block-type="Text" class="has-continuation">
   1. When
   <math display="inline">
    Q_t(u;\theta) = Q(u;\theta)
   </math>
   is independent of the path, the parameter
   <math display="inline">
    \theta
   </math>
   can be estimated by calibrating on
   <math display="inline">
    L
   </math>
   -moments or trimmed
   <math display="inline">
    L
   </math>
   -moments [8, 17]. The theoretical
   <math display="inline">
    L
   </math>
   -moments or trimmed
   <i>
    L
   </i>
   -moments are of the type
   <math display="inline">
    \int Q(u;\theta)P_l(u) du
   </math>
   ,&lt;br&gt;
   <math display="inline">
    l = 1, \ldots, L
   </math>
   , where
   <math display="inline">
    P_l
   </math>
   are well-chosen
  </p>
  <p block-type="TextInlineMath">
   polynomials and their sample counterparts are
   <math display="inline">
    \frac{1}{T} \sum_{i=1}^{T} y_i^* P_l(t/T), \text{ where } y_1^* &lt; \dots &lt; y_T^* \text{ is the}
   </math>
   order statistic, that is, the observations
   <math display="inline">
    y_1, \ldots, y_T
   </math>
   are ranked in increasing order. This approach is easy to implement, but does not provide efficient estimators, and is difficult to extend to a dynamic framework [see the Generalized Method of L-Moments in [13, Section 4].
  </p>
  <p block-type="Text">
   2. In the dynamic framework, the parameter
   <math display="inline">
    \theta
   </math>
   can also be consistently estimated by minimizing an objective function of the type in
   <math display="inline">
    [20]
   </math>
   :
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{\theta}_T = \arg\min_{\theta} \sum_{t=1}^T \{ \alpha \max[y_t - Q_t(\theta), 0]
   </math>
   <br/>
   +
   <math>
    (1 - \alpha) \max[Q_t(\theta) - y_t, 0] \}
   </math>
   <br/>
   =
   <math>
    \arg\min_{\theta} \sum_{t=1}^T \{ \alpha[y_t - Q_t(\theta)]^+
   </math>
   <br/>
   +
   <math>
    (1 - \alpha)[y_t - Q_t(\theta)]^- \}
   </math>
   (44)
  </p>
  <p block-type="Text">
   where
   <math display="inline">
    \alpha
   </math>
   is a scalar between 0 and 1 (see the section The Control Problem for the interpretation of the objective function).
  </p>
  <p block-type="Text">
   3. The estimation methods above are easy to apply, but are generally not efficient. They can be used as starting values in the optimization algorithm of the estimated inverse Kullback-Leibler information criterion (KLIC) :
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{\theta}_T = \arg \max_{\theta} \sum_{t=1}^T \left\{ \int_0^1 \log \left[ \frac{\mathrm{d}Q}{\mathrm{d}u}(u|y_{t-1};\theta) \right] + \int_0^1 \log \hat{f}_T[Q(u|y_{t-1};\theta)|y_{t-1}) \right\} \mathrm{d}u \tag{45}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    \hat{f}_T
   </math>
   is a kernel estimator of the conditional pdf of
   <math display="inline">
    y_t
   </math>
   given
   <math display="inline">
    y_{t-1}
   </math>
   . The inverse KLIC estimator is asymptotically equivalent to the ML estimator and asymptotically efficient [13].
  </p>
  <h2>
   <b>
    Control and Out-of-sample Validation
   </b>
  </h2>
  <p block-type="Text">
   The current regulations have at least three limitations: (i) the large use of the VaR to measure the risk and fix the required capital. This measure
  </p>
  <p block-type="Text">
   accounts for the probability of loss, but not for the magnitude of the loss beyond the VaR. This drawback can be corrected by considering another DRM such as the Tail-VaR. (ii) The lack of coherency between the suggested (but often not followed) computation of the VaR as a conditional quantile, and the ex post validation of this computation by the regulator, which is generally based on a historical (that is unconditional) analysis. (iii) The computation of VaR is performed independently for each business line without taking into account the potential dependence between the risks of different lines.
  </p>
  <p block-type="Text">
   The two latter limitations can be solved by considering the problem of the determination of reserves as a control problem [12, 16].
  </p>
  <h4>
   The Control Problem
  </h4>
  <p block-type="Text">
   The concept of VaR has been initially defined in a rather
   <i>
    ad hoc
   </i>
   way, but is the solution of an optimal control problem. More precisely, let us consider the objective function
  </p>
  <p block-type="Equation">
   <math display="block">
    \psi(t, z_t) = E_t[\alpha(y_{t+1} + z_t)^+ + (1 - \alpha)(y_{t+1} + z_t)^-]
   </math>
   (46)
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    \alpha
   </math>
   is the announced risk level. The decision criterion corresponds to an asymmetric loss function, which distinguishes two types of errors. When
   <math display="inline">
    y +
   </math>
   <math display="inline">
    z &lt; 0
   </math>
   , the reserve level is not large enough to hedge the loss; when
   <math display="inline">
    y + z &gt; 0
   </math>
   , the reserve level is too high. The type I error has to be avoided from the prudential point of view of the regulator, whereas the type II error has to be avoided for the firm, since the reserves receive no the interest rate in the current regulation.
  </p>
  <p block-type="TextInlineMath">
   The solution of the optimization problem
   <math display="inline">
    (46)
   </math>
   [19],
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{z}_t = \arg\max_{z_t} E_t[\alpha(y_{t+1} + z_t)^+ + (1 - \alpha)(y_{t+1} + z_t)^-]
   </math>
   (47)
  </p>
  <p block-type="TextInlineMath">
   performed over the variables
   <math display="inline">
    z_t
   </math>
   function of the information, is
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{z}_t = -Q_t(\alpha) = VaR_t(\alpha) \tag{48}
   </math>
  </p>
  <p block-type="Text">
   Thus, the reserve level can be interpreted as a control variate and the conditional VaR as the optimal control variate.
  </p>
  <p block-type="Text">
   In this control framework, the optimal value of the criterion function is given as
   <math display="inline">
    [24]
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{aligned} \psi(t,\hat{z}_{t}) &amp;= \alpha P_{t}[y_{t+1} &gt; -\hat{z}_{t}] \\ &amp;\times E_{t}[(y_{t+1} + \hat{z}_{t})^{+}|y_{t+1} &gt; -\hat{z}_{t}] + (1-\alpha) \\ &amp;\times P_{t}[y_{t+1} &lt; \hat{z}_{t}]E_{t}[(y_{t+1} + \hat{z}_{t})^{-}|y_{t+1} &lt; -\hat{z}_{t}] \\ &amp;= \alpha(1-\alpha)[TVar^{+}(\alpha) + TVaR^{-}(\alpha)] \end{aligned} \tag{49}
   </math>
  </p>
  <p block-type="Text">
   where
   <math display="inline">
    TVaR^+
   </math>
   and
   <math display="inline">
    TVaR^-
   </math>
   are the Tail-VaR associated with the right and left tails of the conditional distribution, respectively. Thus, if the VaR is used as the reserve level, the Tail-VaRs have also to be computed and provide the optimal value of the decision criterion.
  </p>
  <h4>
   Specification Test
  </h4>
  <p block-type="TextInlineMath">
   In practice, it is usual to check the validity of the proposed reserve levels
   <math display="inline">
    \widehat{VaR}_t
   </math>
   by comparing the announced level
   <math display="inline">
    \alpha
   </math>
   with the frequency of exceedance dates with
   <math display="inline">
    y_t + \widehat{VaR}_t &lt; 0
   </math>
   . This practice is misleading. Indeed, two different procedures for determining the reserves can give the same frequency, 5%, say, but the dates at which the reserves are not sufficient can be equally located with the first procedure and come in cluster with the second one. Clearly, if
   <math display="inline">
    T = 100
   </math>
   , the second procedure, in which losses will cumulate over five periods, say, is more risky. An appropriate validation has to distinguish these situations.
  </p>
  <p block-type="Text">
   In fact, the first-order conditions of the control problem are as follows:
  </p>
  <p block-type="Equation">
   <math display="block">
    \frac{\partial \psi}{\partial z}(t,\hat{z}_t) = 0 \Leftrightarrow E_t \left[ \mathbf{1}_{y_{t+1} + \hat{z}_t &lt; 0} \right] = \alpha \qquad (50)
   </math>
  </p>
  <p block-type="Text">
   which is the definition of the conditional VaR, that is,
  </p>
  <p block-type="Equation">
   <math display="block">
    P_t[y_{t+1} + \hat{z}_t &lt; 0] = \alpha \tag{51}
   </math>
  </p>
  <p block-type="Text">
   The first-order condition
   <math display="inline">
    (50)
   </math>
   is a conditional moment restriction. As usual, it can be replaced by a set of unconditional moment restrictions by introducing instrumental variables
   <math display="inline">
    g_t
   </math>
   , which are observable functions of the past. We get
  </p>
  <p block-type="Equation">
   <math display="block">
    E[g_t(\mathbf{1}_{y_{t+1}+\hat{z}_t&lt;0}-\alpha)] = 0 \quad \forall g_t \tag{52}
   </math>
  </p>
  <p block-type="Text" class="has-continuation">
   Specification tests can be constructed from the sample counterparts of these restrictions; the test
  </p>
  <p block-type="TextInlineMath">
   compares the statistics
   <math display="inline">
    (1/T) \sum_{t=1}^{T} g_t(\mathbf{1}_{y_{t+1}+\hat{z}_t&lt;0} - \alpha)
   </math>
   to zero, after an appropriate standardization.
  </p>
  <p block-type="TextInlineMath">
   The current practice, considering the historical frequency
   <math display="inline">
    (1/T)\sum_{t=1}^{T}(\mathbf{1}_{y_{t+1}+\hat{z}_t&lt;0}-\alpha)
   </math>
   , thus, selects
   <math display="inline">
    g_t = 1
   </math>
   as the single instrumental variable. Clearly, other instrumental variables have also to be considered to detect the persistence in extreme losses, such
   <math display="inline">
    as
   </math>
  </p>
  <p block-type="Equation">
   <math display="block">
    g_{1,t} = \mathbf{1}_{y_t + \hat{z}_{t-1} &lt; 0}, g_{2,t} = \mathbf{1}_{y_{t-1} + \hat{z}_{t-2} &lt; 0}, \dots \tag{53}
   </math>
  </p>
  <p block-type="Text">
   which indicate the lack of reserve in the past.
  </p>
  <h4>
   Dependent Business Lines
  </h4>
  <p block-type="TextInlineMath">
   Let us consider two business lines, say,
   <math display="inline">
    y_{1,t}
   </math>
   ,
   <math display="inline">
    y_{2,t}
   </math>
   . The current regulation suggests to compute separately the VaR for the two lines, with the same
   <math display="inline">
    \alpha
   </math>
   , that is, to compute
   <math display="inline">
    VaR_{1,t}(\alpha)
   </math>
   ,
   <math display="inline">
    VaR_{2,t}(\alpha)
   </math>
   . Then, the total reserve is
   <math display="inline">
    VaR_{1,t}(\alpha) + VaR_{2,t}(\alpha)
   </math>
   . This regulation does not account for the dependence between the two risks. The question of reserve allocations between business lines is difficult. A possible solution introduced by Gourieroux and Liu [16] focuses on the definition of an appropriate decision criterion. By analogy with the control problem described in the section The Control Problem, we may consider the objective function:
  </p>
  <p block-type="Equation">
   <math display="block">
    \begin{aligned}\n\psi(t; z_{1t}, z_{2t}) \\
&amp;= E_t \{ [\alpha(y_{1,t+1} + z_{1t})^+ + (1 - \alpha)(y_{1,t+1} + z_{1t})^-] \\
&amp;\times [\alpha(y_{2,t+1} + z_{2t})^+ + (1 - \alpha)(y_{2,t+1} + z_{2t})^-] \} \n\end{aligned} \tag{54}
   </math>
  </p>
  <p block-type="TextInlineMath">
   which distinguished four types of errors, which are type I and II errors cross with business lines. If the loss variables
   <math display="inline">
    y_{1,t+1}
   </math>
   and
   <math display="inline">
    y_{2,t+1}
   </math>
   are conditionally independent, the objective function is equal to the product:
  </p>
  <p block-type="Equation">
   <math display="block">
    E_{t}[\alpha(y_{1,t+1}+z_{1t})^{+}(1-\alpha)(y_{1,t+1}+z_{1t})^{-}]
   </math>
   <br/>
   ×
   <math display="block">
    E_{t}[\alpha(y_{2,t+1}+z_{2t})^{+}+(1-\alpha)(y_{2,t+1}+z_{2,t})^{-}]
   </math>
   <br/>
   (55)
  </p>
  <p block-type="Text">
   and the solutions of the control problem are simply the VaR computed per business line.
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{z}_{1,t} = VaR_{1,t}(\alpha), \hat{z}_{2,t} = VaR_{2,t}(\alpha) \tag{56}
   </math>
  </p>
  <p block-type="Text" class="has-continuation">
   If the loss variables are dependent, the optimization of the objective function (54) provides another
  </p>
  <p block-type="Text">
   solution, which accounts for the dependence between extreme risks. The advantage of this approach, based on the direct optimization of the control decision criterion, is that it is easy to extend to any number of business lines and can provide a solution without having to estimate or specify the joint distribution of
   <math display="inline">
    (y_{1,t+1}, y_{2,t+1}).
   </math>
  </p>
  <h2>
   <b>
    Concluding Remarks
   </b>
  </h2>
  <p block-type="Text">
   The new regulations have led to a rethink on the whole question of risk measures in term of reserve levels and to see the determination of reserves as a control problem. As a consequence, the standard volatility risk measure is progressively being replaced by the VaR, Tail-VaR, or another DRM for several financial problems such as portfolio management [1, 5, 10, 14, 21], performance comparisons [7], or even derivative pricing, especially in insurance [3, 25].
  </p>
  <h3>
   Acknowledgments
  </h3>
  <p block-type="Text">
   The author gratefully acknowledges financial support of NSERC Canada and of the chair AXA/Risk Foundation "Large Risks in Insurance".
  </p>
  <h2>
   <b>
    End Notes
   </b>
  </h2>
  <p block-type="Text">
   &lt;sup&gt;a.&lt;/sup&gt;Thus, we implicitly assume that the current portfolio value is known. This assumption is satisfied for assets that are highly traded on the markets, but should be discussed for over-the-counter (OTC) products.
  </p>
  <p block-type="TextInlineMath">
   &lt;sup&gt;b.&lt;/sup&gt;The portfolio returns
   <math display="inline">
    (W_{t+h} - W_t)/W_t
   </math>
   can be even more stationary; the corresponding
   <math display="inline">
    \alpha
   </math>
   -quantile becomes
   <math display="inline">
    -VaR(t, h; \alpha)/W_t
   </math>
   .
  </p>
  <p block-type="Text">
   &lt;sup&gt;c&lt;/sup&gt;. Equivalently if the cumulative distribution function (cdf) of
   <math display="inline">
    W
   </math>
   is smaller than the cdf of
   <math display="inline">
    W^*
   </math>
   .
  </p>
  <p block-type="Text">
   &lt;sup&gt;d.&lt;/sup&gt;This is called an
   <math display="inline">
    L
   </math>
   -statistic in the statistical literature.
  </p>
  <p block-type="Text">
   &lt;sup&gt;e.&lt;/sup&gt;It also arises when computing the VaR by historical simulation, since the asymptotic properties of the sample quantile, especially the asymptotic variance–covariance matrix, are modified under serial dependence.
  </p>
  <h2>
   References
  </h2>
  <p block-type="ListGroup" class="has-continuation">
   <ul>
    <li block-type="ListItem">
     Acerbi, C. &amp; Simonetti, P. (2002). Portfolio Optimiza-[1] tion with Spectral Measure of Risk. DP. Abaxbank.
    </li>
    <li block-type="ListItem">
     [2] Artzner, P., Delbaen, F., Eber, J. &amp; Heath, D. (1999). Coherent measures of risk, Mathematical Finance 9, 203-228.
    </li>
   </ul>
  </p>
  <p block-type="ListGroup" class="has-continuation">
   <ul>
    <li block-type="ListItem">
     Basak, S. &amp; Shapiro, A. (2001). Value-at-risk based [3] risk management: optimal policies and asset prices, The Review of Financial Studies 14, 371-405.
    </li>
    <li block-type="ListItem">
     [4] Basel Committee on Banking Supervision (1995). An Internal Model Based Approach to Market Risk Capital Requirements. Bank of International Settlements, Working Paper.
    </li>
    <li block-type="ListItem">
     [5] Bassi, F., Embrechts, P. &amp; Kafetzaki, M., (1997). Risk management and quantile estimation, in
     <i>
      Practical Guide
     </i>
     to Heavy Tails. Adler. R., Feldman. K. &amp; M., Taggu. eds. Birkhauser, Boston.
    </li>
    <li block-type="ListItem">
     [6] Billio, M. &amp; Pelizzon, L. (2000). Value-at-risk: a multivariate switching regime approach, Journal of Empirical Finance 7, 531-554.
    </li>
    <li block-type="ListItem">
     Darolles, S., Gourieroux, C. &amp; Jasiak, J. (2009). [7] L-Performance Measures with Application to Hedge Funds. CREST DP.
    </li>
    <li block-type="ListItem">
     Elamir, E. &amp; Seheult, A. (2003). Trimmed [8] L-moments, Computational Statistics and Data Analysis 43. 299-314.
    </li>
    <li block-type="ListItem">
     Engle, R. &amp; Manganelli, S. (2004). CAViaR: conditional [9] autoregressive value-at-risk by regression quantile, Journal of Business and Economic Statistics 22, 367-381.
    </li>
    <li block-type="ListItem">
     [10] Foellmer, H. &amp; Leukert, P. (1999). Quantile hedging, Finance and Stochastics 3, 251-273.
    </li>
    <li block-type="ListItem">
     [11] Giacomini, R. &amp; Komunjer, I. (2005). Evaluation and combination of conditional quantile forecasts, Journal of Business and Economic Statistics 23, 416-431.
    </li>
    <li block-type="ListItem">
     [12] Giacomini, R. &amp; White, H. (2006). Test of conditional predictive ability,
     <i>
      Econometrica
     </i>
     <b>
      74
     </b>
     , 1545-1578.
    </li>
    <li block-type="ListItem">
     [13] Gourieroux, C. &amp; Jasiak, J. (2008). Dynamic quantile model, Journal of Econometrics 147, 198-205.
    </li>
    <li block-type="ListItem">
     Gourieroux, C., Laurent, J.P. &amp; Scaillet, O. (2000). Sen-[14] sitivity analysis of value-at-risk, Journal of Empirical Finance 7, 225-245.
    </li>
    <li block-type="ListItem">
     [15] Gourieroux, C. &amp; Liu, W. (2007). Converting Tail-VaR to VaR: an Econometric Study. CREST-DP.
    </li>
    <li block-type="ListItem">
     Gourieroux, C. &amp; Liu, W. (2009). Control and out-of-[16] sample validation of dependent risks, Journal of Risk and Insurance 75, 683-707.
    </li>
    <li block-type="ListItem">
     [17] Hosking, J. (1990). L-moments: analysis and estimation of distribution using linear combinations of order statistics, Journal of the Royal Statistical Society, B 52,
     <math display="inline">
      105 - 124
     </math>
     .
    </li>
    <li block-type="ListItem">
     [18] Jones, B. &amp; Zitikis, R. (2003). Empirical estimation of risk measures and related quantities, North-American Actuarial Journal 7, 44-54.
    </li>
    <li block-type="ListItem">
     [19] Koenker, R. (2005). Quantile Regression, Cambridge University Press.
    </li>
    <li block-type="ListItem">
     [20] Koenker, R. &amp; Xiao, Z. (2006). Quantile autoregression, JASA 101, 980-990.
    </li>
    <li block-type="ListItem">
     [21] Liu, W. (2007). Analysis of Risk Measures and Multidimensional Risk Dependence. PhD dissertation, University of Toronto.
    </li>
    <li block-type="ListItem">
     Schmeidler, D. (1989). Subjective probability and [22] expected utility without additivity,
     <i>
      Econometrica
     </i>
     57, 571-587.
    </li>
   </ul>
  </p>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     [23] Shorack, G. &amp; Wellner, J. (1986).
     <i>
      Empirical Processes with Applications to Statistics
     </i>
     , Wiley, New-York.
    </li>
    <li block-type="ListItem">
     [24] Uryasev, S. &amp; Rockafellar, R. (2000). Optimization of conditional value-at-risk,
     <i>
      Journal of Risk
     </i>
     <b>
      2
     </b>
     , 21–41.
    </li>
    <li block-type="ListItem">
     [25] Wang, S. (1996). Premium calculation by transforming the layer premium density,
     <i>
      ASTIN Bulletin
     </i>
     <b>
      26
     </b>
     , 71–92.
    </li>
    <li block-type="ListItem">
     [26] Wang, S. (2000). A class of distortion operators for pricing financial and insurance risks,
     <i>
      Journal of Risk and Insurance
     </i>
     <b>
      67
     </b>
     , 15–36.
    </li>
    <li block-type="ListItem">
     [27] Wang, S. &amp; Young, V. (1998). Ordering risks: expected utility theory versus Yaari's dual theory of risk,
     <i>
      Insurance: Mathematics and Economics
     </i>
     <b>
      22
     </b>
     , 145–161.
    </li>
    <li block-type="ListItem">
     [28] Yaari, M. (1987). The dual theory of choice under risk,
     <i>
      Econometrica
     </i>
     <b>
      55
     </b>
     , 95–115.
    </li>
   </ul>
  </p>
  <h1>
   <b>
    Further Reading
   </b>
  </h1>
  <p block-type="Text" class="has-continuation">
   Cont, R., Deguest, R. &amp; Scandolo, G. (2007).
   <i>
    Robustness and Sensitivity Analysis of Risk Measurement Procedures
   </i>
   ,
  </p>
  <p block-type="Text">
   Columbia University Financial Engineering Report No. 2007-06.
  </p>
  <p block-type="Text">
   Koenker, R. &amp; Zhao, Q., (1996). Conditional quantile estimation and inference for ARCH models,
   <i>
    Econometric Theory
   </i>
   <b>
    12
   </b>
   , 793–813.
  </p>
  <h1>
   <b>
    Related Articles
   </b>
  </h1>
  <p block-type="Text">
   <b>
    Backtesting
   </b>
   ;
   <b>
    Convex Risk Measures
   </b>
   ;
   <b>
    Expected Shortfall
   </b>
   ;
   <b>
    Market Risk
   </b>
   ;
   <b>
    Model Validation
   </b>
   ;
   <b>
    Multivariate Distributions
   </b>
   ;
   <b>
    Regulatory Capital
   </b>
   ;
   <b>
    Simulation-based Estimation
   </b>
   ;
   <b>
    Spectral Measures of Risk
   </b>
   ;
   <b>
    Stylized Properties of Asset Returns
   </b>
   ;
   <b>
    Valueat-Risk
   </b>
   .
  </p>
  <p block-type="Text">
   CHRISTIAN GOURIEROUX
  </p>
 </body>
</html>
