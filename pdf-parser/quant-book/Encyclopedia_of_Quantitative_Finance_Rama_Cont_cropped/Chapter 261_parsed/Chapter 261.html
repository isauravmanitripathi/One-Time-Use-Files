<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
 </head>
 <body>
  <h1>
   <b>
    Monte Carlo Simulation
   </b>
   for Stochastic Differential Equations
  </h1>
  <h2>
   <b>
    Weak Convergence Criterion
   </b>
  </h2>
  <p block-type="Text">
   There exists a well-developed literature on classical Monte Carlo methods. We might mention, among others, Hammersley and Handscomb [3] and Fishman [1]. This literature, however, does not focus on approximating functionals of solutions of stochastic differential equations (SDEs). Exploiting the stochastic analytic structure of the underlying SDEs in discrete-time approximations allows to obtain deeper insight and significant benefits in a Monte Carlo simulation. One can construct more efficient methods than usually would be obtained under the classical Monte Carlo approach. Monographs on Monte Carlo methods for SDEs include [6, 7, 10]. The area of Monte Carlo methods in finance is the focus of the well-written books by Jackel [5] and Glasserman [2]. In [12], one can find a brief survey of such methods. In many circumstances, when other numerical methods fail or are difficult to implement, Monte Carlo methods can still provide a reasonable answer. This applies, in particular, to problems involving a large number of factors.
  </p>
  <p block-type="TextInlineMath">
   First, let us introduce a criterion that provides a classification of different simulation schemes. In Monte Carlo simulation, one concentrates on the approximation of probabilities and expectations of payoffs. Consider the process
   <math display="inline">
    X = \{X_t, t \in [0, T]\},\
   </math>
   which is the solution of the SDE
  </p>
  <p block-type="Equation">
   <math display="block">
    dX_t = a(X_t) dt + b(X_t) dW_t
   </math>
   (1)
  </p>
  <p block-type="TextInlineMath">
   for
   <math display="inline">
    t \in [0, T]
   </math>
   with
   <math display="inline">
    X_0 \in \mathbb{R}
   </math>
   . We shall say that a discrete-time approximation
   <math display="inline">
    Y^{\Delta}
   </math>
   converges with weak
   <i>
    order
   </i>
   <math display="inline">
    \beta &gt; 0
   </math>
   to X at time T as
   <math display="inline">
    \Delta \rightarrow 0
   </math>
   if for each polynomial
   <math display="inline">
    g: \mathbb{R} \to \mathbb{R}
   </math>
   there exists a constant
   <math display="inline">
    C_g
   </math>
   , which does not depend on
   <math display="inline">
    \Delta
   </math>
   , and a
   <math display="inline">
    \Delta_0 \in [0, 1]
   </math>
   such that
  </p>
  <p block-type="Equation">
   <math display="block">
    \mu(\Delta) = |E(g(X_T)) - E(g(Y_T^{\Delta}))| \le C_g \,\Delta^{\beta} \qquad (2)
   </math>
  </p>
  <p block-type="TextInlineMath">
   for each
   <math display="inline">
    \Delta \in (0, \Delta_0)
   </math>
   . We call this also the
   <i>
    weak
   </i>
   convergence criterion.
  </p>
  <h1>
   <b>
    Systematic and Statistical Error
   </b>
  </h1>
  <p block-type="Text">
   Under the weak convergence criterion (2) functionals of the form
  </p>
  <p block-type="Equation">
   <math display="block">
    u = E(g(X_T)) \tag{3}
   </math>
  </p>
  <p block-type="Text">
   are approximated
   <i>
    via weak approximations
   </i>
   <math display="inline">
    Y^{\Delta}
   </math>
   of the solution of the SDE (1). One can form a raw Monte
   <i>
    Carlo estimate
   </i>
   by using the sample average
  </p>
  <p block-type="Equation">
   <math display="block">
    u_{N,\Delta} = \frac{1}{N} \sum_{k=1}^{N} g(Y_T^{\Delta}(\omega_k)) \tag{4}
   </math>
  </p>
  <p block-type="TextInlineMath">
   with N independent simulated realizations
   <math display="inline">
    Y_T^{\Delta}(\omega_1)
   </math>
   ,
   <math display="inline">
    Y_T^{\Delta}(\omega_2), \ldots, Y_T^{\Delta}(\omega_N)
   </math>
   of a discrete-time weak approximation
   <math display="inline">
    Y_T^{\Delta}
   </math>
   at time T, where
   <math display="inline">
    \omega_k \in \Omega
   </math>
   for
   <math display="inline">
    k \in
   </math>
   <math display="inline">
    \{1, 2, \ldots, N\}
   </math>
   . The corresponding weak error
   <math display="inline">
    \hat{\mu}_{N,\Delta}
   </math>
   has the form
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{\mu}_{N,\Delta} = u_{N,\Delta} - E(g(X_T)) \tag{5}
   </math>
  </p>
  <p block-type="Text">
   which we decompose into a
   <i>
    systematic error
   </i>
   <math display="inline">
    \mu_{\text{sys}}
   </math>
   and a
   <i>
    statistical error
   </i>
   <math display="inline">
    \mu_{\text{stat}}
   </math>
   , such that
  </p>
  <p block-type="Equation">
   <math display="block">
    \hat{\mu}_{N,\Delta} = \mu_{\text{sys}} + \mu_{\text{stat}} \tag{6}
   </math>
  </p>
  <p block-type="Text">
   Here, we set
  </p>
  <p block-type="Equation">
   <math display="block">
    \mu_{\text{sys}} = E(\hat{\mu}_{N,\Delta})
   </math>
   <br/>
   =
   <math>
    E\left(\frac{1}{N}\sum_{k=1}^{N}g(Y_{T}^{\Delta}(\omega_{k}))\right) - E(g(X_{T}))
   </math>
   <br/>
   =
   <math>
    E(g(Y_{T}^{\Delta})) - E(g(X_{T}))
   </math>
   (7)
  </p>
  <p block-type="Text">
   Thus, we have
  </p>
  <p block-type="Equation">
   <math display="block">
    \mu(\Delta) = |\mu_{\text{sys}}| \tag{8}
   </math>
  </p>
  <p block-type="Text">
   The absolute systematic error
   <math display="inline">
    |\mu_{\text{sys}}|
   </math>
   can be interpreted as the absolute weak error and is a critical variable under the weak convergence criterion (2).
  </p>
  <p block-type="TextInlineMath">
   For a large number
   <math display="inline">
    N
   </math>
   of simulated independent realizations of
   <math display="inline">
    Y^{\Delta}
   </math>
   , we can conclude from the central limit theorem that the statistical error
   <math display="inline">
    \mu_{\text{stat}}
   </math>
   becomes asymptotically Gaussian with mean 0 and variance of the form
  </p>
  <p block-type="Equation">
   <math display="block">
    \text{Var}(\mu_{\text{stat}}) = \text{Var}(\hat{\mu}_{N,\Delta}) = \frac{1}{N} \text{Var}(g(Y_T^{\Delta})) \qquad (9)
   </math>
  </p>
  <p block-type="Text">
   Note that in equation
   <math display="inline">
    (9)
   </math>
   we used the independence of the realization for each
   <math display="inline">
    \omega_k
   </math>
   . The expression (9) reveals a major disadvantage of the raw Monte Carlo method. One notes that the variance of the statistical error
   <math display="inline">
    \mu_{\text{stat}}
   </math>
   decreases only with
   <math display="inline">
    1/N
   </math>
   . Consequently, the deviation
  </p>
  <p block-type="Equation">
   <math display="block">
    \text{Dev}(\mu_{\text{stat}}) = \sqrt{\text{Var}(\mu_{\text{stat}})} = \frac{1}{\sqrt{N}} \sqrt{\text{Var}(g(Y_T^{\Delta}))}
   </math>
   (10)
  </p>
  <p block-type="TextInlineMath">
   of the statistical error decreases at only the slow rate
   <math display="inline">
    1/\sqrt{N}
   </math>
   as
   <math display="inline">
    N \to \infty
   </math>
   . This means that, unless one has to estimate the expectation of a random variable
   <math display="inline">
    g(Y_T^{\Delta})
   </math>
   with a small variance, one may need an extremely large number
   <math display="inline">
    N
   </math>
   of sample paths to achieve a reasonably small confidence interval. However, there exist various
   <i>
    variance reduction techniques
   </i>
   (see
   <b>
    Variance Reduction
   </b>
   ), that deal with this problem.
  </p>
  <p block-type="Text">
   We shall discuss now discrete-time approximations of solutions of SDEs that are appropriate for the Monte Carlo simulation of derivative prices or other functionals of diffusion processes. This means that we study the weak order of convergence of discretetime approximations. By truncating appropriately the Wagner-Platen expansion (see Stochastic Taylor
   <b>
    Expansions
   </b>
   ) one obtains
   <i>
    weak Taylor schemes
   </i>
   . The desired order of weak convergence determines the kind of truncation that must be used [6]. However, the truncations will be different from those required for the strong convergence of a comparable order, as described in Stochastic Differential Equations: Scenario Simulation. In general, weak Taylor schemes involve fewer terms compared with the strong Taylor schemes of the same order.
  </p>
  <h2>
   <b>
    Euler and Simplified Weak Euler Scheme
   </b>
  </h2>
  <p block-type="Text">
   The simplest weak Taylor scheme is the Euler scheme (see also
   <b>
    Stochastic Taylor Expansions
   </b>
   ), which has the form
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + a \Delta + b \Delta W_n \tag{11}
   </math>
  </p>
  <p block-type="TextInlineMath">
   with
   <math display="inline">
    \Delta W_n = W_{\tau_{n+1}} - W_{\tau_n}
   </math>
   and initial value
   <math display="inline">
    Y_0 = X_0
   </math>
   , where
   <math display="inline">
    \tau_n = n\Delta
   </math>
   ,
   <math display="inline">
    \Delta &gt; 0
   </math>
   . Here and in the following, we suppress in our notation of coefficient functions, as a and b, the dependence on
   <math display="inline">
    \tau_n
   </math>
   and
   <math display="inline">
    Y_n
   </math>
   .
  </p>
  <p block-type="Text">
   The Euler scheme (11) corresponds to the truncated Wagner-Platen expansion that contains only the time integral and the single It√¥ integral with respect to the Wiener process. The Euler scheme has order of weak convergence
   <math display="inline">
    \beta = 1.0
   </math>
   if the drift and diffusion coefficient are sufficiently smooth and regular.
  </p>
  <p block-type="Text">
   For weak convergence, we only need to approximate the probability measure induced by the process
   <math display="inline">
    X
   </math>
   . Here, we can replace the Gaussian increments
   <math display="inline">
    \Delta W_n
   </math>
   in (11) by other simpler random variables
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   with similar moment properties as
   <math display="inline">
    \Delta W_n
   </math>
   . We can thus obtain a simpler scheme by choosing more easily generated random variables. This leads to the
   <i>
    simplified
   </i>
   weak Euler scheme
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + a \Delta + b \Delta \hat{W}_n \tag{12}
   </math>
  </p>
  <p block-type="Text">
   where the
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   are independent random variables with moments satisfying the moment-matching condition
  </p>
  <p block-type="Equation">
   <math display="block">
    \left| E\left(\Delta \hat{W}_{n}\right) \right| + \left| E\left(\left(\Delta \hat{W}_{n}\right)^{3}\right) \right|
   </math>
   <br/>
   +
   <math display="block">
    \left| E\left(\left(\Delta \hat{W}_{n}\right)^{2}\right) - \Delta \right| \leq K \Delta^{2}
   </math>
   (13)
  </p>
  <p block-type="TextInlineMath">
   for some constant
   <math display="inline">
    K
   </math>
   . The simplest example of such a simplified random variable
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   to be used in equation (12) is a two-point distributed random variable with
  </p>
  <p block-type="Equation">
   <math display="block">
    P\left(\Delta\hat{W}_n = \pm\sqrt{\Delta}\right) = 1/2\tag{14}
   </math>
  </p>
  <p block-type="TextInlineMath">
   When the drift and diffusion coefficients are only H√∂lder continuous, then it has been shown in
   <math display="inline">
    [8]
   </math>
   that the Euler scheme still converges weakly, but with some weak order
   <math display="inline">
    \beta &lt; 1.0
   </math>
   .
  </p>
  <h4>
   Weak Order 2.0 Taylor Scheme
  </h4>
  <p block-type="Text">
   Now, let us consider the Taylor scheme of weak order
   <math display="inline">
    \beta = 2.0
   </math>
   . This scheme is obtained by adding all of the double stochastic integrals from the Wagner-Platen expansion to the terms of the Euler scheme, as shown in Stochastic Taylor Expansions. This scheme was
  </p>
  <p block-type="Text">
   first proposed in [9]. The weak order 2.0 Taylor
   <i>
    scheme
   </i>
   has the form
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + a \Delta + b \Delta W_n + \frac{1}{2} b b' \left\{ (\Delta W_n)^2 - \Delta \right\}
   </math>
   <br/>
   +
   <math>
    a' b \Delta Z_n + \frac{1}{2} \left( a a' + \frac{1}{2} a'' b^2 \right) \Delta^2
   </math>
   <br/>
   +
   <math>
    \left( a b' + \frac{1}{2} b'' b^2 \right) \left\{ \Delta W_n \Delta - \Delta Z_n \right\}
   </math>
   (15)
  </p>
  <p block-type="TextInlineMath">
   The random variable
   <math display="inline">
    \Delta Z_n = \int_{\tau_n}^{\tau_{n+1}} \int_{\tau_n}^{s_2} dW_{s_1} ds_2
   </math>
   represents a stochastic double integral. One can easily generate the pair of correlated Gaussian random variables
   <math display="inline">
    \Delta W_n
   </math>
   and
   <math display="inline">
    \Delta Z_n
   </math>
   from independent Gaussian random variables.
  </p>
  <p block-type="Text">
   Under the weak convergence criterion, one has more freedom than under the strong convergence criterion (see Stochastic Differential Equations: Scenario Simulation) in constructing the random variables in a discrete-time weak approximation. For instance, from the above scheme, one can derive the simplified weak order 2.0 Taylor scheme
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + a \Delta + b \Delta \hat{W}_n
   </math>
   <br/>
   + 1/2 b b'
   <math>
    \left\{ \left( \Delta \hat{W}_n \right)^2 - \Delta \right\}
   </math>
   <br/>
   + 1/2
   <math>
    (a' b + a b' + 1/2 b'' b^2) \Delta \hat{W}_n \Delta
   </math>
   <br/>
   + 1/2
   <math>
    (a a' + 1/2 a'' b^2) \Delta^2
   </math>
   (16)
  </p>
  <p block-type="Text">
   Here the simplified random variable
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   must satisfy the moment-matching condition
  </p>
  <p block-type="Equation">
   <math display="block">
    \left| E\left(\Delta \hat{W}_{n}\right) \right| + \left| E\left(\left(\Delta \hat{W}_{n}\right)^{3}\right) \right|
   </math>
   <br/>
   +
   <math display="block">
    \left| E\left(\left(\Delta \hat{W}_{n}\right)^{5}\right) \right| + \left| E\left(\left(\Delta \hat{W}_{n}\right)^{2}\right) - \Delta \right|
   </math>
   <br/>
   +
   <math display="block">
    \left| E\left(\left(\Delta \hat{W}_{n}\right)^{4}\right) - 3\Delta^{2} \right| \leq K \Delta^{3}
   </math>
   <br/>
   (17)
  </p>
  <p block-type="Text" class="has-continuation">
   for some constant K. For instance, an
   <math display="inline">
    N(0, \Delta)
   </math>
   Gaussian distributed random variable satisfies the
  </p>
  <p block-type="Text">
   condition (17). So also does a three-point distributed random variable
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   with
  </p>
  <p block-type="Equation">
   <math display="block">
    P\left(\Delta \hat{W}_n = \pm \sqrt{3\Delta}\right) = \frac{1}{6} \quad \text{and}
   </math>
   <math display="block">
    P\left(\Delta \hat{W}_n = 0\right) = \frac{2}{3} \tag{18}
   </math>
  </p>
  <p block-type="Text">
   Under appropriate conditions on the drift and diffusion coefficients, the scheme converges with weak order 2.0 [6].
  </p>
  <h2>
   Weak Order 3.0 Taylor Scheme
  </h2>
  <p block-type="TextInlineMath">
   As shown in [6], Taylor schemes of weak order
   <math display="inline">
    \beta = 3.0
   </math>
   need to include from the Wagner‚ÄìPlaten expansion all of the multiple It√¥ integrals of up to multiplicity three. The following simplified weak order 3.0 Taylor scheme can he obtained
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + a \Delta + b \Delta \tilde{W}_n + \frac{1}{2} L^1 b \left\{ \left( \Delta \tilde{W}_n \right)^2 - \Delta \right\}
   </math>
   <br/>
   +
   <math>
    L^1 a \Delta \tilde{Z}_n + \frac{1}{2} L^0 a \Delta^2 + L^0 b
   </math>
   <br/>
   <math>
    \times \left\{ \Delta \tilde{W}_n \Delta - \Delta \tilde{Z}_n \right\}
   </math>
   <br/>
   +
   <math>
    \frac{1}{6} \left( L^0 L^0 b + L^0 L^1 a + L^1 L^0 a \right) \Delta \tilde{W}_n \Delta^2
   </math>
   <br/>
   +
   <math>
    \frac{1}{6} \left( L^1 L^1 a + L^1 L^0 b + L^0 L^1 b \right)
   </math>
   <br/>
   <math>
    \times \left\{ \left( \Delta \tilde{W}_n \right)^2 - \Delta \right\} \Delta
   </math>
   <br/>
   +
   <math>
    \frac{1}{6} L^0 L^0 a \Delta^3 + \frac{1}{6} L^1 L^1 b
   </math>
   <br/>
   <math>
    \times \left\{ \left( \Delta \tilde{W}_n \right)^2 - 3\Delta \right\} \Delta \tilde{W}_n
   </math>
   (19)
  </p>
  <p block-type="Text">
   Here
   <math display="inline">
    \Delta \tilde{W}_n
   </math>
   and
   <math display="inline">
    \Delta \tilde{Z}_n
   </math>
   are correlated Gaussian random variables with
  </p>
  <p block-type="Equation">
   <math display="block">
    \Delta \tilde{W}_n \sim N(0, \Delta), \qquad \Delta \tilde{Z}_n \sim N\left(0, 1/3 \,\Delta^3\right)\n
   </math>
   (20)
  </p>
  <p block-type="Text">
   and covariance
  </p>
  <p block-type="Equation">
   <math display="block">
    E\left(\Delta\tilde{W}_n\,\Delta\tilde{Z}_n\right) = 1/2\,\Delta^2\tag{21}
   </math>
  </p>
  <p block-type="Text">
   Furthermore, we use here the operators
  </p>
  <p block-type="Equation">
   <math display="block">
    L^{0} = \frac{\partial}{\partial t} + a \frac{\partial}{\partial x} + \frac{1}{2} b^{2} \frac{\partial^{2}}{\partial x^{2}}
   </math>
   (22)
  </p>
  <p block-type="TextInlineMath">
   and
   <math display="inline">
    L^1 = b \frac{\partial}{\partial x}
   </math>
  </p>
  <h2>
   Weak Order 4.0 Taylor Scheme
  </h2>
  <p block-type="Text">
   To construct the weak order 4.0 Taylor scheme, we also need to include all of the fourth-order multiple stochastic integrals from the Wagner-Platen expansion.
  </p>
  <p block-type="Text">
   In the case of particular SDEs, for instance those with additive noise, one obtains highly accurate schemes in this manner. For accurate Monte Carlo simulation, the following
   <i>
    simplified weak order
   </i>
   4.0
   <i>
    Taylor scheme for additive noise
   </i>
   can be used:
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + a \Delta + b \Delta \tilde{W}_n + \frac{1}{2} L^0 a \Delta^2
   </math>
   <br/>
   +
   <math>
    L^1 a \Delta \tilde{Z}_n + L^0 b \left\{ \Delta \tilde{W}_n \Delta - \Delta \tilde{Z}_n \right\}
   </math>
   <br/>
   +
   <math>
    \frac{1}{3!} \left\{ L^0 L^0 b + L^0 L^1 a \right\} \Delta \tilde{W}_n \Delta^2
   </math>
   <br/>
   +
   <math>
    L^1 L^1 a \left\{ 2 \Delta \tilde{W}_n \Delta \tilde{Z}_n - \frac{5}{6} \left( \Delta \tilde{W}_n \right)^2 \Delta \right\}
   </math>
   <br/>
   -
   <math>
    \frac{1}{6} \Delta^2 \right\}
   </math>
   <br/>
   +
   <math>
    \frac{1}{3!} L^0 L^0 a \Delta^3 + \frac{1}{4!} L^0 L^0 L^0 a \Delta^4
   </math>
   <br/>
   +
   <math>
    \frac{1}{4!} \left\{ L^1 L^0 L^0 a + L^0 L^1 L^0 a \right\}
   </math>
   <br/>
   +
   <math>
    L^0 L^0 L^1 a + L^0 L^0 L^0 b \right\} \Delta \tilde{W}_n \Delta^3
   </math>
   <br/>
   +
   <math>
    \frac{1}{4!} \left\{ L^1 L^1 L^0 a + L^0 L^1 L^1 a + L^1 L^0 L^1 a \right\}
   </math>
   <br/>
   <math>
    \times \left\{ \left( \Delta \tilde{W}_n \right)^2 - \Delta \right\} \Delta^2
   </math>
   <br/>
   +
   <math>
    \frac{1}{4!} L^1 L^1 L^1 a \Delta \tilde{W}_n \left\{ \left( \Delta \tilde{W}_n \right)^2 - 3\Delta \right\} \Delta \right\} \Delta
   </math>
   <br/>
   (23)
  </p>
  <p block-type="TextInlineMath">
   Here
   <math display="inline">
    \Delta \tilde{W}_n
   </math>
   and
   <math display="inline">
    \Delta \tilde{Z}_n
   </math>
   are correlated Gaussian random variables with
   <math display="inline">
    \Delta \tilde{W}_n \sim N(0, \Delta), \ \Delta \tilde{Z}_n \sim N(0, \frac{1}{2}\Delta^3)
   </math>
   and
   <math display="inline">
    E(\Delta \tilde{W}_n \Delta \tilde{Z}_n) = \frac{1}{2} \Delta^2
   </math>
   . The weak order of convergence of the above schemes is derived in [6].
  </p>
  <h1>
   <b>
    Explicit Weak Schemes
   </b>
  </h1>
  <p block-type="Text">
   Higher order weak Taylor schemes require the evaluation of derivatives of various orders of the drift and diffusion coefficients. We can construct derivativefree discrete-time weak approximations, which avoid the use of such derivatives.
  </p>
  <p block-type="Text">
   The following
   <i>
    explicit weak order
   </i>
   2.0
   <i>
    scheme
   </i>
   was suggested by Platen
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + 1/2 \left( a \left( \bar{\Upsilon}_n \right) + a \right) \Delta
   </math>
   <br/>
   + 1/4 \left( b \left( \bar{\That{\Theta}}_n^+ \right) + b \left( \bar{\Theta}_n^- \right) + 2b \right) \Delta \hat{W}_n \right)
   <br/>
   + 1/4 \left( b \left( \bar{\Theta}_n^+ \right) - b \left( \bar{\Theta}_n^- \right) \right)
   <br/>
   \times \left\{ \left( \Delta \hat{W}_n \right)^2 - \Delta \right\} \Delta^{1/2} \qquad (24)
  </p>
  <p block-type="Text">
   with supporting values
  </p>
  <p block-type="Equation">
   <math display="block">
    \bar{\Upsilon}_n = Y_n + a \,\Delta + b \,\Delta \hat{W}_n \tag{25}
   </math>
  </p>
  <p block-type="Text">
   and
  </p>
  <p block-type="Equation">
   <math display="block">
    \bar{\Upsilon}_{n}^{\pm} = Y_{n} + a \,\Delta \pm b \,\sqrt{\Delta} \tag{26}
   </math>
  </p>
  <p block-type="Text">
   Here
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   is required to satisfy the moment condition (17). This means,
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   can be, for instance, Gaussian or three-point distributed with
  </p>
  <p block-type="Equation">
   <math display="block">
    P\left(\Delta \hat{W}_n = \pm \sqrt{3\Delta}\right) = 1/6
   </math>
   and
   <br/>
   <math>
    P\left(\Delta \hat{W}_n = 0\right) = 2/3
   </math>
   (27)
  </p>
  <p block-type="Text">
   By comparing equation
   <math display="inline">
    (24)
   </math>
   with the corresponding simplified weak Taylor scheme (16), one notes that equation
   <math display="inline">
    (24)
   </math>
   avoids the derivatives that appear in equation
   <math display="inline">
    (16)
   </math>
   by using additional supporting values.
  </p>
  <p block-type="Text">
   For
   <i>
    additive noise
   </i>
   the second-order weak scheme
   <math display="inline">
    (24)
   </math>
   reduces to the relatively simple algorithm
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + 1/2 \left\{ a \left( Y_n + a \Delta + b \Delta \hat{W}_n^j \right) + a \right\} \Delta
   </math>
   <math display="block">
    + b \Delta \hat{W}_n^j \tag{28}
   </math>
  </p>
  <p block-type="Text">
   For the case with additive noise, one finds in [6] the explicit weak order 3.0 scheme
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + a \Delta + b \Delta \hat{W}_n
   </math>
   <br/>
   +
   <math>
    \frac{1}{2} \left( a_{\zeta_n}^+ + a_{\zeta_n}^- - \frac{3}{2} a - \frac{1}{4} \left( \tilde{a}_{\zeta_n}^+ + \tilde{a}_{\zeta_n}^- \right) \right) \Delta
   </math>
   <br/>
   +
   <math>
    \sqrt{\frac{2}{\Delta}} \left( \frac{1}{\sqrt{2}} \left( a_{\zeta_n}^+ - a_{\zeta_n}^- \right) - \frac{1}{4} \left( \tilde{a}_{\zeta_n}^+ - \tilde{a}_{\zeta_n}^- \right) \right) \zeta_n \Delta \hat{Z}_n
   </math>
   <br/>
   +
   <math>
    \frac{1}{6} \Big[ a \left( Y_n + \left( a + a_{\zeta_n}^+ \right) \Delta + \left( \zeta_n + \varrho_n \right) b \sqrt{\Delta} \right) - a_{\zeta_n}^+ - a_{\varrho_n}^+ + a \Big]
   </math>
   <br/>
   <math>
    \times \Big[ \left( \zeta_n + \varrho_n \right) \Delta \hat{W}_n \sqrt{\Delta} + \Delta
   </math>
   <br/>
   +
   <math>
    \zeta_n \varrho_n \left\{ \left( \Delta \hat{W}_n \right)^2 - \Delta \right\} \Big]
   </math>
   (29)
  </p>
  <p block-type="Text">
   with
  </p>
  <p block-type="Equation">
   <math display="block">
    a_{\phi}^{\pm} = a \left( Y_n + a \Delta \pm b \sqrt{\Delta} \phi \right) \tag{30}
   </math>
  </p>
  <p block-type="Text">
   and
  </p>
  <p block-type="Equation">
   <math display="block">
    \tilde{a}_{\phi}^{\pm} = a \left( Y_n + 2a \Delta \pm b \sqrt{2\Delta} \phi \right) \tag{31}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    \phi
   </math>
   is either
   <math display="inline">
    \zeta_n
   </math>
   or
   <math display="inline">
    \varrho_n
   </math>
   . Here, one can use two correlated Gaussian random variables
   <math display="inline">
    \Delta \hat{W}_n \sim N(0, \Delta)
   </math>
   and
   <math display="inline">
    \Delta \hat{Z}_n \sim N(0, 1/3 \Delta^3)
   </math>
   with
   <math display="inline">
    E(\Delta \hat{W}_n \Delta \hat{Z}_n) =
   </math>
   <math display="inline">
    1/2\Delta^2
   </math>
   , together with two independent two-point distributed random variables
   <math display="inline">
    \zeta_n
   </math>
   and
   <math display="inline">
    \varrho_n
   </math>
   with
  </p>
  <p block-type="Equation">
   <math display="block">
    P(\zeta_n = \pm 1) = P(\varrho_n = \pm 1) = 1/2 \qquad (32)
   </math>
  </p>
  <h2>
   <b>
    Extrapolation Methods
   </b>
  </h2>
  <p block-type="TextInlineMath">
   Extrapolation provides an efficient, yet simple way of obtaining a higher order weak approximation when using only lower order weak schemes. Only equidistant time discretizations of the time interval
   <math display="inline">
    [0, T]
   </math>
   with
   <math display="inline">
    \tau_{n_T} = T
   </math>
   are used in what follows. As before, we denote the considered discrete-time approximation with time step size
   <math display="inline">
    \Delta &gt; 0
   </math>
   by
   <math display="inline">
    Y^{\Delta}
   </math>
   , with value
   <math display="inline">
    Y_{\tau_n}^{\Delta} = Y_n^{\Delta}
   </math>
   at the discretization time
   <math display="inline">
    \tau_n
   </math>
   , and the corresponding approximation with twice this step size by
   <math display="inline">
    Y^{2\Delta}
   </math>
   , and so on.
  </p>
  <p block-type="Text">
   Suppose that we have evaluated
   <i>
    via
   </i>
   simulation the functional
   <math display="inline">
    \sim
   </math>
   A
  </p>
  <p block-type="Equation">
   <math display="block">
    E\left(g\left(Y_{T}^{\Delta}\right)\right)
   </math>
  </p>
  <p block-type="Text">
   of a weak order 1.0 approximation using, say, the Euler scheme (11) or the simplified Euler scheme (12) with step size
   <math display="inline">
    \Delta
   </math>
   . Let us repeat this Monte Carlo simulation with the double step size
   <math display="inline">
    2\Delta
   </math>
   to obtain a Monte Carlo estimate of the functional
  </p>
  <p block-type="Equation">
   <math display="block">
    E\left(g\left(Y_{T}^{2\Delta}\right)\right)
   </math>
  </p>
  <p block-type="Text">
   We can then combine these two functionals to obtain the
   <i>
    weak order
   </i>
   2.0
   <i>
    extrapolation
   </i>
  </p>
  <p block-type="Equation">
   <math display="block">
    V_{g,2}^{\Delta}(T) = 2E\left(g\left(Y_{T}^{\Delta}\right)\right) - E\left(g\left(Y_{T}^{2\Delta}\right)\right) \tag{33}
   </math>
  </p>
  <p block-type="Text">
   which was proposed in [13]. It is a stochastic generalization of the well-known
   <i>
    Richardson extrapolation
   </i>
   .
  </p>
  <p block-type="TextInlineMath">
   As is shown in [6], if a weak method exhibits a certain representation of the leading error term, then a corresponding extrapolation method can be constructed. For instance, one can use a weak order
   <math display="inline">
    \beta = 2.0
   </math>
   approximation
   <math display="inline">
    Y^{\Delta}
   </math>
   and extrapolate it to obtain a fourth-order weak approximation of the targeted functional. A
   <i>
    weak order
   </i>
   4.0
   <i>
    extrapolation
   </i>
   has the form
  </p>
  <p block-type="Equation">
   <math display="block">
    V_{g,4}^{\Delta}(T) = 1/21 \bigg[ 32 E \left( g \left( Y_T^{\Delta} \right) \right)
   </math>
   <math display="block">
    - 12 E \left( g \left( Y_T^{2\Delta} \right) \right) + E \left( g \left( Y_T^{4\Delta} \right) \right) \bigg]
   </math>
   (34)
  </p>
  <p block-type="Text">
   Suitable weak order 2.0 approximations include the weak order 2.0 Taylor scheme (15), the simplified weak order
   <math display="inline">
    2.0
   </math>
   Taylor scheme (16), and the explicit weak order
   <math display="inline">
    2.0
   </math>
   scheme (24).
  </p>
  <p block-type="Text">
   The practical use of extrapolations of discrete time approximations depends strongly on the numerical stability of the underlying weak schemes. These weak methods need to have almost identical leading error coefficients for a wide range of step sizes and should yield numerically stable simulation results; see Stochastic Differential Equations: Scenario Simulation.
  </p>
  <h2>
   Implicit Methods
  </h2>
  <p block-type="Text" class="has-continuation">
   In Monte Carlo simulation, the numerical stability of a scheme has highest priority. Introducing some
  </p>
  <p block-type="Text">
   type of implicitness into a scheme usually improves its numerical stability. The simplest implicit weak schemes can be found in the family of drift implicit simplified Euler schemes
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + \{(1 - \alpha) a(Y_n) + \alpha a(Y_{n+1})\} \Delta
   </math>
   <br/>
   +
   <math>
    b(Y_n) \Delta \hat{W}_n
   </math>
   (35)
  </p>
  <p block-type="Text">
   where the random variables
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   are independent two-point distributed with
  </p>
  <p block-type="Equation">
   <math display="block">
    P\left(\Delta\hat{W}_n = \pm\sqrt{\Delta}\right) = 1/2\tag{36}
   </math>
  </p>
  <p block-type="TextInlineMath">
   The parameter
   <math display="inline">
    \alpha
   </math>
   is the
   <i>
    degree of drift implicitness
   </i>
   . With
   <math display="inline">
    \alpha = 0
   </math>
   , the scheme (35) reduces to the simplified Euler scheme (12), whereas with
   <math display="inline">
    \alpha = 0.5
   </math>
   it represents a stochastic generalization of the trapezoidal method. Under sufficient regularity conditions, one can show that the scheme (35) converges with weak order
   <math display="inline">
    \beta = 1.0
   </math>
   . The scheme (35) is A-stable for
   <math display="inline">
    \alpha \in [0.5, 1]
   </math>
   , whereas for
   <math display="inline">
    \alpha \in [0, 0.5)
   </math>
   its region of A-stability, in the sense of what is discussed in Stochastic
   <b>
    Differential Equations: Scenario Simulation
   </b>
   , is the interior of the interval that begins at
   <math display="inline">
    -2(1-2\alpha)^{-1}
   </math>
   and finishes at 0.
  </p>
  <p block-type="Text">
   The possible use of bounded random variables in weak simplified schemes allows us to construct fully implicit weak schemes that is, algorithms where also the approximate diffusion term becomes implicit.
  </p>
  <p block-type="Text">
   The fully implicit weak Euler scheme has the form
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + \bar{a}(Y_{n+1}) \Delta + b(Y_{n+1}) \Delta \hat{W}_n \qquad (37)
   </math>
  </p>
  <p block-type="TextInlineMath">
   where
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   is as in equation (35) and
   <math display="inline">
    \bar{a}
   </math>
   is some adjusted drift coefficient defined by
  </p>
  <p block-type="Equation">
   <math display="block">
    \bar{a} = a - b \, b' \tag{38}
   </math>
  </p>
  <p block-type="Text">
   The drift adjustment is necessary, otherwise the approximation would not converge toward the correct solution of the given It√¥ SDE.
  </p>
  <p block-type="Text">
   We also mention a family of implicit weak Euler schemes
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + \left\{ \alpha \, \bar{a}_{\eta}(Y_{n+1}) + (1 - \alpha) \, \bar{a}_{\eta}(Y_n) \right\} \Delta
   </math>
   <math display="block">
    + \left\{ \eta \, b(Y_{n+1}) + (1 - \eta) \, b(Y_n) \right\} \Delta \hat{W}_n \tag{39}
   </math>
  </p>
  <p block-type="TextInlineMath">
   where the random variables
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   are as in equation (35) and the corrected drift coefficient
   <math display="inline">
    \bar{a}_{\eta}
   </math>
   is defined
  </p>
  <p block-type="Text">
   as
  </p>
  <p block-type="Equation">
   <math display="block">
    \bar{a}_{\eta} = a - \eta \, b \, \frac{\partial b}{\partial x} \tag{40}
   </math>
  </p>
  <p block-type="TextInlineMath">
   for
   <math display="inline">
    \alpha, \eta \in [0, 1]
   </math>
   .
  </p>
  <p block-type="Text">
   One can avoid the calculation of derivatives in the above family of implicit schemes by using differences instead. The following
   <i>
    implicit weak order
   </i>
   2.0
   <i>
    scheme
   </i>
   can be found in
   <math display="inline">
    [11]
   </math>
   , where
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + 1/2 \ (a + a \ (Y_{n+1})) \ \Delta
   </math>
   <br/>
   + 1/4 \ \ (b \ (\tilde{\gamma}_n^+) + b \ (\tilde{\gamma}_n^-) + 2 b \) \ \ \Delta \hat{W}_n \\
   <br/>
   + 1/4 \ (b \ (\tilde{\gamma}_n^+) - b \ (\tilde{\gamma}_n^-) \) \
   <br/>
   \ \ \ \ \ \ \left( \Delta \hat{W}_n \right)^2 - \Delta \right\} \ \Delta^{-1/2} \qquad (41)
  </p>
  <p block-type="Text">
   with supporting values
  </p>
  <p block-type="Equation">
   <math display="block">
    \bar{\Upsilon}_{n}^{\pm} = Y_{n} + a \,\Delta \pm b \,\sqrt{\Delta} \tag{42}
   </math>
  </p>
  <p block-type="TextInlineMath">
   Here, the random variable
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   can be chosen as in (18).
  </p>
  <p block-type="TextInlineMath">
   Note that the scheme
   <math display="inline">
    (39)
   </math>
   is A-stable. In [6], it is shown that the above second-order weak scheme converges under appropriate conditions with weak order
   <math display="inline">
    \beta = 2.0
   </math>
   .
  </p>
  <h1>
   <b>
    Weak Predictor-Corrector Methods
   </b>
  </h1>
  <p block-type="Text">
   In general, implicit schemes require an algebraic equation to be solved at each time step. This imposes an additional computational burden. However, without giving a weak scheme some kind of implicitness the simulation might not turn out to be of much practical use due to inherent numerical instabilities.
  </p>
  <p block-type="Text">
   Predictor-corrector methods are similar to implicit methods but do not require the solution of an algebraic equation at each time step. They are used mainly because of their good numerical stability properties, which they inherit from the implicit counterparts of their corrector. The following predictor-corrector methods can be found in [11].
  </p>
  <p block-type="Text">
   One has the following family of weak order 1.0
   <i>
    predictor‚Äìcorrector methods
   </i>
   with corrector
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + \left\{ \alpha \, \bar{a}_{\eta}(\bar{Y}_{n+1}) + (1 - \alpha) \, \bar{a}_{\eta}(Y_n) \right\} \Delta
   </math>
   <math display="block">
    + \left\{ \eta \, b(\bar{Y}_{n+1}) + (1 - \eta) \, b(Y_n) \right\} \Delta \hat{W}_n \tag{43}
   </math>
  </p>
  <p block-type="TextInlineMath">
   for
   <math display="inline">
    \alpha, \eta \in [0, 1]
   </math>
   , where
  </p>
  <p block-type="Equation">
   <math display="block">
    \bar{a}_{\eta} = a - \eta \, b \, \frac{\partial b}{\partial x} \tag{44}
   </math>
  </p>
  <p block-type="Text">
   and with predictor
  </p>
  <p block-type="Equation">
   <math display="block">
    \bar{Y}_{n+1} = Y_n + a \,\Delta + b \,\Delta \hat{W}_n \tag{45}
   </math>
  </p>
  <p block-type="Text">
   Here, the random variables
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   are as in (14). Note that the corrector (43) with
   <math display="inline">
    \eta &gt; 0
   </math>
   allows to include some implicitness in the diffusion terms. This scheme often provides efficient and numerically reliable methods for appropriate choices of
   <math display="inline">
    \alpha
   </math>
   and
   <math display="inline">
    \eta
   </math>
   . By performing the Monte Carlo simulation with different parameter choices for
   <math display="inline">
    \alpha
   </math>
   and
   <math display="inline">
    \eta
   </math>
   one can obtain useful information about the numerical stability of the scheme for the given application.
  </p>
  <p block-type="Text">
   A weak order 2.0 predictor‚Äìcorrector method is obtained by choosing as corrector
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + 1/2 \left\{ a \left( \bar{Y}_{n+1} \right) + a \right\} \Delta + \Psi_n \qquad (46)
   </math>
  </p>
  <p block-type="Text">
   with
  </p>
  <p block-type="Equation">
   <math display="block">
    \Psi_n = b \,\Delta \hat{W}_n + 1/2 \,b \,b' \left\{ \left( \Delta \hat{W}_n \right)^2 - \Delta \right\} \\
+ 1/2 \left( a \,b' + \frac{1}{2} \,b^2 \,b'' \right) \Delta \hat{W}_n \,\Delta \tag{47}
   </math>
  </p>
  <p block-type="Text">
   and as predictor
  </p>
  <p block-type="Equation">
   <math display="block">
    \bar{Y}_{n+1} = Y_n + a \Delta + \Psi_n + 1/2 a' b \Delta \hat{W}_n \Delta + 1/2 (a a' + 1/2 a'' b^2) \Delta^2
   </math>
   (48)
  </p>
  <p block-type="Text">
   Here the random variable
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   can be, for instance,
   <math display="inline">
    N(0, \Delta)
   </math>
   Gaussian or three-point distributed as in equation
   <math display="inline">
    (18)
   </math>
   .
  </p>
  <p block-type="Text">
   Another derivative-free weak order 2.0 predic
   <i>
    tor-corrector method
   </i>
   has corrector
  </p>
  <p block-type="Equation">
   <math display="block">
    Y_{n+1} = Y_n + 1/2 \left\{ a \left( \bar{Y}_{n+1} \right) + a \right\} \Delta + \phi_n \qquad (49)
   </math>
  </p>
  <p block-type="Text">
   where
  </p>
  <p block-type="Equation">
   <math display="block">
    \phi_n = 1/4 \left( b \left( \bar{\Upsilon}_n^+ \right) + b \left( \bar{\Upsilon}_n^- \right) + 2 b \right) \Delta \hat{W}_n \n+ 1/4 \left( b \left( \bar{\Upsilon}_n^+ \right) - b \left( \bar{\Upsilon}_n^- \right) \right) \n\times \left\{ \left( \Delta \hat{W}_n \right)^2 - \Delta \right\} \Delta^{-1/2} \n
   </math>
   (50)
  </p>
  <p block-type="Text">
   with supporting values
  </p>
  <p block-type="Equation">
   <math display="block">
    \bar{\Upsilon}_n^{\pm} = Y_n + a \,\Delta \pm b \,\sqrt{\Delta} \tag{51}
   </math>
  </p>
  <p block-type="Text">
   and with predictor
  </p>
  <p block-type="Equation">
   <math display="block">
    \bar{Y}_{n+1} = Y_n + 1/2 \left\{ a \left( \bar{\Upsilon}_n \right) + a \right\} \Delta + \phi_n \qquad (52)
   </math>
  </p>
  <p block-type="Text">
   using the supporting value
  </p>
  <p block-type="Equation">
   <math display="block">
    \bar{\Upsilon}_n = Y_n + a \,\Delta + b \,\Delta \hat{W}_n \tag{53}
   </math>
  </p>
  <p block-type="Text">
   Here the random variable
   <math display="inline">
    \Delta \hat{W}_n
   </math>
   can be chosen as in equation
   <math display="inline">
    (18)
   </math>
   .
  </p>
  <p block-type="Text">
   Predictor-corrector methods of the above kind have been successfully used in the Monte Carlo simulation of various asset price models, see, for instance, [4].
  </p>
  <h2>
   References
  </h2>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     Fishman, G.S. (1996). Monte Carlo: Concepts, Algo-[1] rithms and Applications, Springer.
    </li>
    <li block-type="ListItem">
     Glasserman, P. (2004). Monte Carlo Methods in Finan-[2] cial Engineering, Applied Mathematics, Springer, Vol. 53.
    </li>
    <li block-type="ListItem">
     Hammersley, J.M. &amp; Handscomb, D.C. (1964). Monte [3] Carlo Methods, Methuen, London.
    </li>
    <li block-type="ListItem">
     Hunter, C.J., J√§ckel, P. &amp; Joshi, M.S. (2001). Getting [4] the drift, Risk
     <math display="inline">
      14(7)
     </math>
     ,
     <math display="inline">
      81-84
     </math>
     .
    </li>
    <li block-type="ListItem">
     [5] J√§ckel, P. (2002). Monte Carlo Methods in Finance, John Wiley &amp; Sons.
    </li>
    <li block-type="ListItem">
     Kloeden, P.E. &amp; Platen, E. (1999). Numerical Solution of [6] Stochastic Differential Equations, Applied Mathematics, Springer, Vol. 23 (Third Printing).
    </li>
   </ul>
  </p>
  <h1>
   <b>
    8 Monte Carlo Simulation for Stochastic Differential Equations
   </b>
  </h1>
  <p block-type="ListGroup">
   <ul>
    <li block-type="ListItem">
     [7] Kloeden, P.E., Platen, E. &amp; Schurz, H. (2003).
     <i>
      Numerical Solution of SDE's Through Computer Experiments
     </i>
     , Universitext, Springer (Third Corrected Printing).
    </li>
    <li block-type="ListItem">
     [8] Mikulevicius, R. &amp; Platen, E. (1991). Rate of convergence of the Euler approximation for diffusion processes,
     <i>
      Mathematische Nachrichten
     </i>
     <b>
      151
     </b>
     , 233‚Äì239.
    </li>
    <li block-type="ListItem">
     [9] Milstein, G.N. (1978). A method of second order accuracy integration of stochastic differential equations,
     <i>
      Theory of Probability and its Applications
     </i>
     <b>
      23
     </b>
     , 396‚Äì401.
    </li>
    <li block-type="ListItem">
     [10] Milstein, G.N. (1995).
     <i>
      Numerical Integration of Stochastic Differential Equations
     </i>
     , Mathematics and Its Applications, Kluwer.
    </li>
    <li block-type="ListItem">
     [11] Platen, E. (1995). On weak implicit and predictor‚Äì corrector methods,
     <i>
      Mathematics and Computers in Simulation
     </i>
     <b>
      38
     </b>
     , 69‚Äì76.
    </li>
    <li block-type="ListItem">
     [12] Platen, E. &amp; Heath, D. (2006).
     <i>
      A Benchmark Approach to Quantitative Finance
     </i>
     , Springer.
    </li>
   </ul>
  </p>
  <p block-type="Text">
   [13] Talay, D. &amp; Tubaro, L. (1990). Expansion of the global error for numerical schemes solving stochastic differential equations,
   <i>
    Stochastic Analysis and Applications
   </i>
   <b>
    8
   </b>
   (4), 483‚Äì509.
  </p>
  <h1>
   <b>
    Related Articles
   </b>
  </h1>
  <p block-type="Text">
   <b>
    Backward Stochastic Differential Equations: Numerical Methods
   </b>
   ;
   <b>
    LIBOR Market Model
   </b>
   ;
   <b>
    LIBOR Market Models: Simulation
   </b>
   ;
   <b>
    Pseudorandom Number Generators
   </b>
   ;
   <b>
    Simulation of Square-root Processes
   </b>
   ;
   <b>
    Stochastic Differential Equations: Scenario Simulation
   </b>
   ;
   <b>
    Stochastic Differential Equations with Jumps: Simulation
   </b>
   ;
   <b>
    Stochastic Integrals
   </b>
   ;
   <b>
    Stochastic Taylor Expansions
   </b>
   ;
   <b>
    Variance Reduction
   </b>
   .
  </p>
  <p block-type="Text">
   NICOLA BRUTI-LIBERATI &amp; ECKHARD PLATEN
  </p>
 </body>
</html>
