# Chapter 1 Overview

Algorithmic trading is simply a computerised rule-based system responsible for executing orders to buy or sell a given asset.

Direct Market Access (DMA) enables clients to send orders to exchanges by using their broker's membership.

#### Introduction $1.1$

Algorithmic trading and Direct Market Access (DMA) are important tools for the electronic trading of financial assets.

Nowadays, a bewildering array of assets can be traded electronically. Stocks and bonds, cash, certificates and a variety of derivatives contracts may all be bought and sold just at the push of a button. The technology to achieve this is still relatively new, but the fundamental market mechanics of buying and selling remain the same. Put simply, sellers need to find buyers (and vice-versa) as quickly and efficiently as possible. Corporations and governments issue assets in order to raise the cash (or capital) required to meet their needs. Likewise, investors and speculators must be able to easily buy and sell assets in order to see a return from their capital.

Over time, the world's markets have evolved to accommodate the differing requirements of both the issuers of financial assets and those who invest in them. The ease with which such trading takes place is commonly referred to as liquidity: Highly liquid markets (or assets) are more active and so usually much easier and cheaper to trade in. To improve liquidity, dedicated trading venues, such as exchanges, have often been established. However, there may not always be a natural buyer or seller to trade with, so markets also rely on intermediaries to "grease the wheels": Specialised traders, or dealers, trade for a set price with the aim of making a short-term profit. Brokers act as agents to place their clients' orders with the dealers, or match them with other clients' orders. Since both brokers and dealers facilitate the issuance and selling of assets they are often referred to as the "sellside". In turn, institutional investors are often called the "buy-side".

To illustrate the trading process, Figure 1-1 shows some example trade flows from the point of view of an investor. Traditionally, a buy-side initiated trade is placed as an order with a broker's salesperson who must then communicate the order to a trader (or dealer). In turn, the trader would then either quote a price to trade against their own inventory or alternatively work the order on an exchange. This is shown as the pathway labelled A in Figure 1-1. Electronic trading simply offers a means of issuing such orders via computers.

![](_page_1_Figure_1.jpeg)

Figure 1-1 A comparison of the different order execution methods

Direct Market Access (DMA) is where brokers allow clients access to their order routing infrastructure, as shown by pathway B. This allows the buy-side to issue their electronic orders almost directly to the exchanges, effectively giving them much the same level of control over an order's execution as a sell-side trader has. Sponsored access takes this to the next level, for clients whose high-frequency trading strategies need ultra-low latency connections. Essentially, this allows clients to connect directly to the market, as shown in pathway E, using the broker's trading identifier, but their own infrastructure. Alternatively, the buy-side can organise membership of the specific market and so have native access.

Algorithmic trading takes a slightly different approach to DMA: A computerised system is responsible for executing the orders to huy or sell a given asset, rather than being worked manually by a trader. So a computer program follows preset rules to determine how each order should be executed. Based on these rules, it splits off portions (or child orders) to send to the market, often tracking market conditions and events. Initially, such trading algorithms were used as a labour-saving device for busy sell-side traders, labelled pathway C in Figure 1-1. As these algorithms became more established, brokers started to offer their buy-side clients direct access to them, shown by pathway D. Together with DMA, allowing clients access to trade on markets in this way is also known as Direct Access Trading.

It is important to note that all of the labelled pathways in Figure 1-1 are only concerned with executing a given order. The actual investment decision is a completely separate process. In this case, it is shown as an idea from a buy-side analyst; it is this idea that leads to the decision to trade. This is then analysed and approved by the portfolio manager before being translated into an actual order to buy (or sell) a set quantity of asset XYZ. The order is then usually passed on to an in-house trader who decides on the most appropriate approach and on which broker/s to use. Alternatively, for more quantitative investment funds the order may well be generated by an automated system. Either way, algorithmic trading, DMA and the sell-side trader are all just a means to execute this order; hence, we can also refer to them as core execution methods.

In some ways, the term algorithmic trading is an unfortunate choice, particularly for such use by institutional investors. Trading tends to make people think of dealers buying low and selling high. Whereas the algorithmic trading systems, which are offered by the major brokers. only execute the orders they are given, as Figure 1-1 tries to show. Perhaps a more representative name for this process is "algorithmic execution".

Clearly, there are exceptions to every rule; there are no major technical reasons why trading algorithms could not also incorporate investment decisions. Indeed, as the buy-side starts to develop their own algorithms this may well become more commonplace. However, the main aim of this book is focus on how algorithms and DMA may be used to enhance order execution.

Over the last few years, algorithmic trading has become a hot topic. New reports keep predicting an increasing global market share, which is expanding from equities to foreign exchange, futures and options and even bonds. There has also been bad press; some headlines have foretold the end of trading, as we know it. Whilst the start of the sub-prime crisis in the summer of 2007, saw "algorithmic trading" blamed for both market volatility and some firms realising huge losses. Volatility is certainly higher; in part, this is due to the increase in speed achieved by electronic and algorithmic trading. However, any losses that firms have made are generally due to their investment strategy. If this is not suitable for the market conditions then losses will be realised. Algorithmic trading is the bullet, not the finger on the trigger. In section 1.10, some of the common fears and myths surrounding algorithmic trading will also be examined (and hopefully debunked).

Before we move on to consider each of these core execution methods in more detail, let's briefly review some fundamentals, such as risk, return and costs, from the perspective of both an investor and a trader.

#### 1.2 Fundamentals

Investment theory tries to maximize profits and minimize risk by carefully choosing different assets. Arguably, the best known approach is modern portfolio theory (MPT) pioneered by Harry Markowitz (1952).

Modern portfolio theory models profits from the returns (or price changes) in a portfolio of financial assets. Volatility is often used as a proxy for the overall risk; this represents the standard deviation of the returns. Assets with higher returns are generally riskier. Portfolios can be made up of an almost infinite set of compositions, using a range of assets with various weightings. Plotting the risk-return characteristics of these allows an efficient frontier to be constructed, as shown in Figure 1-2 (a). This is the upper edge of the shaded region; it represents the portfolios with the highest returns for a given amount of risk. Consequently, an investor must focus on the overall makeup of their portfolio, as much as the risk and returns for individual assets.

![](_page_3_Figure_1.jpeg)

Figure 1-2 A difference in perspective

In order to build up this optimal portfolio we need to buy or sell the specific assets, and so send order/s to broker/dealers or direct to the markets, as we saw in Figure 1-1, Risk (or volatility) is again important, since it shows how much each asset's price might change by. However, returns are somewhat less important, since we are now focussed on executing the given order/s, often in the next second/s, minute/s or hour/s. Instead, cost becomes more important, as shown in Figure 1-2 (b). Executing each order has an associated cost, from the impact it has on the asset's price to broker and exchange fccs. Trading faster with large or aggressively priced orders will generally have more impact and so cost more, although the speed of execution reduces the risk. Whereas trading more slowly or passively costs less but exposes us to risk from the asset's price volatility. This is what Robert Kissell and Morton Glantz (2003) refer to as the trader's dilemma. Striking the right balance between cost and risk is a question of taking into account the investor's priorities, as we will see in Chapter 7: it can be the key to achieving optimal execution.

#### 1.3 Core execution methods

Institutional trading can broadly be classified as either agency or principal trading. In agency trading, the broker acts as a conduit to the market, as we saw in Figure 1-1. The client may also give trading instructions, such as to execute throughout the day or target a specific benchmark price or a certain percentage of the market volume. With principal trading, the broker/dealer agrees an up-front price for the asset, which they will fulfil either from their own inventory or by executing on the markets. Since principal trading is carried out with a specific dcaler, rather than at an exchange, this is also referred to as "over-the-counter" (OTC) trading.

In terms of risk, the client is exposed to the market with agency trading. The price may move favourably (or not), there is also the possibility that the order may fail to be completed. The broker will strive to achieve best execution for the client, but at the end of the day they are acting as an agent for the client, they do not take on any of the risk. In comparison, with principal trades the risk is transferred immediately to the broker/dealer. Consequently, principal trading is more expensive because the dealer tries to offset this by incorporating it in the negotiated price. The investor must decide whether the up-front costs are worthwhile compared to the potential market risk.

In general, both types of trading are supported for most equities and for the standardised

(or listed) futures and options contracts, which are traded on exchanges. The bond and foreign exchange markets have tended to be based more on dealers (or market makers), and so principal or OTC trading is more common (although agency trading is sometimes available for the more liquid assets).

Hence, the final destination for orders in Figure 1-1 also depends on the asset being traded. Algorithmic trading and DMA are generally only viable options when there is a wellestablished secondary market, such as an exchange. So direct access trading has historically centred on stocks and futures. Although algorithmic trading and DMA are rapidly spreading to most of the major asset classes, as we shall see in Chapter 3.

Agency trading may also be classified based on the execution method used to achieve it. "High-touch" trading is where orders are worked manually by a trader. Algorithmic trading is sometimes referred to as "Low-touch" trading, since it requires little or no handling by actual traders and so can be offered as a lower cost agency service. The final piece of the puzzle is DMA, which is also referred to as "Zero-touch". With DMA the broker's own electronic access to markets is extended out to their clients. The sell-side traders have nothing to do with the order; instead, the execution is handled manually by the client.

The increasing focus on transaction costs by the buy-side has meant a decline in the more traditional "High-touch" trading. Still, all these methods are in fact complementary, since they are trying to meet the same objectives, as Figure 1-3 tries to show.

![](_page_4_Figure_5.jpeg)

Figure 1-3 The range of core execution methods

Both buy (and sell-side) traders now have a wider choice of execution method than ever before. They can take complete control of the execution by using DMA (or native access), or they can delegate it to an algorithmic trading system. Vendors are even working on systems that allow traders to "pick and mix". For instance, Neovest's AlgoGenetics allows "metaalgorithms" to be created which can combine algorithms from a range of brokers together with DMA orders.

Continual evolution and the adoption of similar tactics mean that the boundaries between these methods are constantly blurring. For example, increasingly complex DMA order types, such as iceberg orders and smart order routing, are making it more difficult to differentiate between pure DMA and algorithmic trading.

Another example of the constant evolution of trading strategies is crossing. Block trading is a specialisation for handling large orders of single assets. The advent of platforms such as ITG's POSIT allowed investors to participate in electronic crossing, rather than use brokers' block trading desks for such orders. This trend has continued with the success of the socalled "dark pools" of liquidity offered by the hidden crossings of Alternative Trading Systems (ATS). Although the probability of execution is lower than a broker-mediated block trade, these approaches offer the potential of getting a better price. As with DMA, it is the client's responsibility to manage these orders. Therefore, crossing is shown together with DMA in Figure 1-3. Sourcing liquidity via these "dark pools" has also become extremely important for algorithmic trading.

### 1.4 Institutional trading types

In the previous section, we focussed on the methods used to actually execute orders. The orders themselves are invariably sourced from the buy-side, in other words institutional or hedge fund investors, as part of their overall trading strategy. Figure 1-4 shows the broader range of trading types, which are widely adopted by different kinds of investors.

![](_page_5_Figure_4.jpeg)

Figure 1-4 Different trading types

Traditionally, institutional investors, such as investment and pension funds, maintain large portfolios with specific investment criteria. Orders are generated when they need to change the make-up of their portfolios. For single assets, they may choose to trade in either an agency or a principal fashion, whilst block trading may be used for larger orders.

Quantitative investment funds adopt more highly automated strategies, as do some hedge funds. For those targeting short-term arbitrage opportunities or generating revenue by market making, this means much higher trading frequencies. So they are even more focussed on low-cost execution methods, such as algorithmic trading and DMA.

**Portfolio trading** is sometimes referred to as basket or **program trading**. It provides investors with a cost-effective means of trading multiple assets, rather than having to trade them individually. Typically, this is used when they need to adjust or rebalance their portfolios. The trading list represents the assets that must be bought or sold to transform the investor's current portfolio to their desired target. Portfolio trading is a broker provided service, which allows for economics of scale, and so it generally offers a cheaper alternative for handling such transitions. As with single stock institutional trading, the investor may choose to negotiate a principal trade with a broker/dealer, or have a broker trade the list in an agency fashion. We will revisit this topic in more detail in Chapter 12.

Systematic, black-box, quantitative and high frequency trading are terms which all sound like references to algorithmic trading, and are sometimes mistakenly used as such. However, they have as much to do with the style of investment as the actual trading. In fact, they are all forms of systematic trading (or investment), and are sometimes referred to as **Automated trading.** Predominantly, these strategies are adopted by either quantitative investors or proprietary trading desks.

Systematic trading, as its name suggests, is all about consistently adopting the same approach for trading. This may be used to dictate points for trade entry and exit, for instance by comparing market prices with boundary conditions, e.g. Bollinger bands. Alternatively, it may require an intricate set of rules, which accommodate a wide range of intraday conditions such as price, volume or volatility.

**Quantitative trading** (sometimes referred to as "Black-box" trading) is often confused with algorithmic trading. Here the trading rules are enforced by adopting proprietary quantitative models.  $1$  The difference is fairly subtle, but quantitative trading systems instigate trades whereas algorithmic trading systems merely execute them. Therefore, quantitative trading systems need to focus on a wider range of goals in addition to the actual execution strategies. These may range from tracking indicators to determine trade initiation and closeout, to monitoring the overall portfolio risk.

**High frequency trading** aims to take advantage of opportunities intraday. The time scales involved range from hours down to seconds or even fractions of a second. Effectively, it is a specialised form of black-box/quantitative trading focussed on exploiting short-term gains. Some high frequency strategies adopt a style similar to a market maker, trying to keep a relatively neutral position except to take advantage of any price discrepancies. For such strategies, monitoring the overall position/inventory risk and incorporating this information into the pricing/trading decisions is vital.

Statistical arbitrage represents a systematic investment/trading approach, which is based on a fusion of real-time and historical data analysis. The main difference from high frequency trading is that strategies may span over longer timeframes. Other than this, the goals are generally the same, both try to take advantage of mispricing whilst minimising the overall exposure to risk. Strategies try to find trends or indicators from previous data (intraday and/or historical) and then use these to gain an edge. Time series analysis, data mining and even artificial intelligence are employed to try to isolate useful information from the mass of data that is available.

<sup>&</sup>lt;sup>1</sup> Such models have sometimes been termed "black-boxes", since their actual mechanisms are closely guarded, although obviously their creators have a clear understanding of how they work.

Regardless of which of these trading types are actually chosen, each of them may be implemented using one or more of the core execution methods, as shown in Figure 1-4.

### **Electronic trading** $1.5$

In their time, the invention of the telegraph and telephone revolutionised trading, allowing prices and orders to be communicated remotely. Still, it was the advent of the computer that has most affected trading. Before we go into any more detail on algorithmic trading and DMA techniques, it is worth briefly reviewing the development of electronic trading. Some of the more notable milestones in this journey are shown in Table 1-1.

| Year | Event                                                                                                                               |  |  |  |  |  |
|------|-------------------------------------------------------------------------------------------------------------------------------------|--|--|--|--|--|
| 1969 | Instinct's "Institutional Networks" started, allowing electronic block-trading.                                                     |  |  |  |  |  |
| 1971 | NASDAQ electronic bulletin board started, allowing OTC trading of stocks.                                                           |  |  |  |  |  |
| 1972 | Cantor establish first electronic marketplace for U.S. Government securities.                                                       |  |  |  |  |  |
| 1976 | NYSE's Designated Order Turnaround (DOT) system routes small orders.                                                                |  |  |  |  |  |
| 1978 | U.S. Intermarket Trading System (ITS) established, providing an electronic link<br>between NYSE and the other U.S. stock exchanges. |  |  |  |  |  |
| 1980 | Instinct introduces PSE Scorex, enabling DMA to U.S. exchanges.                                                                     |  |  |  |  |  |
| 1981 | Reuters pioneered electronic monitor dealing service for FX.                                                                        |  |  |  |  |  |
| 1982 | Tokyo Stock Exchange introduces its Computer-assisted Order Routing &<br>Execution System (CORES).                                  |  |  |  |  |  |
| 1986 | London Stock Exchange's "The Big Bang" shifts to screen trading.<br>Paris Bourse introduced an electronic trading system.           |  |  |  |  |  |
| 1987 | ITG POSIT offers scheduled block crossings for stocks.                                                                              |  |  |  |  |  |
| 1988 | MTS platform created electronic secondary market for Italian government bonds.                                                      |  |  |  |  |  |
| 1992 | CME launches first version of GLOBEX electronic futures platform.                                                                   |  |  |  |  |  |
| 1993 | EBS (Electronic Brokers System) adds competition for spot FX.                                                                       |  |  |  |  |  |
| 1997 | U.S. SEC order handling rules change results in the creation of Arca, Brut, Island<br>and Bloomberg Tradebook ECNs.                 |  |  |  |  |  |
| 1998 | Eurex offers the first fully electronic exchange for futures.                                                                       |  |  |  |  |  |
| 1999 | EuroMTS launched for European government bond trading.<br>eSpeed available for client bond trading.                                 |  |  |  |  |  |
| 2000 | ICAP's BrokerTec bond trading platform launches.                                                                                    |  |  |  |  |  |
| 2001 | Liquidnet ATS created, allowing "dark pool" buy-side crossing for equities.                                                         |  |  |  |  |  |
| 2006 | NYSE starts moving equity trading to its Hybrid platform.                                                                           |  |  |  |  |  |
| 2007 | U.S. Regulation NMS, European MiFID regulations come in force.                                                                      |  |  |  |  |  |

### Table 1-1 Some of the key milestones in the adoption of electronic trading

In the 1960s, computer networks were used to route prices to computer terminals, effectively making ticker-tape machines obsolete. Soon afterwards, computers were used to start transmitting orders and trades. Systems supporting fully electronic trading began to appear in the 1960-70s. Suddenly, traders could issue orders remotely; there was no longer a technical need for them to be physically based on an exchange floor.

Early on, electronic trading was mainly focussed on handling relatively small orders. The bulk of trading was still carried out over the phone or in person on exchanges. However, by the mid 1990s many of the world's major stock exchanges were trading a considerable proportion of their volume electronically. Since then the shift to fully electronic trading has become almost inevitable.

The equities markets have clearly led the way in electronic trading. In the early stages, the New York Stock Exchange (NYSE) and NASDAQ (National Association of Securities Dealers Automated Quotations) were undoubtedly at the forefront. By the 1990s, though, the focus had shifted to Europe where trading floors started closing as exchanges shifted to fully electronic order books. Then in 1997, the U.S. saw a major shake-up with the Securities and Exchange Commission (SEC) order handling rules, which allowed new competition in the form of Electronic Communication Networks (ECNs). These new venues saw a huge expansion around the millennium, followed by a fierce round of takeovers and consolidations. Over the last fcw years, innovation has still continued at a rapid pace, particularly in terms of new variants of the block crossing Alternative Trading Systems (ATSs), such as Liquidnet. Two of the major ECNs, namely BATS and Direct Edge have even become exchanges in their own right (or are in the process of doing so). Further changes are likely as the full effects of the U.S. Regulation-NMS (National Market System) and Europe's Markets in Financial Instruments Directive (MiFID) take effect. In fact, Multilateral Trading Facilities (MTFs), Europe's equivalent to ECNs, are starting to become significant competition for the major European exchanges.

The bond markets have been slower to adopt electronic trading, in part due to them being centred more on market makers rather than exchanges. Europe has again played an important part in the evolution of electronic bond trading, most notably with Italy's MTS (Mercato Telematico dei Titoli di Stato), which has become Europe's leading centre for government bond trading. In the U.S., a mass of electronic systems appeared around the millennium; however, since then the consolidations and closeouts have been brutal. The electronic market for bonds is now dominated by a handful of major players.

Foreign exchange has also shifted towards electronic trading. ECNs are well established and even "dark pool" ATSs have started to appear.

The derivatives marketplace is more complex. The majority of trading is still carried out over the counter (OTC). Still, there is also a sizeable market for exchange-listed derivatives. The Chicago Mercantile Exchange (CME) launched the first version of its GLOBEX platform back in 1992; though, initially this was primarily for after-hours trading. Six years later Eurex became the first fully electronic exchange for futures. Electronic trading is now commonplace for most of the world's major future and options exchanges.

Overall, the rapid proliferation of electronic trading has made the world markets accessible to a much wider range of users. Without this innovation, algorithmic trading, DMA and automated crossing simply would not exist. Note that we will cover the individual markets in more detail in Chapter 3, and the appendices.

#### **Algorithmic trading** 1.6

An algorithm  $^{2}$  is a set of instructions for accomplishing a given task. So a trading algorithm is just a computerised model that incorporates the steps required to trade an order in a specific way. Admittedly, for the algorithm to react to ever changing market conditions these rules can become quite complex. Hence, in this book we shall break them down and consider these decisions in isolation as well as showing how they may then be grouped together to build actual trading algorithms.

For example, given an order to buy 20,000 of asset XYZ the rules might dictate placing

<sup>&</sup>lt;sup>2</sup> The word algorithm derives from the term algorism, which was used by the 9th century Persian mathematician Abu Abdullah Muhammad ibn Musa al-Khwarizmi in referring to the rules of arithmetic.

the whole quantity as a limit order at the current best market price. Alternatively, they might work the order over the day, splitting it into segments. The rules determine the type, price and quantity for each of these child orders, often based on a mixture of historical and live market data. A computerised system is responsible for handling the algorithm's instructions, so the execution is fully automated. The system ensures that each corresponding child order is split and placed on the market. It then monitors these child orders, adjusting or cancelling them, as and when it becomes necessary.

Let's consider a very simple trading algorithm that aims to achieve an average market price. It does this by dividing each order into uniform slices, which are traded sequentially. Given an order to buy 10,000 of asset ABC over the next five hours, our simple algorithm will trade 1,000 ABC every half hour, by sending a market order to the exchange. Figure 1-5 shows the resultant trading pattern for these child orders.

![](_page_9_Figure_3.jpeg)

Figure 1-5 A simple example algorithm

Table 1-2 shows another way of viewing our algorithm, as a trading schedule with the target quantity specified for each time period.

| Time  | 08:30 | 09:00 | 09:30 | 10:00 | 0:30 | 1:00 | 1:30 | 12:00 | 12:30 | 3:00  |
|-------|-------|-------|-------|-------|------|------|------|-------|-------|-------|
| Trade | 1000  | 000   | 1000  | 000   | 1000 | 000  | 000  | 1000  | 1000  | 000   |
| Total | 000   | 2000  | 3000  | 4000  | 5000 | 6000 | 7000 | 8000  | 9000  | 10000 |

|  |  |  | Table 1-2 A simplified trading schedule |  |  |
|--|--|--|-----------------------------------------|--|--|
|--|--|--|-----------------------------------------|--|--|

Clearly, our example algorithm is far from perfect; it is predictable and it takes no account of either market prices or volumes. Modern trading algorithms have evolved from this simplistic order slicing strategy to the point where their trading patterns are unrecognisable in comparison. Complex algorithms must be expertly defined and implemented. So the actual trading rules upon which these algorithms are based are defined by experienced traders and

quantitative analysts. They are designed to target the best execution, given the specified objectives.

# Types of trading algorithms

At present, there are literally hundreds of different trading algorithms available. Each broker or vendor provides their own range of trading algorithms, catering for specific goals. Unsurprisingly, the driving forces for many of these algorithms are price, volume or liquidity. Some algorithms rigidly adhere to a given trading schedule whilst others may be more dynamic, adapting in real-time to ever changing market conditions. Obviously, it is vital for the objectives to be clearly defined for an algorithm to have a chance of achieving its goals.

If we ignore the various names that are used we can start to distil the existing algorithms into a handful of basic types. Table 1-3 shows a summary of the more commonly adopted trading algorithms, which are presently in widespread use.

| Key driver    |        | Algorithms                                        |  |  |  |
|---------------|--------|---------------------------------------------------|--|--|--|
| Schedule      | Time   | Time Weighted Average Price (TWAP)                |  |  |  |
|               | Volume | Volume Weighted Average Price (VWAP)              |  |  |  |
| Predetermined | Volume | Percentage Of Volume (POV)                        |  |  |  |
| benchmark     | Price  | Implementation Shortfall (IS)                     |  |  |  |
|               | Ratio  | Pairs / Spread trading                            |  |  |  |
| Dynamic       | Price  | Price Inline                                      |  |  |  |
| Benchmark     |        | Market On Close (MOC)                             |  |  |  |
| Liquidity     |        | Liquidity-based algorithms<br>Smart order routing |  |  |  |

### Table 1-3 A summary of common trading algorithms

Often, trading algorithms are designed to meet (or beat) specific benchmarks, such as the Volume Weighted Average Price (VWAP) or the market closing price. Others try to minimise overall transaction costs whilst some try to trade more opportunistically. There are also algorithms that are driven by liquidity, spanning multiple execution venues or "dark pools" to seek additional liquidity. In Chapter 5, we will cover the whole range of trading algorithms in more detail.

# The evolution of trading algorithms

The origins of algorithmic trading may be traced back to electronic trading systems developed as efficiency aids for sell-side traders. Around the millennium, brokers started to realise that these tools could also be offered to clients. Within a few years, every major brokerage was offering algorithmic trading services, and client uptake has steadily increased. Vendors are also starting to create frameworks that make it easier for the buy-side to create their own trading algorithms.

The first generation of trading algorithms were natural evolutions of simple order slicing. They focussed on meeting specific benchmarks, starting with a Time Weighted Average Price (TWAP) and progressing on to the ubiquitous Volume Weighted Average Price (VWAP). The simplicity of calculating a VWAP and its more accurate reflection of daily price moves meant that for several years VWAP reigned supreme.

Both the early TWAP and VWAP algorithms tended to be statically driven. So as soon as an order was received a specific trading schedule was determined, which then drove the trading algorithm. For VWAP, this schedule would be based on a historical volume profile, essentially this is a representation of how trading volume progresses through an average day. Though, using statically created trading schedules increasingly proved vulnerable, since other market participants could easily spot and take advantage of such regular trading patterns. To combat predatory trading, algorithms started to incorporate more randomisation. Consequently, there was a natural progression from purely schedule driven algorithms to more dynamic strategies. For example, the Percentage of Volume (POV) algorithm bases its execution in response to the live market volume instead of trading based on a historical volume profile.

The second generation of trading algorithms were created in response to the application of transaction cost analysis (TCA). This analysis breaks down all the various costs associated with trading. TCA highlighted that the effect an order has on the asset's price (its market impact) was not the only significant cost. Indeed, other factors, such as timing risk and opportunity cost, could actually outweigh the market impact. Andr√© Perold (1988) coined the term implementation shortfall to represent the actual costs of trading. Essentially, this reflects the difference between the market price when the investment decision was actually made (the decision price) and the actual executed price. The increasing popularity of TCA meant investors started to re-examine their use of benchmarks. In fact, VWAP began to be replaced by decision price. In general, the first generation trading algorithms were not designed to be price or risk sensitive; they were more focussed on reducing the overall market impact. Hence, brokers needed to develop algorithms that were more price- and costcentric, the most notable of which being the Implementation Shortfall (IS) based algorithms. These new algorithms tried to tackle what Robert Kissell and Morton Glantz (2003) termed the trader's dilemma: trading too fast brings high market impact costs whilst trading too slowly exposes us to considerable risk. Suddenly, algorithms started incorporating complex market models to estimate potential transaction costs, as they attempted to determine the optimum trading strategy for each order.

The third generation of algorithms have resulted from the ongoing search for liquidity, triggered by the rapid proliferation of Electronic Crossing Networks (ECNs) and Alternative Trading Systems (ATSs) in the U.S. equity market. Having so many potential execution venues meant a raft of simple order routing systems were created. Another important factor has been the increasing order book transparency as markets have transitioned to electronic trading. Many of the first generation algorithms focussed solely on the best bid and offer quotes, often because that was all that was available. As order book data becomes increasingly available, more and more algorithms are taking advantage of this for their order placement decisions. The combination of multiple venues and increasing transparency has helped transform simple order routing systems into complex liquidity-based algorithms. These constantly examine the order books of different venues to decide where best to place orders.

Off-market trading has also shifted to new electronic venues, in particular the "dark pools" or ATSs that have proven so successful for U.S. equities. Algorithms now routinely interact with these "dark pools" to find additional liquidity at set price points, trying to achieve best execution. At first, this started with dedicated liquidity-seeking algorithms, but increasingly this behaviour is also being incorporated in other algorithms, such as Implementation Shortfall or even VWAP. Thus, new hybrid strategies are starting to evolve.

In parallel with the search for liquidity, another shift in algorithm behaviour is taking place. Customisation and adaptability are becoming key focuses for algorithms, allowing brokers to more easily offer client-centric trading algorithms.

Exactly what the next generation of trading algorithms will offer is hard to predict, but it is certain that they will keep evolving.

#### 1.7 **Direct Access Trading**

Direct access trading represents the shift in access and control of execution to the buy-side. Investors and buy-side traders can now get direct access allowing them to place orders on many of the world's financial marketplaces. Originally, direct access trading was synonymous with DMA; however, the introduction of crossing and algorithmic trading has meant institutions now have an even broader choice of execution methods.

# **Direct Market Access**

Direct Market Access (DMA) extends the principle of remote access to a broker's clients. Its roots trace back to the 1980s with vendors such as Instinct. Although used by some institutional clients, many of the early adopters of DMA were retail users. Certainly, vendors targeted the retail market with their DMA systems. This gave day traders, or SOES bandits (named after NASDAQ's Small Order Execution System), an unprecedented level of access and control over their orders.

Institutional users became interested in the prospect of DMA in the 1990s. In particular, this was led by hedge funds and statistical arbitrageurs. Many of the initial DMA offerings were provided by software houses and small agency brokerages. However, after the millennium the larger brokers started investing in DMA in a big way. In 2000, Goldman Sachs acquired REDIPlus whilst in 2004 Bank of America Securities bought Direct Access Financial Corp., Sonic Trading Management went to Bank of New York and Lava Trading became part of Citigroup. Suddenly, the DMA marketplace was dominated by major brokers; DMA had become a key selling point for institutional use.

With DMA, the client can take advantage of the broker's infrastructure to send their orders to the exchange, much like the broker's own orders. Hence the moniker "Zero touch", since the order execution is controlled by the client. This requires the client traders to have access to an Order Management System (OMS) or Execution Management System (EMS), which is linked to the broker. Prime brokerage agreements are often established to organise the clearing and settlement of any executions, and any other custodial or financing requirements.

Clearly, information leakage is a key concern for institutional users. Therefore DMA services are generally run by brokers as a separate entity to protect the client orders from being viewed by the rest of the broker's traders, and in particular their proprietary desks.

### Sponsored access

Sponsored access caters for buy-side clients with high-frequency trading strategies. This allows the client to connect to the market using use their broker's unique market identifier (or MPID), but without having to go through their entire infrastructure. Although the markets generally require the broker to monitor the trading, ensuring that no excessive risks are taken. The monitoring may be carried out pre-trade, either with a fast, dedicated system or by using a solution from a third-party vendor, such as FTEN. Whilst this adds some overhead, the client should still get faster access than normal DMA.

Alternatively, some sponsored access may rely on post-trade monitoring. This has been termed "naked access", since this does not allow the broker to prevent erroneous trading. Given the increased regulatory attention, the future for such "naked access" is uncertain.

### Crossing

Institutions often need to trade in large sizes, but large block orders can expose them to substantial price risk. Traditionally, these large orders were handled by brokers off the trading floor. This is sometimes referred to as the "upstairs market" since historically such negotiations took place upstairs in broker's offices, well away from the exchange floor.

Often block trading is undertaken on a principal basis, although agency trading is also catered for. In a principal trade, the broker/dealer assumes all the risk by taking the required position onto their inventory. To work such large block orders they may need to find new counterparties who require the asset, or they may split the order into smaller quantities and work them on the market.

Crossing systems provide an electronic mechanism allowing investors to carry out their own block trading anonymously. These systems aggregate orders and then match them at set points throughout the day. For instance, ITG's POSIT matches orders at over a dozen set times daily. In comparison, Alternative Trading Systems (ATS), such as Liquidnet, generally provide continuous electronic order matching. These anonymous trading venues ensure the order details (size and sometimes price) are hidden; hence, they have often been referred to as "dark pools" of liquidity. Effectively, they offer the buy-side the chance to cut out the broker as an intermediary and trade anonymously with each other. Due to the size of the orders involved, they have become significant sources of liquidity.

Note that it is important to remember that orders placed on crossing systems or ATSs are not guaranteed to execute. Instead, the focus is on achieving a better price and minimising information leakage. In fact, the probability of execution can be much lower than on the main exchanges, depending on the liquidity of the asset and the size of the block order. Consequently, such orders tend to require some monitoring. In order to guarantee execution other trading methods, such as algorithmic trading or DMA, may be used in tandem. For example, we could place an order to buy a million shares of XYZ on a crossing system in the morning. As the day progresses if it still has not executed we could reduce the quantity by 10 or 20% every hour and work this separately. This allows us to hold out for the best price from crossing, whilst still ensuring that the order is executed. Indeed, there are now trading algorithms that offer this kind of approach.

# **Direct Liquidity Access**

Managing an order on a crossing network or ATS is essentially the same as DMA. This similarity has meant that vendors now offer solutions that enable access to both mechanisms, To reflect this some brokers/vendors have started using the term Direct Liquidity Access (DLA) for their services.

DLA type services are not necessarily just a combination of DMA and crossing provision. They may also incorporate features such as liquidity aggregation, where smart order routing or custom trading algorithms are used to seek out sufficient liquidity at the desired price.

# **Direct Strategy Access**

Client access for trading algorithms was initially handled over the phone. Nowadays, more and more OMSs and EMSs can handle algorithmic trading. So clients now have direct access to algorithms, much as they have direct access to orders via DMA. In fact, some brokers, such as UBS, have started using the term Direct Strategy Access (DSA).

#### Comparing execution methods 1.8

Although all the core execution methods are complimentary, there are still some significant differences between them. To illustrate this Table 1-4 shows two simple example orders. The first order is simply a limit order to buy asset ABC within a fixed price limit, whilst the second order targets the daily VWAP as a benchmark.

| Order | Trading method      |                      |                      |  |  |  |  |  |
|-------|---------------------|----------------------|----------------------|--|--|--|--|--|
|       | Manual              | DMA/Crossing         | Algorithmic          |  |  |  |  |  |
|       | "Buy 10,000 ABC     | Buy limit order      | No direct equivalent |  |  |  |  |  |
|       | with a limit of 53" | 10,000 ABC at 53     |                      |  |  |  |  |  |
| 2.    | "Buy 100,000 ABC    | No direct equivalent | Buy 100,000 ABC      |  |  |  |  |  |
|       | Trade VWAP over     |                      | Algorithm: VWAP      |  |  |  |  |  |
|       | the day             |                      | Start time: Now      |  |  |  |  |  |
|       | Don't go above 53"  |                      | End time: Close      |  |  |  |  |  |
|       |                     |                      | Price limit: 53      |  |  |  |  |  |

### Table 1-4 Different trading methods for some example orders

Manual trading can deal with any type of order. The instructions are simple and easy to understand. It is also popular because it allows the client to discuss the order with the broker. This gives them an opportunity to gain new market information and analysis (or "colour") which may even lead them to alter their trading strategy. Such information can be vital to clients, and is one of the main reasons why manual trading is still so widespread.

DMA is perfect for simple order types such the first order in Table 1-4. It allows clients complete control over how and when orders are placed. However, there is not usually a single equivalent order that can handle something like the example daily VWAP trade. DMA caters solely for low-level access. So instead, the client must try to reproduce the strategy that a trader might adopt manually. Therefore, to achieve best execution a client will need considerable market experience, as well as having the time to analyse and decide how best to place each child order. Whilst this may suit some clients, clearly this is a more time consuming approach. That is why, for many clients, either manual or algorithmic trading offer a more practical alternative.

Likewise, order crossing can easily handle simple limit orders, but not more complicated order types. Again, it is up to the client to monitor the order's status, possibly cancelling and re-routing it if executions are not forthcoming on the ATS. Since such crossing networks tend to deal with larger order sizes, a client may actually prefer a dual trading strategy, whereby most of the order is left on the ATS for potential crossing whilst a smaller portion is traded on the exchange to try to ensure execution. Such strategies are starting to be offered by new liquidity-based trading algorithms.

Algorithmic trading is intended to cope with more complex trading strategies, so the example VWAP order in Table 1-4 poses no problems. Upon receiving the order, a VWAP

trading algorithm will then decide how it should be handled. Some algorithms adopt a static approach, splitting orders based purely on information from historical data. Alternatively, ones that are more dynamic incorporate a mixture of historical and live market data in their decisions. As required, the algorithm will then send child orders to the market, selecting the most appropriate order type/price and size; then continually monitor their progress. Essentially, this is no different to what happens for traders working such orders manually or via DMA, except that the trading algorithm provides a fully automated process. Clearly, in order for the execution to meet the client's objectives it is vital that any requirements such as limit prices, benchmarks etc. are fully specified. As we can see from Table 1-4, the algorithm parameters (the start and end times and the limit price) are similar to how we might ask a trader to work the order. Admittedly, this is a more constrained approach than just talking to a trader over the phone. However, brokers are constantly introducing new algorithms and refining their parameters to try and make it easier to issue appropriate orders and to cope with any required customisations. They have even started introducing algorithms that look at the order details and decide the most appropriate trading strategy/algorithm for it.

Another way of comparing execution methods is to try to rate them in terms of factors such as:

- $\bullet$ Efficiency
- $\bullet$ Usability
- Performance/Cost

| <b>Factors</b> |                   | Manual              | <b>Direct Access</b> |                     |                     |  |
|----------------|-------------------|---------------------|----------------------|---------------------|---------------------|--|
|                |                   |                     | DMA                  | Crossing            | Algorithmic         |  |
| Efficiency     | Capacity          | $\star$             | $\star$              | $\star$             | $\star \star \star$ |  |
|                | Speed             | $\star$             | *                    | $\star$             | $\star \star \star$ |  |
| Usability      | Control           | $\star$             | $\star \star \star$  | *                   | $\star$             |  |
|                | Transparency      | $\star$             | $\star \star \star$  | +                   | $\star$             |  |
|                | Anonymity         | $\star \star$       | $\star \star$        | $\star \star \star$ | $\star \star$       |  |
|                | Market conditions | $\star$             | $\star$              | $\star$             | $\star \star$       |  |
|                | Market knowledge  | $\star \star \star$ | $\star$              | $\star \star$       | $\star \star \star$ |  |
|                | Asset knowledge   | $\star \star \star$ | $\star$              | $\star \star$       | $\star \star \star$ |  |
| Performance/   | Performance       | $\star \star$       | $\star \star$        | $\star \star$       | $\star \star$       |  |
| Cost           | Commission        | $\star$             | $\star \star \star$  | $\star$             | $\star \star$       |  |
|                | Risk/Cost control | $\star \star$       | *                    | $\star$             | $\star \star$       |  |
| Other          | Regulations       | $\star \star$       | $\star$              | $\star$             | $\star \star$       |  |

These are broken down in more detail in Table 1-5.

Graded from weakest  $(\star)$  to strongest  $(\star \star \star)$ 

Table 1-5 Comparing the core methods for trading

# Efficiency

Efficiency has been one of the key drivers for the sell-side; a skilled trader is a valuable commodity, anything that helps make them more productive is clearly beneficial. For some segments of the buy-side, typically hedge funds, speed is becoming ever more important. Low latency trading mechanisms allow them to capitalise on opportunities as soon as they see them.

In terms of capacity, algorithmic trading is clearly the winner; computers can easily

handle thousands of orders simultaneously. Additional capacity can often be added by setting up another computer server, provided the underlying infrastructure (networks, links to exchanges etc.) is good enough. In comparison, manual trading is quite an expensive option.

Traders are inherently good at multi-tasking; however, there is still a limit to how many orders a person can handle at any one time, beyond this level the quality of execution may suffer. DMA has similar capacity issues since all that has really happened is a shift of the manual trading from the broker to the buy-side. Capacity is less of an issue when using crossing systems since this tends to be a more passive trading style. Though, the orders still need to be monitored, and if they have not crossed after some time, alternative trading methods may need to be used.

With respect to speed, algorithmic trading is again the best option. Computerised systems are perfect for monitoring and analysing thousands of variables in fractions of a second. Exchanges used to have latencies of around 300 milliseconds, at present they are now competing to offer services with latencies below 10 milliseconds. To put this in perspective a blink takes between 100-150 milliseconds (as noted by David Burr (2005)). Even complex analytics for determining the most appropriate reaction can be calculated in fractions of a second. In other words, a trading algorithm can spot an opportunity and scnd an appropriate order to the exchange before we even notice the quote flickering on our monitor. Speed has become such a key issue that some exchanges and ATSs now offer co-location services, essentially allowing member's computer servers to be placed in their machine rooms to virtually eradicate any network delays.

### Usability

Usability is obviously a major issue for most users. A convoluted trading method is unlikely to be popular, even if it gets good results.

Direct control over how their orders are handled has significantly improved for the buyside. DMA allows them to place and manage orders as if they were a broker/dealer. In comparison, both manual and algorithmic trading represent a slight loss of control, since the client can only issue general trade instructions or select an appropriate trading algorithm. Clearly, it is often easier to communicate such instructions to a person, but trading algorithms are continually evolving to try to be as intuitive as possible. They are also becoming highly customisable, catering for an ever-expanding range of trading requirements.

Transparency is closely related to control. If we cannot dictate exactly how something is done, we would at least like to be able to monitor it closely to ensure that it is doing what we want. Competitive advantage means that brokers cannot divulge the exact inner workings of their algorithms, but they should be still be able to explain the behaviour for specific orders. It is also important to get a broad understanding of how each trading algorithm works, so as to be able choose the most appropriate one for our orders.

Anonymity is important as well, since information leakage is one of the key concerns for many investors. Over the last few years, the anonymity offered by crossing networks has helped these systems gain a substantial market share, particularly in the U.S. DMA and algorithmic trading can also provide anonymity, since most brokers segregate the trading for their prime brokerages to ensure client privacy.

Another factor that affects usability is changing market conditions, in part triggered by electronic and algorithmic trading and by the competition between venues. Across many of the world's markets average order sizes have significantly decreased whilst trading volumes have rocketed. So orders, which might have immediately filled five years ago, must now be

split to prevent market impact. Similarly, having multiple execution venues fragments the available liquidity, making it harder to trade. Algorithmic trading is the best suited to handling such conditions; computer capacity means it can closely monitor each venue and decide where best to trade, for thousands of orders. Neither DMA, nor manual trading can match this.

Market and asset specific knowledge are also key to achieving best execution. This can be as simple as knowing when markets are open and understanding the supported order types. Alternatively, it might mean having in-depth experience of how each asset trades. For manual or algorithmic trading, the orders are being handled by a dedicated expert or system, so orders can be easily delegated to these methods. It does not matter whether the order is for U.S. bonds or Japanese equities they will handle the complexities of each market and asset type. Whereas for DMA, and to a lesser extent crossing, there is less inbuilt guidance, it is up to the client to determine how best to trade. That said, many OMSs and EMSs often have built-in rules to prevent simple errors such as selecting an unsupported order type.

# Performance / Cost

Execution methods have to deliver in terms of both performance and cost. Performance may be measured by comparing the average execution price to a specific benchmark. Note that it is also important to consider the variability, or volatility, of these averages. For any specific order, manual trading should generally be able to beat the performance of an algorithm, since traders can often infer much more subtle signals from the market. However, the rule based nature of algorithms means that they should provide more consistent results, since they do not get tired or distracted. Therefore, in terms of overall performance algorithms and manual trading are relatively evenly matched. Admittedly, traders probably still have the edge, but algorithms are improving all the time.

It is also important to get the balance right between performance and efficiency. An experienced trader should generally be able to outperform most trading algorithms; however, this may consume a large proportion of their time. Overall, better performance might be achieved by having the trader manually work the more difficult orders whilst delegating the others to trading algorithms.

When examining performance, the investment goals should be considered as well. For instance, trading passively may save the bid offer spread and so result in a good average price, but this may be at the expense of fully completing the order. If, the next day, the asset price shifts then completing the order may be more expensive than if we had traded more aggressively the day before. Transaction cost analysis (TCA) has played a key role in making traders and investors examine such costs more thoroughly.

For markets where brokers still charge commissions, e.g. equities, this is clearly a very visible cost of trading. Until the 2007-09 financial crisis, overall commissions have been stcadily declining. Figure 1-6 charts their progression over the last few years, in terms of \$/share. It also highlights the differences between DMA, algorithmic and manual (high touch) trading. From a broker's point of view, the low touch services (DMA and algorithmic trading) have relatively low labour costs hence the lower charges. The costs for high touch / manual trading also reflect the fact that traders can offer additional information to clients, such as market colour or sentiment.

Overall, TCA has highlighted the fact that hidden costs, such as market impact and timing risk, are more significant than visible costs, such as commissions. Most algorithms are adept at reducing overall market impact, by splitting the order into smaller sizes.

![](_page_18_Figure_1.jpeg)

Reproduced with permission from Aite Group

Figure 1-6 U.S. equity average commissions

Similarly, crossing is an equally efficient, if not better, means of reducing market impact. Minimising timing risk and opportunity costs is more complex. The second generation of algorithms introduced cost-centric models, typified by Implementation Shortfall, which are better suited to this. We shall cover this in more detail in Chapters 5 and 6.

# Other reasons

Market regulation, such as Regulation NMS in the U.S. and MiFID in Europe, means that brokers and investors must be able to demonstrate that they achieved best execution. Electronic trading has made this somewhat easier, since detailed audit trails are relatively simple to maintain. Therefore, algorithmic trading is arguably one of the best choices to cater for such regulations, since its rule hased nature provides consistent and easily auditable trading decisions, as well as coping well with fragmented marketplaces.

### 1.9 How much are these execution methods used?

The sell-side brokerages have had electronic trading for years. Internally, almost all their trading is electronic, except for the few markets where there is still considerable floor-based activity. Similarly, automated trading systems and trading algorithms have long been established. Hence, most studies focus on the uptake of these technologies with the buy-side institutions. For example, Figure 1-7 shows estimates from the Aite Group consultancy for the breakdown of trading methods adopted by U.S. institutions.

The growth trends for algorithmic trading and DMA are clearly visible, as is the decline in "High touch" (and higher cost) manual trading. A report by the TABB Group (2008) estimates that by 2007 algorithmic trading, DMA, crossing and program trading together accounted for 63% of the U.S. institutional equities trades. Still, in 2008 they also note that the market crisis led to a slight shift in the trends. Algorithmic trading continued to increase, reaching 24% of buy-side flow, up 2% from the year before. However, high touch trading via sales traders also increased, recovering to 44% (back from 37% in 2007), as institutions sought to cope with the heightened levels of volatility.

Overview

![](_page_19_Figure_1.jpeg)

Figure 1-7 Estimates for the use of different trading methods by U.S. institutions

# 1.10 Fears and myths

Algorithmic trading has attracted a lot of publicity; there has also been a lot of marketing and hype. So in this section let's examine some of the common fears and myths that have attached themselves to this topic. Broadly speaking, these may be categorised into three main issues, namely safety, performance and usefulness.

# Safety of algorithmic trading

Some of the commonest concerns about algorithmic trading are that:

- Algorithms are fundamentally changing the market
- Algorithms will replace traders  $\bullet$
- Algorithms can leak alpha to proprietary traders  $\bullet$

There can be no doubt that electronic trading has transformed the world markets. Marketplaces are seeing waves of fragmentation and consolidation as competition for market share drives the creation of new execution venues whilst existing ones are bought, merge or fail. The emergence of crossing systems is a perfect example of this cyclc. Order sizes are shrinking, so off-exchange crossing becomes increasingly popular. In response, the exchanges introduce new mechanisms to try to regain liquidity from the crossing networks, and the cycle begins again. All the while, these market shifts offer opportunities for astute investors and traders who are ahead of the market. Coping with this constant change is clearly difficult. Nevertheless, Pandora's Box has already been opened, for better or worse, so we may as well look inside and find ways to deal with the new market reality.

Algorithmic trading is a natural evolution from electronic trading. Computers are ideally suited to working in complex multi-venue markets, since they can easily monitor the order books of a range of execution venues. If everyone used VWAP algorithms for their trading then clearly some self-reinforcement of trading patterns would occur, much like if everyone used the same technical analysis. However, people's views differ: Indeed, the very reason that the world's markets function is because investors and traders have a diverse range of opinions. Therefore, they target different prices and use a range of alternative trading strategies. There is no reason why algorithmic trading should alter this diversity.

Job security is also an issue. Eye-catching news headlines have proclaimed the end of the trader, but then we're all going to be replaced with robots in 2075 aren't we? It is important to remember that electronic and algorithmic trading are simply tools. Certainly, job roles are evolving, for example, salespeople are becoming sales traders. Sell-side desks are now covering multiple asset classes. Not long ago, it was predicted that principal or risk trading would become more commonly used than agency trading. The 2007-09 financial crisis and the transformation of the financial sector have given a new lease of life to agency trading. In fact, during this crisis principal trading looked far more endangered. In such markets, traders and investors need to be flexible to take advantage of any tools that help give them an edge and drive profits.

An article in the CFA Magazine (2006) titled 'Hype and Algorithms' poses a good counterpoint to the fear that algorithms will take over the world. In the article, Joe Gawronski, COO of Rosenblatt Securities, highlights the fact that:

"Algorithms can't react in the true sense of how I define a reaction. Everything they do is based on a rule that's been provided, whereas traders can change their mind on the fly. There's no way to incorporate into algorithms the random facts and observation that may give a trader a "feel" for the market."

Artificial Intelligence (AI) may offer a solution to this; however, this is still some way off. AI first took of in the 1950s, but it was not until 1997 that IBM's Deep Blue computer could beat the world chess champion. In the same CFA article James Finnegan, editor of the Financial Engineering News, points out:

"People equate black-box algorithms with super computers developed to play chess and mistakenly assume there will one day be an algorithm that is so smart, quick, and innovative that even the best traders in the world won't stand a chance. However, the difference is that although there are billions and billions of permutations with chess, there is a defined board and a very strict set of rules, so a computer with enough memory can learn every move. That's not the case with markets."

Beyond all the hype, algorithmic trading will certainly have a major impact. For instance, good algorithms may be just as efficiently used by a salesperson as a sales trader. It should also open up new avenues for trading, expanding the potential of multi-region and multiasset trading.

Another concern for investors is information leakage. There is still some suspicion that brokers can garner information from client order flow and use this for their own proprietary trading. That said, the buy-side has more power and control than it has ever had. Offexchange crossing networks even allow the buy-side to completely bypass brokers. Given that commissions are declining, it is vital for brokers to retain order flow. Reputation is paramount. Brokers have to ensure that their proprietary trading desks are truly isolated from the brokerage operations. This holds true for all the major brokers, whose prime brokerage units are often segregated, located on separate floors or even buildings.

# Performance of algorithmic trading

Another common fear is that trading algorithms have now become commoditised and there is little differentiation between them. There is some truth to this, in that there are only so many ways of implementing an algorithm that targets a benchmark like VWAP. However, being commoditised is not altogether a bad thing; it is important to have a certain level of standardisation. We just have to look at the markets to see how standardised products have better liquidity and so lower trading costs. Similarly, standardised algorithms, at least in terms of their parameters and basic functions, would allow clients to swap between brokers more easily, thus encouraging more competition.

Commoditisation is less of an issue for the more complex cost driven and opportunistic algorithms. Here the performance is dependent on the quality of their quantitative models, so brokers can add significant value. Indeed, there can be considerable variation in the performance of these algorithms between brokers.

Algorithm choice is also an important factor: If an unsuitable type of algorithm is chosen then performance is bound to suffer. This can be addressed by a combination of education and improving the available pre-trade analytics. Another solution is the increasing provision of systems that can automatically suggest the most suitable algorithm for a specific order. Post-trade analysis is vital to check the actual performance. Note that both the mean and standard deviation of performance need to be considered.

There is also the feeling that brokers hold back the best performing algorithms for themselves. Fundamentally, proprietary desks, particularly those employing high frequency trading or statistical arbitrage adopt different strategies to investors. They are usually keen to stay market neutral and so strategies tend not to build up large positions, instead acting more like sophisticated day traders. Thus, any algorithms they use tend to be highly specialised, often based on market making. That's not to say brokers don't run different algorithms. Newer versions of algorithms need extensive testing, so these will be used internally before being made available to clients. In general, algorithms are a valuable marketing resource which brokers are keen to make available as soon as they are ready.

Finally, it is important to remember that algorithmic trading is just a tool, not a panacea. It is not designed to generate profits (or alpha), simply to help control costs and provide best execution.

# Usefulness of algorithmic trading

The success of algorithmic trading means that less people are still questioning its usefulness. Although there are still a few issues rooted from the early days of algorithmic trading, namely that:

- Algorithms are complicated to use
- They only really work for liquid assets or small orders

Algorithms sometimes have a reputation of being complicated, but as we saw in the example in Table I-4, they require parameters that look very similar to the instructions we might give to a trader. Most algorithms will have sanity checks, so if an order is unusually large, or the price limit is miles away from the actual market price then the order may be rejected, just to be safe. Nevertheless, as with any computer program, it is important to bear in mind the "Garbage In Garbage Out" maxim, and assume that it will not be as forgiving with any typos.

Algorithm selection from the hundreds available may seem like an ominous task. That said, any one broker probably offers a maximum of a dozen trading algorithms. Therefore, it is simply a case of using pre-trade analytics to estimate the potential impact and risk of an order. Increasingly, brokers are rationalising their suites of algorithms to make selection even easier. They are also starting to provide more client-focussed solutions that cater for specific requirements. Some brokers even provide services that suggest the most appropriate algorithm, based on the order size and the asset's liquidity and volatility.

In terms of algorithms only being able to cope with liquid assets or small orders, this may

have been true for the first generation of algorithms. Modern algorithms are much more versatile. In particular, the introduction of cost-centric and liquidity seeking algorithms means they can now support a much broader set of requirements.

Illiquid assets pose a specific problem, namely signalling risk. This represents the information leakage to other market participants from our trading strategy. Imagine using the simplistic algorithm we saw in Figure 1-5 for an illiquid asset. The regular large buy orders would scream, "We have a buyer", whereas for a more heavily traded asset they would not stand out as much. Consequently, it is often necessary to hide our actual intentions as much as possible, by using special order types and by seeking liquidity from alternative sources such as crossing networks. We shall cover this in more detail in Chapters 8 and 9. Interestingly, these techniques are increasingly being applied to more liquid assets.

One area where algorithms do need more work is coping with unexpected events or news. Human traders can often deal with this much more effectively. That said, the next generation of algorithms are already starting to look at how best to incorporate additional information to deal with such situations. We will look at this in more depth in Chapters 10 and 14.

# 1.11 Summary

- m Direct Market Access (DMA) enables clients to send orders to exchanges by using a proxy for their broker's membership, giving them a similar level of control for an order's execution to a sell-side trader.
- Algorithmic trading is a computerised rule-based system responsible for executing orders to buy or sell a given asset. A computer program follows preset rules to determine how each order should be executed. Algorithmic execution is perhaps a more representative name.
- $\blacksquare$ Systematic, black-box, quantitative and high frequency or automated trading are terms that are sometimes mistakenly used as references to algorithmic trading. In fact, they are more to do with the style of investment than the execution.
- So far, there have been three main generations in the evolution of trading algorithms:  $\mathbf{u}$ 
  - The first algorithms were natural evolutions of simple order slicing, focussing on specific benchmarks, such as TWAP or VWAP. Initially, these were schedule driven, often based on historical data. Later, more dynamic versions incorporated market conditions, leading to tracking algorithms, such as percentage of volume.
  - The second generation of trading algorithms were created in response to the application of transaction cost analysis. Implementation shortfall algorithms strive to minimise cost by balancing both market impact and risk.
  - The third generation of algorithms are focussed more on liquidity, resulting from the fragmentation of major markets and the arrival of "dark pools".
  - Continual evolution and the adoption of similar tactics mean that the boundaries between these methods are constantly blurring. Increasingly, complex DMA order types are making it difficult to differentiate between them and trading algorithms.

- $\blacksquare$ Comparing algorithmic trading and DMA with manual trading:
  - In terms of speed and capacity, algorithmic trading is clearly the winner; computers \_ can handle thousands of orders simultaneously, responding in fractions of a second.
  - In terms of performance, experienced traders still have the edge over algorithms since they can infer more subtle signals from the market. Though, as algorithms continue to evolve, the gap is closing. Algorithms also offer the prospect of more consistent results. Note that selecting the appropriate algorithm is vital.