# Appendix A Stochastic Calculus for Finance

This chapter provides a concise overview of stochastic calculus for diffusion and jump processes. There are many excellent textbooks (see, e.g., the bibliography and other readings at the end of this appendix) which cover these topics in an inordinate amount of detail. Here, however, we focus on the main tools and results that we require to pose and solve the algorithmic trading problems that appear in Part III of this textbook.

In all sections, we work on a filtered probability space (also called a stochastic basi.s) denoted by (D,F, {Ft} <sup>o</sup><t<r,lP') where as is standard:

- e D denotes the space of all events,
- e F denotes the set of all measurable events,
- { Ft} <sup>o</sup><t<T ( each contained in F) denotes the filtration a sequence of sigmaalgebras which refine one another in the sense that Fs c;;; Ft for all O <::: s < *t* <::: *T.*

We further assume that the usual conditions apply and that the filtered probability is completed:

- e the probability space (S1, F, JP') is complete every subset of a measure zero set is measurable itself and (therefore) has zero measure; more precisely, for all w E F s.t. lP'(w) = 0 and for all w' C w, we have w' E F and so lP'(w') = 0,
- each Ft contains the zero measure sets of F,
- e the filtration is right-continuous, i.e. Ft+ = ns>tT, = Ft.

These technical conditions allow us to construct a version of a stochastic process which is cadlag, i.e. right continuous with left limit (RCLL).

### A.1 Diffusion Processes

In this section, we investigate the very important stochastic process known as a Brownian motion or Wiener process.

#### A.1.1 Brownian Motion

DEFINITION A.1 A standard Brownian motion  $W = (W_t)_{0 \le t \le T}$  is a stochastic process defined on the completed probability space  $(\Omega, \mathcal{F}, \{\mathcal{F}_t\}_{0 < t < T}, \mathbb{P}),$ where the filtration is the natural one generated by  $W$ , satisfying the following properties:

- (i)  $W_0 = 0$ , almost surely,
- (ii) W has **independent increments**: for all  $0 = t_0 \le t_1 \le t_2 \le \cdots \le t_{n-1} \le$  $t_n = T$  the increments  $W_{t_{k+1}} - W_{t_k}$  for  $k = 0, \ldots, n-1$  are independent random variables,
- (iii) W has **stationary increments**: for all  $0 \le t < t + h \le T$ , the increment  $W_{t+h} - W_t$  (which is a random variable) has distribution that is independent of  $t$ ,
- (iv) the random variable  $W_t$  is normally distributed with mean 0 and variance t, and we will often write  $W_t \sim \mathcal{N}(0, t)$ ,
- (v) the function  $t \mapsto W_t$  is almost surely continuous.

It is not clear whether specifying the marginal distributions of the Brownian motion, which is done in points  $(ii)$ - $(iv)$  above, is consistent with the continuity condition in  $(v)$ . This condition is necessary, because certainly if we modify the Brownian motion at say an exponential time  $\tau$  and make it equal zero there, then the marginal properties remain the same, but it will fail to satisfy the continuity requirement. In fact, Paul Lévy proves (Jacod & Shiryaev (1987)) that indeed there is no contradiction and such processes do in fact exist.

### A.1.2 Stochastic Integrals

Stochastic integration with respect to Brownian motion can be most easily viewed through the lens of Itô integrals. Let  $\Pi_1, \Pi_2, \ldots$  denote an infinite sequence of refining partitions of the interval  $[0,T]$ , so that each  $\Pi_k$  represents an increasing sequence  $0 = t_0^{(k)} < t_1^{(k)} < t_2^{(k)} < \cdots < t_{n^{(k)}}^{(k)} = T$ , and the  $L^{\infty}$  norm

$$\|\Pi_k\| = \max_{m=1,\ldots,n^{(k)}} \left( t_m^{(k)} - t_{m-1}^{(k)} \right) \,,$$

tends to zero as  $k$  tends to infinity.

DEFINITION A.2 The **Itô integral** of an  $\mathcal{F}_t$ -adapted stochastic process  $q =$  $(g_t)_{0 \le t \le T}$  which is  $\mathbb{P}$ -square integrable, i.e.  $\mathbb{E}\left[\int_0^T g_s^2 \, ds\right] < +\infty$ , often simply said to be square integrable, or in  $L^2$ , is defined as follows:

$$I_{t} = \int_{0}^{t} g_{s} dW_{s} = \lim_{\|\Pi_{k}\| \to 0} \sum_{m=1}^{n_{k}} g_{t_{m-1}} \left( W_{t_{m}} - W_{t_{m-1}} \right) . \tag{A.1}$$

In the definition above, the function  $q$  is evaluated at the left-hand end point of the interval  $[t_{m-1}, t_m)$ . This has the financial interpretation of entering a position  $g_{t_{m-1}}$  at the start of the interval, and the Brownian increment  $(W_{t_m} - W_{t_{m-1}})$ 

represents the increase in the asset's value while keeping the position constant over that time interval. This is why Itô integrals are used ubiquitously in the mathematical finance literature.<sup>1</sup> Strictly, one should introduce the Itô integral for simple functions, i.e. functions which are piecewise defined:  $H_t(\omega)$  =  $\sum_{k} h_k(\omega) \mathbb{1}_{t \in [t_k, t_{k+1})}$  for  $h_k \in \mathcal{F}_{t_k}$ , show that any  $g \in L^2$  can be approximated, in  $L^2$ , by a sequence of such functions, and finally define the Itô integral of g as the limiting value of the Itô integral of the sequence. See, e.g., Øksendal (2010). The Itô isometry is one of the tools which allows this programme to be developed.

THEOREM A.3 Itô's isometry. If  $g \in L^2$ , that is, g is  $\mathcal{F}_t$  adapted and  $\mathbb{E}\left[\int_0^T g_s^2 ds\right] < +\infty$ , then

$$\mathbb{E}\left[\left(\int_0^T g_s \, dW_s\right)^2\right] = \mathbb{E}\left[\int_0^T g_s^2 \, ds\right] \, .$$

The stochastic integral  $(A.1)$  is called an Itô process, and is often written in differential form

$$dI_t = g_t \, dW_t \,,$$

despite the fact that a Brownian motion is not differentiable anywhere, so that the expression  $dW_t$  without the integral is meaningless. It is, however, convenient to write it this way and renders computations more digestible. Itô processes can more generally be written as

$$I_t = \int_0^t \mu_s \, ds + \int_0^t \sigma_s \, dW_s \,,$$

where  $\mu$  and  $\sigma$  are  $\mathcal{F}_t$ -adapted and satisfy certain integrability requirements. The first term should be interpreted as a Riemann integral and the second term as an Itô integral. This is often written in shorthand as

$$dI_t = \mu_t \, dt + \sigma_t \, dW_t \,. \tag{A.2}$$

When  $\mu_t = \mu(t, I_t)$  and  $\sigma_t = \sigma(t, I_t)$ , the above equation has the form of a differential equation, albeit one with diffusive noise, and these are referred to as stochastic differential equations (SDEs). Not all SDEs have solutions, and solutions come in two flavours, strong and weak solutions. A strong solution is a stochastic process which satisfies  $(A.2)$  and for which  $I_t$  is given explicitly in terms of the version of Brownian motion  $(W_t)_{0 \le t \le T}$  provided, i.e. it is adapted to the given filtration. A weak solution is one in which we seek a filtration  $\mathcal{H}_t$  on which we have a Brownian motion  $W_t$ , and the solution  $I_t$  satisfying (A.2) with W replaced by  $\tilde{W}$ . We will be concerned with only strong solutions of SDEs.

Another interesting property of Itô integrals is that they are in fact martin- $\text{gales.}$ 

 $1$  There are other approaches to stochastic integration, such as the Stratonovich integral, which is often used in quantum field theory in physics and instead evaluates  $q$  at the midpoint of the interval.

Itô Integrals are Martingales. The stochastic integral THEOREM  $A.4$ 

$$I_t = \int_0^t g_s \, dW_s \,,$$

is a martingale.

The intuition here is that for any given simple process approximation,  $\mathfrak{g}^{(n)}$ , to  $g$ , the Itô integral is given by  $\mathfrak{I}^{(n)}_t = \sum_k \mathfrak{g}^{(n)}_{t_{k-1}} (W_{t_k} - W_{t_{k-1}}),$  and so

$$\mathbb{E}\left[\mathfrak{I}_{t}^{(n)}\right] = \sum_{k} \mathbb{E}\left[\mathfrak{g}_{t_{k-1}}^{(n)}\left(W_{t_{k}} - W_{t_{k-1}}\right)\right]$$
$$= \sum_{k} \mathbb{E}\left[\mathbb{E}[\mathfrak{g}_{t_{k-1}}^{(n)}\left(W_{t_{k}} - W_{t_{k-1}}\right)|\mathcal{F}_{t_{k-1}}]\right]$$
$$= \sum_{k} \mathbb{E}\left[\mathfrak{g}_{t_{k-1}}^{(n)}\mathbb{E}[\left(W_{t_{k}} - W_{t_{k-1}}\right)|\mathcal{F}_{t_{k-1}}]\right] = 0.$$

The third equality follows since  $\mathfrak{g}_{t_{k-1}}^{(n)}$  is  $\mathcal{F}_{t_{k-1}}$  measurable, and the expected value of the increment of the Brownian motion is zero. This argument can be formalised to show that the increment of the integral, and not just the simple process approximation, has zero mean, and all that remains is to show that the integral is a strict martingale, and not just a local martingale. This last part follows from the assumption that  $q \in L^2$ .

Next, we touch on Itô's formula which allows us to transform Itô processes, i.e. stochastic processes which satisfy SDEs with Brownian noise terms, into other Itô processes. More specifically, it allows us to identify the SDE which the transformed process satisfies.

THEOREM  $A.5$  $Itô's \; Formula. \; Let \; W_t \; denote \; an \; n-dimensional \; (column)$ vector of independent Brownian motions and suppose that the m-dimensional (column) vector-valued processes  $X_t$  satisfy the SDE:

$$d\boldsymbol{X}_{t} = \boldsymbol{\mu}(t, \boldsymbol{X}_{t}) dt + \boldsymbol{\sigma}(t, \boldsymbol{X}_{t}) d\boldsymbol{W}_{t} , \qquad (A.3)$$

where  $\mu(t, X_t)$  is an m-dimensional (column) vector of drifts, and  $\sigma(t, X_t)$  is an  $m \times n$  matrix of volatilities. Next, introduce a new stochastic process  $Y_t =$  $f(t, \mathbf{X}_t)$ , where  $f(t, \mathbf{x})$  is twice differentiable in each  $x^{(i)}$ , cross-derivatives exist and f is once differentiable in t. Then  $Y_t$  is an Itô process satisfying the SDE

$$dY_t = \left(\partial_t f(t, \boldsymbol{X}_t) + \boldsymbol{\mu}(t, \boldsymbol{X}_t)' \boldsymbol{D} f(t, \boldsymbol{X}_t) + \frac{1}{2} \text{Tr} \,\sigma(t, \boldsymbol{X}_t) \,\sigma(t, \boldsymbol{X}_t)' \boldsymbol{D}^2 f(t, \boldsymbol{X}_t)\right) dt$$
$$+ \boldsymbol{D} f(t, \boldsymbol{X}_t)' \,\sigma(t, \boldsymbol{X}_t) \, d\boldsymbol{W}_t \,,$$

where for any vector or matrix  $A$ ,  $A'$  denotes its transpose,  $Df(t, X_t)$  denotes the m-dimensional (column) vector of first derivatives, i.e.  $\left(\boldsymbol{D}f(t,\boldsymbol{X}_{t})\right)_{i} =$  $\partial_{x^j} f(t, \boldsymbol{X}_t)$ , and  $D^2 f(t, \boldsymbol{X}_t)$  denotes the  $m \times n$ -dimensional matrix of mixed second derivatives, i.e.  $\left(\boldsymbol{D}f(t,\boldsymbol{X}_{t})\right)_{ik} = \partial_{x^{j}x^{k}}f(t,\boldsymbol{X}_{t}).$ 

DEFINITION A.6 The infinitesimal generator, sometimes called simply the generator, denoted by Lt of a process Xt acts on functions which are twice differentiable in the following manner:

$$\mathcal{L}_t f(x) = \lim_{h \downarrow 0} \frac{\mathbb{E}\left[f(X_{t+h}) \mid X_t = x\right] - f(x)}{h}.$$

The infinitesimal generator is the generalisation of a derivative of a function to make it applicable to a stochastic process. From Ito's formula in Theorem A.5, we see that the generator of an Ito process satisfying (A.3) is given by

$$\mathcal{L}_t f(\boldsymbol{x}) = \boldsymbol{\mu}(t, \boldsymbol{x})' \boldsymbol{D} f(\boldsymbol{x}) + \frac{1}{2} \boldsymbol{T} \boldsymbol{r} \sigma(t, \boldsymbol{x}) \, \sigma(t, \boldsymbol{x})' \, \boldsymbol{D}^2 f(\boldsymbol{x}) \, .$$

## A.2 Jump Processes

The basic building blocks for jump processes are counting processes, and more specifically, Poisson processes.

DEFINITION A.7 A Poisson process N = (Nt)o9�T E Z+, with intensity A, is a stochastic process which satisfies the following properties:

(i) No = 0, a.s.,

(ii) Nt - N0 has Poisson distribution with parameter *At,* i.e.

$$\mathbb{P}(N_t - N_0 = n) = e^{-\lambda t} \frac{(\lambda t)^n}{n!},$$

- (iii) has independent increments, so that Nt Ns ( *t* > *s)* is independent of Nv N<sup>u</sup> *(v* > *u)* whenever *(s,* t) n *(u, v)* = 0,
- (iv) has stationary increments, so that Ns+t Ns � Nt, for all *s, t* 2: 0.

An easy consequence of this definition is that the time between the jumps of *N* are independent and exponentially distributed. Moreover, we have that E[Nt] = ,.\ *t,* so that the following proposition holds.

PROPOSITION A.8 *The compensated Poisson process N* = {Nt}o<t<T, *with* Nt = Nt - ,.\ *t, is* a *martingale.* 

As with Brownian motions, we can define stochastic integrals with respect to a compensated Poisson processes in such a way that the resulting object is a martingale. To this end, let *g* be an Fradapted process, where *Ft* is the natural filtration generated by a Poisson process *N.* 

DEFINITION A.9 We define the stochastic integral *Y* = {Yt}o�t�T of g with respect to the compensated Poisson process N as follows:

$$Y_t = \int_0^t g_{s^-} d\widehat{N}_s = \sum_{k=1}^{N_t} g_{\tau_k^-} - \int_0^t g_s \lambda \, ds \,, \tag{A.4}$$

where { T1, T2, ... } is the collection of times at which *N* jumps.

Note that the summation term evaluates g from its left limit, and not at the time of the jump of *N.* This is a technical condition which renders the stochastic integral a martingale. If we evaluate *g* at the time of the jump, we can easily find examples for *g* which make the integral not a martingale. An alternate for the above integral is

$$Y_{t} = \int_{0}^{t} g_{s-} d\widehat{N}_{s} = \sum_{0 \le s \le t}^{N_{t}} g_{s-} \Delta N_{s} - \int_{0}^{t} g_{s} \lambda \, ds \,, \tag{A.5}$$

where the notation

$$\Delta N_s = N_s - N_{s^-}$$

is the size of the jump in N at time *s* which in this case is zero or one.

THEOREM A.10 *Ito's Formula for Poisson Processes. Suppose that Y is given by* (A.5). *Moreover, let Z* = { *Zt}o<t<T with Zt* = *f (t,* Yt) *for sorne function f, once d�ff erentiable in t. Then,* 

$$\begin{split} dZ_{t} &= \left( \partial_{t}f(t,Y_{t}) - \lambda \, g_{t} \, \partial_{y}f(t,Y_{t}) \right) dt \\ &+ \left[ \, f(t,Y_{t-} + g_{t-}) - f(t,Y_{t-}) \right] \, dN_{t} \\ &= \left\{ \partial_{t}f(t,Y_{t}) + \lambda \big( \left[ \, f(t,Y_{t-} + g_{t-}) - f(t,Y_{t-}) \right] - g_{t} \, \partial_{y}f(t,Y_{t}) \big) \right\} dt \\ &+ \left[ \, f(t,Y_{t-} + g_{t-}) - f(t,Y_{t-}) \right] \, d\widehat{N}_{t} \,. \end{split} \tag{A.6}$$

The interpretation of this formula is as follows: the second term accounts for the change in Z whenever a jump in N arrives, while the first term accounts for the drift corrections.

From the above, we see that the generator Lf of the process *Y* in A.5 acts as follows:

$$\mathcal{L}_t^Y f(y) = \lambda \big( [f(y+g_t) - f(y)] - g_t \, \partial_y f(y) \big) \, .$$

The above framework can be generalised to incorporate both diffusions and jumps. To this end, consider the sum of two stochastic integrals

$$Y_t = \int_0^t f_s \, ds + \int_0^t g_s \, dW_s + \int_0^t h_{s^-} \, d\widehat{N}_s \,, \tag{A.7}$$

where, *f, g* and h are Ft adapted processes, and the filtration F is the natural one generated by both the diffusion *W* and the Poisson process *N* ( assumed to be mutually independent). Each integral should be interpreted as in their individual definitions, i.e. the first term is simply a Riemann integral, the second term as in (A.l) and the third term as in (A.5). The Ito formula generalises naturally in this case.

THEOREM A.11 *Ito's Formula for Single Jumps and Diffusion. Suppose that Y is given by* (A.7). *Moreover, let Z* = *{Zt}o<t<T with Zt* = *£(t,* ½) *for*  some function .e, once d'iff'erentiable in t and tw'ice differentiable in y. Then,

$$\begin{split} dZ_{t} &= \left( \partial_{t} + f_{t} \, \partial_{y} + \frac{1}{2} \, g_{t}^{2} \, \partial_{yy} - \lambda \, h_{t} \, \partial_{y} \right) \ell(t, Y_{t}) \, dt \\ &+ \left[ \, \ell(t, Y_{t-} + h_{t-}) - \ell(t, Y_{t-}) \right] \, dN_{t} \\ &= \left\{ \, \left( \partial_{t} + f_{t} \, \partial_{y} + \frac{1}{2} \, g_{t}^{2} \, \partial_{yy} \right) \ell(t, Y_{t}) \\ &+ \lambda \left( \left[ \, \ell(t, Y_{t-} + h_{t-}) - \ell(t, Y_{t-}) \right] - h_{t} \, \partial_{y} \ell(t, Y_{t}) \right) \right\} dt \\ &+ \left[ \, \ell(t, Y_{t-} + h_{t-}) - \ell(t, Y_{t-}) \right] \, d\widehat{N}_{t} \,. \end{split} \tag{A.8}$$

Again, we can identify the action of the generator £'{ of the generalised Y process in (A.7) as

$$\mathcal{L}_t^Y \ell(y) = f_t \,\partial_y \ell(y) + \tfrac{1}{2} \,g_t^2 \,\partial_{yy} \ell(y) + \lambda \left( \left[ \,\ell(y+h_t) - \ell(y) \right] - h_t \,\partial_y \ell(y) \right).$$

The final generalisation which we wish to address in this section is the case of compound Poisson processes. A compound Poisson process I = { It}o<::t<::T is build out of a Poisson process N (with intensity A) and a collection of independent and identically distributed random variables { c1, c2, ... } with distribution function *F* (lE[c] < +oo, where c � F), and is given by

$$J_t = \sum_{k=1}^{N_t} \varepsilon_i \,, \quad t \ge 0 \,.$$

That is, the process jumps at the time of arrival of a Poisson process, and the size of the jump is independently drawn each time from the distribution function F.

PROPOSITION A.12 The compensated compound Poisson process J = { h}o<::t<::T, w'lth *lt* = It - lE[c] A t, is a martingale.

Analogous to the Poisson case, we can define stochastic integrals with respect to compound Poisson processes as well.

DEFINITION A.13 Let F denote the natural filtration generated by I. We define the stochastic integral Y = {Yt}o<t<T of an F-adapted process g with respect to the compensated compound Pcis:on process J as follows:

$$Y_t = \int_0^t g_{s^-} d\widehat{J}_s = \sum_{s \le t} g_{s^-} \Delta J_s - \int_0^t g_s \lambda \mathbb{E}[\varepsilon] ds$$
$$= \sum_{s \le t} g_{s^-} \varepsilon_{N_s} \Delta N_s - \int_0^t g_s \lambda \mathbb{E}[\varepsilon] ds , \qquad (A.9)$$

where, as before, 6It = It - I<sup>t</sup> - represents the jump size of I at time *t.*

In the next generalisation, we have the analog of the sum of stochastic integrals as in (A.7) by introducing three F-adapted stochastic processes, *f, g* and *h,*

where  $\mathcal{F}$  is the natural filtration generated by an independent Brownian motion W and  $\widehat{J}$ , and defining the stochastic integral Y as follows:

$$Y_t = \int_0^t f_s \, ds + \int_0^t g_s \, dW_s + \int_0^t h_{s^-} \, d\widehat{J}_s \,, \tag{A.10}$$

where each term is interpreted appropriately.

THEOREM A.14 Itô's Formula for Jump-Diffusion. Suppose that  $Y$  is given by (A.10). Moreover, let  $Z = \{Z_t\}_{0 \le t \le T}$  with  $Z_t = \ell(t, Y_t)$  for some function  $\ell$ , once differentiable in t and twice differentiable in y. Then,

$$\begin{split} dZ_{t} &= \left( \partial_{t} + f_{t} \, \partial_{y} + \frac{1}{2} \, g_{t}^{2} \, \partial_{yy} - \lambda \, \mathbb{E}[\varepsilon] \, h_{t} \, \partial_{y} \right) \ell(t, Y_{t}) \, dt \\ &+ \left[ \, \ell(t, Y_{t^{-}} + \varepsilon_{N_{t}} \, h_{t^{-}}) - \ell(t, Y_{t^{-}}) \right] \, dN_{t} \\ &= \left\{ \left. \left( \partial_{t} + f_{t} \, \partial_{y} + \frac{1}{2} \, g_{t}^{2} \, \partial_{yy} \right) \ell(t, Y_{t}) \right. \\ &+ \left. \lambda \left( \mathbb{E} \left[ \, \ell(t, Y_{t^{-}} + \varepsilon_{N_{t}} \, h_{t^{-}}) - \ell(t, Y_{t^{-}}) \right] - \mathbb{E}[\varepsilon] \, h_{t} \, \partial_{y} \ell(t, Y_{t}) \right) \right\} dt \quad \text{(A.11)} \\ &+ \left[ \, \ell(t, Y_{t^{-}} + \varepsilon_{N_{t}} \, h_{t^{-}}) - \ell(t, Y_{t^{-}}) \right] \, d\widehat{N}_{t} \, . \end{split}$$

For the process Y in  $(A.10)$ , we can see from the above that the action of the generator  $\mathcal{L}^Y_t$  is as follows:

$$\begin{split} \mathcal{L}_t^Y \ell(y) &= f_t \,\partial_y \ell(y) + \tfrac{1}{2} \, g_t^2 \,\partial_{yy} \ell(y) \\ &+ \lambda \left( \mathbb{E} \left[ \, \ell(t, y + \varepsilon \, h_t) - \ell(t, y) \right] - \mathbb{E}[\varepsilon] \, h_t \,\partial_y \ell(t, Y_t) \right). \end{split}$$

### A.3 **Doubly Stochastic Poisson Processes**

Here we consider the generalisation of jump processes which have stochastic intensity. A simple way to define such processes is by expanding filtrations. Suppose we have a counting process N and we want its intensity process  $\lambda = {\lambda_t}_{0 \le t \le T}$ to be 'stochastic'. One approach to defining such an object is to provide a way of computing the probability that an event arrives at time  $t$  given the information we have at time s, i.e. to define  $\mathbb{P}(N_t - N_s = n | \mathcal{F}_s)$ , where  $\mathcal{F}$  is the natural filtration generated by  $(N, \lambda)$ . If we have a way to compute this, then in principle we can compute all other quantities of interest. Doubly stochastic Poisson **processes**, also known as **Cox processes**, have the following property:

$$\mathbb{P}\Big(N_t - N_s = n \Big| \mathcal{F}_s \vee \sigma\big(\{\lambda_u\}_{s \le u \le t}\big)\Big) = \exp\Big\{-\int_s^t \lambda_u \, du\Big\} \frac{\Big(\int_s^t \lambda_u \, du\Big)^n}{n!} \,, \text{ (A.12a)}$$

so that

$$\mathbb{P}\left(\left.N_{t}-N_{s}=0\right|\mathcal{F}_{s}\right)=\mathbb{E}\left[\exp\left\{-\int_{s}^{t}\lambda_{u}\,du\right\}\left.\frac{\left(\int_{s}^{t}\lambda_{u}\,du\right)^{n}}{n!}\right|\left.\mathcal{F}_{s}\right.\right].\quad\left(\text{A.12b}\right)$$

Here,  $\sigma(\{\lambda_u\}_{s < u < t})$  denotes the smallest σ-algebra generated by the intensity process  $\lambda$  over the time interval  $[s, t]$ , and the 'join' operation  $\mathcal{F}_1 \vee \mathcal{F}_2$ , where  $\mathcal{F}_1$  and  $\mathcal{F}_2$  are two  $\sigma$ -algebras, represents the coarsest  $\sigma$ -algebra generated by taking unions of measurable sets from each individual  $\sigma$ -algebra. Simply put, in the above case,  $\mathcal{F}_s \vee \sigma(\{\lambda_u\}_{s \le u \le t})$  represents the information contained from the observations of  $(N, \lambda)$  up to time s together with the information on the entire path of  $\lambda$  up to time t, but excluding the information on the N process on the interval  $(s, t]$ . Therefore, we see from (A.12a) that the doubly stochastic Poisson process is conditionally (conditioned on  $\sigma(\{\lambda_u\}_{s < u < t})$ ) an inhomogeneous Poisson process with the conditionally known intensity.

The driver of the intensity process may in principle be anything ranging from an independent diffusion, an independent jump process, a combination of these, or even the counting process itself (in which case the process is known as a Hawkes process). Below are a few examples of the intensity process  $\lambda$ , where W is an independent Brownian motion and  $J$  is an independent compound Poisson process (with intensity  $\lambda_J$  and i.i.d. jumps  $\varepsilon \sim F$ ) with non-negative jumps:

$$\begin{array}{ll} d\lambda_t = \kappa(\theta - \lambda_t) \, dt + \eta \sqrt{\lambda_t} \, dW_t \,, & \text{Feller process, (A.13a)} \\ d\lambda_t = -\kappa \, \lambda_t \, dt + \gamma \, dJ_t \,, & \text{Ornstein-Uhlenbeck process, (A.13b)} \\ d\lambda_t = \kappa(\theta - \lambda_t) \, dt + \eta \sqrt{\lambda_t} \, dW_t + \gamma \, dJ_t \,, & \text{Jump-diffusion, (A.13c)} \\ \lambda_t = \int_0^t g(t-s) \, dN_s \,, & \text{Hawkes process. (A.13d)} \end{array}$$

The first three processes exhibit mean-reversion. The first and third processes mean-revert to  $\theta$ , while the second mean-reverts to 0. With jumps, however, the mean-reversion level does not reflect the long-run behaviour. Instead we should rewrite the SDEs in terms of their compensated versions.

PROPOSITION A.15 The compensated doubly stochastic Poisson Pro**cess**  $\widehat{N} = \{\widehat{N}_t\}_{0 \le t \le T}$ , with  $\widehat{N}_t = N_t - \int_0^t \lambda_s \, ds$ , is a martingale.

Writing the OU  $(A.13b)$  and jump-diffusion  $(A.13c)$  in terms of their compensated versions we have

$$d\lambda_t = \kappa \left(\frac{\gamma \lambda_J}{\kappa} \mathbb{E}[\varepsilon] - \lambda_t\right) dt + \gamma \ d\widehat{J}_t \,, \qquad \qquad \text{OU process, (A.14a)}$$

$$d\lambda_t = \kappa \left(\theta + \frac{\gamma \lambda_J}{\kappa} \mathbb{E}[\varepsilon] - \lambda_t\right) dt + \eta \sqrt{\lambda_t} \, dW_t + \gamma \, d\widehat{J}_t \,, \quad \text{Jump-diffusion.} \tag{A.14b}$$

From this expression, we see that the expected average intensities (in the long run) are  $\frac{\gamma \lambda_J}{\kappa} \mathbb{E}[\varepsilon]$  and  $\theta + \frac{\gamma \lambda_J}{\kappa} \mathbb{E}[\varepsilon]$ , respectively. That is, the expected long run intensity is the mean-reversion level plus the jump correction term  $\frac{\gamma \lambda_J}{\kappa} \mathbb{E}[\varepsilon]$ .

We define the stochastic integral  $Y = \{Y_t\}_{0 \le t \le T}$  of  $g$  with DEFINITION  $A.16$ respect to the compensated doubly stochastic Poisson process  $N$  as follows:

$$Y_t = \int_0^t g_{s^-} d\widehat{N}_s = \sum_{k=1}^{N_t} g_{\tau_k^-} - \int_0^t g_s \,\lambda_s \,ds\,,\tag{A.15}$$

where { T1, *T2,* ... } is the collection of times at which *N* jumps.

This definition is completely analogous to Definition A.9 for the simple Poisson processes. The only difference appears in the compensator, which is now a stochastic process in its own right.

THEOREM A.17 *Ito's Formula for Single doubly Stochastic Poisson processes. Let N be a doubly stochastic Poisson process with intensity A satisfying the SDE* 

$$d\lambda_t = \mu_t \, dt + \sigma_t \, dW_t + \eta_{t^-} \, d\dot{J_t} \,, \tag{A.16}$$

*where W and* J *are a Brownian motion and compound Poisson process (with intensity A<sup>J</sup> ,* i. i. *d. jumps E � F, and corresponding counting process NI), all m·utually independent and independent of N, andµ, er and T) are adapted to the natural filtration generated by N, VV and* J. *Furthermore, let Z* = {Zt}o-<:t-<:T *with* Zt = £.(t, Nt, At) *for some function* £, *once differentiable in t and twice differentiable in A. Then,* 

$$\begin{split} dZ_{t} &= \left( \partial_{t} + (\mu_{t} - \lambda_{G} \mathbb{E}[\varepsilon]) \, \partial_{\lambda} + \frac{1}{2} \, \sigma_{t}^{2} \, \partial_{\lambda\lambda} - \lambda_{t} \, \partial_{n} \right) \ell(t, N_{t}, \lambda_{t}) \, dt \\ &+ \left[ \ell(t, N_{t-}, \lambda_{t-} + \varepsilon_{M_{t}}) - \ell(t, N_{t-}, \lambda_{t-}) \right] dM_{t} \\ &+ \left[ \ell(t, N_{t-}, \lambda_{t-}) - \ell(t, N_{t-}, \lambda_{t-}) \right] dM_{t} \end{split} \tag{A.17}$$
$$&+ \left[ \ell(t, N_{t-}, \lambda_{t-}) - \ell(t, N_{t-}, \lambda_{t-}) \right] dN_{t} \\ &= \left\{ \left( \partial_{t} + \mu_{t} \, \partial_{\lambda} + \frac{1}{2} \, \sigma_{t}^{2} \, \partial_{\lambda\lambda} \right) \ell(t, N_{t}, \lambda_{t}) \\ &+ \lambda_{G} \left( \left[ \ell(t, N_{t-}, \lambda_{t-} + \varepsilon_{M_{t}}) - \ell(t, N_{t-}, \lambda_{t-}) \right] - \mathbb{E}[\varepsilon] \partial_{\lambda} \ell(t, N_{t-}, \lambda_{t-}) \right) \\ &+ \lambda \left( \left[ \ell(t, N_{t-}, \lambda_{t-} + \varepsilon_{M_{t}}) - \ell(t, N_{t-}, \lambda_{t-}) \right] - \partial_{n} \ell(t, N_{t-}, \lambda_{t-}) \right) \right\} dt \\ &+ \left[ \ell(t, N_{t-}, \lambda_{t-} + \varepsilon_{M_{t}}) - \ell(t, N_{t-}, \lambda_{t-}) \right] d\widehat{M}_{t} \\ &+ \left[ \ell(t, N_{t-}, \lambda_{t-} + \varepsilon_{M_{t}}) - \ell(t, N_{t-}, \lambda_{t-}) \right] d\widehat{M}_{t} \\ &+ \left[ \ell(t, N_{t-}, \lambda_{t-}) - \ell(t, N_{t-}, \lambda_{t-}) \right] d\widehat{M}_{t} \end{split} \tag{A.18}$$

From this, we see that the generator .c..1(, >. of the joint processes (N, A), where the intensity of N is A and satisfies (A.16), acts on functions as follows:

$$\begin{split} \mathcal{L}^{N,\lambda}_{t} \ell(n,\lambda) &= \quad \mu_{t} \, \partial_{\lambda} \ell(n,\lambda) + \frac{1}{2} \, \sigma_{t}^{2} \, \partial_{\lambda \lambda} \ell(n,\lambda) \\ &+ \lambda_{G} \left( \mathbb{E}[\, \ell(n,\lambda+\varepsilon) - \ell(n,\lambda)] - \mathbb{E}[\varepsilon] \partial_{\lambda} \ell(n,\lambda) \right) \\ &+ \lambda \left( \mathbb{E}\left[\, \ell(n,\lambda) - \ell(n,\lambda)\right] - \partial_{n} \ell(n,\lambda) \right). \end{split}$$

The doubly stochastic Poisson process can be further generalised to the case of a doubly stochastic compound Poisson process, where jumps arrive at the arrival times of a doubly stochastic Poisson process.

### A.4 Feynman-Kac and PDEs

Certain linear partial differential equations are closely linked to stochastic processes and particularly to stochastic differential equations. The simplest example of this is the case of the heat equation:

$$\begin{cases} \partial_t h(t,x) + \frac{1}{2} \partial_{xx} h(t,x) = 0, \\ h(T,x) = H(x), \end{cases} \tag{A.19}$$

where  $H \in L^1$ , i.e.  $\mathbb{E}[|H(X_T)|] < +\infty$  where  $X = \{X_t\}_{0 \le t \le T}$  is a Brownian motion. At first glance, there seems to be no connection whatsoever to a stochastic process or SDEs. To see the connection, suppose we introduce a Brownian motion X on a probability space  $(\Omega, \mathbb{P}, \mathcal{F} = \{\mathcal{F}_t\}_{0 \le t \le T})$ , where  $\mathcal{F}$  is the natural filtration generated by  $X$ , and define the stochastic process

$$f_t = \mathbb{E}[H(X_T) \,|\, \mathcal{F}_t] \, .$$

A key property in making the connection to the PDE, is the fact that such a stochastic process is a martingale because (i) for  $s \le t \le T$ , we have

$$\mathbb{E}\left[f_t\,|\,\mathcal{F}_s\right] = \mathbb{E}\left[\mathbb{E}\left[H(X_T)\,|\,\mathcal{F}_t\right]\,|\,\mathcal{F}_s\right] = \mathbb{E}\left[\,H(X_T)\,|\,\mathcal{F}_s\,\right] = f_s\,,$$

where the second equality follows from the iterated expectation property (since  $\mathcal{F}_s$  is a coarser  $\sigma$ -algebra than  $\mathcal{F}_t$ ), and (ii)

$$\mathbb{E}\left[\left|f_t\right|\right] = \mathbb{E}\left[\left| \mathbb{E}\left[\left|H(X_T)\right| \mathcal{F}_t\right] \right| \right] \leq \mathbb{E}\left[\left| \mathbb{E}\left[\left|H(X_T)\right| \left| \mathcal{F}_t\right] \right| \right] < +\infty,$$

where the first inequality follows from Jensen's inequality and the last from the assumption that H is in  $L^1$ . Next, note that the process  $f_t$  is in fact Markov in  $X$  since

$$f_t = \mathbb{E}\left[H(X_T) \mid \mathcal{F}_t\right] = \mathbb{E}\left[H\left((X_T - X_t) + X_t\right) \mid \mathcal{F}_t\right]$$
$$= \mathbb{E}\left[H\left(\sqrt{T - t} \; Z + X_t\right) \mid \mathcal{F}_t\right] = g(t, X_t),$$

where  $g(t,x)$  is some function, the third equality follows from the independence of  $(X_T - X_t)$  and  $X_t$ , and Z is an standard normal random variable independent of  $X_t$ . If we further assume that g is smooth enough, then we can use Itô's lemma to write (for any  $h > 0$ )

$$g(t+h, X_{t+h}) - g(t, X_t)$$
  
=  $\int_t^{t+h} \left\{ \partial_t g(s, X_s) + \frac{1}{2} \partial_{xx} g(s, X_s) \right\} ds + \int_t^{t+h} \partial_x g(s, X_s) dX_s$ 

Since  $q$  is a martingale, we have

$$\begin{split} 0 &= \mathbb{E}_{t,x} \left[ g(t+h, X_{t+h}) - g(t, X_t) \right] \\ &= \mathbb{E}_{t,x} \left[ \int_t^{t+h} \left\{ \partial_t g(s, X_s) + \frac{1}{2} \partial_{xx} g(s, X_s) \right\} ds + \int_t^{t+h} \partial_x g(s, X_s) dX_s \right] \\ &= \mathbb{E}_{t,x} \left[ \int_t^{t+h} \left\{ \partial_t g(s, X_s) + \frac{1}{2} \partial_{xx} g(s, X_s) \right\} ds \right] \,. \end{split}$$

Next, dividing by h, taking  $h \downarrow 0$ , and invoking the Fundamental Theorem of Calculus, we have

$$0 = \lim_{h \downarrow 0} \frac{1}{h} \mathbb{E}_{t,x} \left[ \int_{t}^{t+h} \left\{ \partial_t g(s, X_s) + \frac{1}{2} \partial_{xx} g(s, X_s) \right\} ds \right]$$
  
=  $\partial_t g(t, x) + \frac{1}{2} \partial_{xx} g(t, x)$ ,

and from the definition of g, we also have  $g(T,x) = H(x)$ . Hence, we see that  $g(t,x)$  satisfies the PDE (A.19). This sequence of arguments is one example of a more general result.

THEOREM A.18 **Feynman-Kac.** Let  $X$  denote an Itô process satisfying the  $SDE$ 

$$dX_t = \mu(t, X_t) dt + \sigma(t, X_t) dW_t,$$

where  $W$  is a Brownian motion. Define the function

$$f(t,x) = \mathbb{E}_{t,x} \left[ \int_t^T e^{-\int_t^s \gamma(u,X_u) \, du} \, g(s,X_s) \, ds + e^{-\int_t^T \gamma(u,X_u) \, du} \, h(X_T) \right],$$

where  $\mathbb{E}[|h(X_T)|] < +\infty$ ,  $\mathbb{E}\left[\int_0^T |g(s,X_s)|\,ds\right] < +\infty$ , and  $\int_0^T \gamma(t,X_t)\,dt$  is bounded from below a.s. . Then  $f(t,x)$  satisfies the PDE

$$\begin{cases} \partial_t f(t,x) + \mathcal{L}_t^X f(t,x) + g(t,x) f(t,x) = \gamma(t,x) f(t,x) \,, \\ f(T,x) = h(x) \,, \end{cases} \tag{A.20}$$

where  $\mathcal{L}^X_t$  represents the infinitesimal generator of X, specifically,

$$\mathcal{L}_t^X f = \mu(t, x) \,\partial_x f + \tfrac{1}{2} \sigma^2(t, x) \,\partial_{xx} f \ .$$

### $A.5$ Bibliography and Selected Readings

Baxter & Rennie (1996), Jacod & Shiryaev (1987), Shreve (2005), Øksendal  $(2010)$ , Shreve  $(2013)$ , Steele  $(2010)$ .